{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 12798,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.8522264957427979,
      "learning_rate": 1.99999698709582e-05,
      "loss": 1.0306,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0459555387496948,
      "learning_rate": 1.9999879484014346e-05,
      "loss": 0.8856,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9636313915252686,
      "learning_rate": 1.999972883971309e-05,
      "loss": 0.836,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9232612252235413,
      "learning_rate": 1.9999517938962186e-05,
      "loss": 0.8489,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7048255205154419,
      "learning_rate": 1.999924678303249e-05,
      "loss": 0.8158,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.225865364074707,
      "learning_rate": 1.9998915373557922e-05,
      "loss": 0.7836,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.32091224193573,
      "learning_rate": 1.9998523712535507e-05,
      "loss": 0.7665,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1787599325180054,
      "learning_rate": 1.999807180232531e-05,
      "loss": 0.7183,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0323059558868408,
      "learning_rate": 1.999755964565046e-05,
      "loss": 0.7487,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.447669267654419,
      "learning_rate": 1.9996987245597104e-05,
      "loss": 0.7407,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.037602424621582,
      "learning_rate": 1.999635460561443e-05,
      "loss": 0.749,
      "step": 110
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1580889225006104,
      "learning_rate": 1.9995661729514596e-05,
      "loss": 0.6919,
      "step": 120
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3559702634811401,
      "learning_rate": 1.9994908621472745e-05,
      "loss": 0.6901,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1495915651321411,
      "learning_rate": 1.9994095286026958e-05,
      "loss": 0.6889,
      "step": 140
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9629917740821838,
      "learning_rate": 1.999322172807824e-05,
      "loss": 0.6845,
      "step": 150
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5072319507598877,
      "learning_rate": 1.999228795289049e-05,
      "loss": 0.6586,
      "step": 160
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4244052171707153,
      "learning_rate": 1.9991293966090445e-05,
      "loss": 0.6611,
      "step": 170
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.6338645219802856,
      "learning_rate": 1.999023977366769e-05,
      "loss": 0.6662,
      "step": 180
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4940223693847656,
      "learning_rate": 1.9989125381974583e-05,
      "loss": 0.671,
      "step": 190
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9690455198287964,
      "learning_rate": 1.9987950797726233e-05,
      "loss": 0.675,
      "step": 200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9254029393196106,
      "learning_rate": 1.9986716028000463e-05,
      "loss": 0.6533,
      "step": 210
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.642014741897583,
      "learning_rate": 1.9985421080237758e-05,
      "loss": 0.6412,
      "step": 220
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0051140785217285,
      "learning_rate": 1.9984065962241224e-05,
      "loss": 0.6745,
      "step": 230
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.3102751970291138,
      "learning_rate": 1.9982650682176542e-05,
      "loss": 0.5951,
      "step": 240
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.3731229305267334,
      "learning_rate": 1.9981175248571918e-05,
      "loss": 0.6673,
      "step": 250
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.192671298980713,
      "learning_rate": 1.9979639670318037e-05,
      "loss": 0.6712,
      "step": 260
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.7478315830230713,
      "learning_rate": 1.997804395666799e-05,
      "loss": 0.6122,
      "step": 270
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.4927548170089722,
      "learning_rate": 1.9976388117237252e-05,
      "loss": 0.6491,
      "step": 280
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.149437189102173,
      "learning_rate": 1.9974672162003586e-05,
      "loss": 0.6315,
      "step": 290
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.4848204851150513,
      "learning_rate": 1.997289610130701e-05,
      "loss": 0.6502,
      "step": 300
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6608432531356812,
      "learning_rate": 1.9971059945849732e-05,
      "loss": 0.6942,
      "step": 310
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1652532815933228,
      "learning_rate": 1.996916370669607e-05,
      "loss": 0.6345,
      "step": 320
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.4337588548660278,
      "learning_rate": 1.9967207395272394e-05,
      "loss": 0.6464,
      "step": 330
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2072029113769531,
      "learning_rate": 1.9965191023367066e-05,
      "loss": 0.6158,
      "step": 340
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9501742124557495,
      "learning_rate": 1.9963114603130353e-05,
      "loss": 0.6171,
      "step": 350
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.6932827234268188,
      "learning_rate": 1.9960978147074367e-05,
      "loss": 0.617,
      "step": 360
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.598122000694275,
      "learning_rate": 1.9958781668072986e-05,
      "loss": 0.5746,
      "step": 370
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.015287160873413,
      "learning_rate": 1.9956525179361767e-05,
      "loss": 0.6351,
      "step": 380
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.169156074523926,
      "learning_rate": 1.995420869453788e-05,
      "loss": 0.6137,
      "step": 390
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.150291085243225,
      "learning_rate": 1.995183222756002e-05,
      "loss": 0.5846,
      "step": 400
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.279493570327759,
      "learning_rate": 1.9949395792748322e-05,
      "loss": 0.63,
      "step": 410
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.7296935319900513,
      "learning_rate": 1.994689940478427e-05,
      "loss": 0.6137,
      "step": 420
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5771337747573853,
      "learning_rate": 1.9944343078710627e-05,
      "loss": 0.6409,
      "step": 430
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.67044734954834,
      "learning_rate": 1.994172682993132e-05,
      "loss": 0.5617,
      "step": 440
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.5562214851379395,
      "learning_rate": 1.9939050674211358e-05,
      "loss": 0.5973,
      "step": 450
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3102848529815674,
      "learning_rate": 1.9936314627676753e-05,
      "loss": 0.5866,
      "step": 460
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.6510436534881592,
      "learning_rate": 1.993351870681439e-05,
      "loss": 0.6126,
      "step": 470
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.3016092777252197,
      "learning_rate": 1.993066292847195e-05,
      "loss": 0.5687,
      "step": 480
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.794482946395874,
      "learning_rate": 1.9927747309857816e-05,
      "loss": 0.5873,
      "step": 490
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.5070444345474243,
      "learning_rate": 1.9924771868540937e-05,
      "loss": 0.5775,
      "step": 500
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.6558611392974854,
      "learning_rate": 1.9921736622450755e-05,
      "loss": 0.5769,
      "step": 510
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9155470132827759,
      "learning_rate": 1.9918641589877087e-05,
      "loss": 0.5771,
      "step": 520
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4727964401245117,
      "learning_rate": 1.991548678947e-05,
      "loss": 0.6117,
      "step": 530
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.3177714347839355,
      "learning_rate": 1.9912272240239715e-05,
      "loss": 0.5843,
      "step": 540
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.5801219940185547,
      "learning_rate": 1.9908997961556498e-05,
      "loss": 0.6048,
      "step": 550
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.238816976547241,
      "learning_rate": 1.9905663973150516e-05,
      "loss": 0.5802,
      "step": 560
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0578434467315674,
      "learning_rate": 1.990227029511175e-05,
      "loss": 0.5482,
      "step": 570
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.0711476802825928,
      "learning_rate": 1.989881694788985e-05,
      "loss": 0.5849,
      "step": 580
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.848081111907959,
      "learning_rate": 1.9895303952294024e-05,
      "loss": 0.5732,
      "step": 590
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9633995294570923,
      "learning_rate": 1.9891731329492912e-05,
      "loss": 0.5815,
      "step": 600
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.72892427444458,
      "learning_rate": 1.988809910101446e-05,
      "loss": 0.5991,
      "step": 610
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2983996868133545,
      "learning_rate": 1.988440728874577e-05,
      "loss": 0.6265,
      "step": 620
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0397396087646484,
      "learning_rate": 1.9880655914933003e-05,
      "loss": 0.5729,
      "step": 630
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.4665707349777222,
      "learning_rate": 1.9876845002181217e-05,
      "loss": 0.5931,
      "step": 640
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9297963380813599,
      "learning_rate": 1.987297457345424e-05,
      "loss": 0.5649,
      "step": 650
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.885498285293579,
      "learning_rate": 1.9869044652074538e-05,
      "loss": 0.6015,
      "step": 660
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.1364998817443848,
      "learning_rate": 1.9865055261723058e-05,
      "loss": 0.5692,
      "step": 670
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.260935068130493,
      "learning_rate": 1.98610064264391e-05,
      "loss": 0.5797,
      "step": 680
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4450185298919678,
      "learning_rate": 1.9856898170620182e-05,
      "loss": 0.6135,
      "step": 690
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8632386922836304,
      "learning_rate": 1.9852730519021853e-05,
      "loss": 0.5829,
      "step": 700
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.464857816696167,
      "learning_rate": 1.984850349675759e-05,
      "loss": 0.5391,
      "step": 710
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1488757133483887,
      "learning_rate": 1.9844217129298616e-05,
      "loss": 0.583,
      "step": 720
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.707641363143921,
      "learning_rate": 1.9839871442473766e-05,
      "loss": 0.5716,
      "step": 730
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.3270108699798584,
      "learning_rate": 1.9835466462469307e-05,
      "loss": 0.5657,
      "step": 740
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8134204149246216,
      "learning_rate": 1.9831002215828812e-05,
      "loss": 0.5839,
      "step": 750
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.4957146644592285,
      "learning_rate": 1.982647872945297e-05,
      "loss": 0.5631,
      "step": 760
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.763030529022217,
      "learning_rate": 1.9821896030599448e-05,
      "loss": 0.5691,
      "step": 770
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.6974971294403076,
      "learning_rate": 1.9817254146882704e-05,
      "loss": 0.5554,
      "step": 780
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8545125722885132,
      "learning_rate": 1.9812553106273848e-05,
      "loss": 0.519,
      "step": 790
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.6831135749816895,
      "learning_rate": 1.9807792937100446e-05,
      "loss": 0.5449,
      "step": 800
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.137880563735962,
      "learning_rate": 1.9802973668046364e-05,
      "loss": 0.5791,
      "step": 810
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.788285255432129,
      "learning_rate": 1.9798095328151595e-05,
      "loss": 0.5837,
      "step": 820
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.089675426483154,
      "learning_rate": 1.9793157946812078e-05,
      "loss": 0.5553,
      "step": 830
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8916798830032349,
      "learning_rate": 1.9788161553779534e-05,
      "loss": 0.5498,
      "step": 840
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.2801363468170166,
      "learning_rate": 1.978310617916126e-05,
      "loss": 0.567,
      "step": 850
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8267335891723633,
      "learning_rate": 1.9777991853419984e-05,
      "loss": 0.5597,
      "step": 860
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.020909309387207,
      "learning_rate": 1.9772818607373642e-05,
      "loss": 0.5737,
      "step": 870
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.5630546808242798,
      "learning_rate": 1.9767586472195235e-05,
      "loss": 0.5821,
      "step": 880
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.108002185821533,
      "learning_rate": 1.97622954794126e-05,
      "loss": 0.5337,
      "step": 890
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.8416898250579834,
      "learning_rate": 1.975694566090825e-05,
      "loss": 0.5535,
      "step": 900
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.4489500522613525,
      "learning_rate": 1.9751537048919158e-05,
      "loss": 0.5539,
      "step": 910
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9632877111434937,
      "learning_rate": 1.974606967603659e-05,
      "loss": 0.5144,
      "step": 920
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5862624645233154,
      "learning_rate": 1.9740543575205888e-05,
      "loss": 0.5457,
      "step": 930
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.698899984359741,
      "learning_rate": 1.9734958779726274e-05,
      "loss": 0.5602,
      "step": 940
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.445810079574585,
      "learning_rate": 1.9729315323250655e-05,
      "loss": 0.5657,
      "step": 950
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.140651822090149,
      "learning_rate": 1.9723613239785416e-05,
      "loss": 0.5811,
      "step": 960
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.6852705478668213,
      "learning_rate": 1.9717852563690227e-05,
      "loss": 0.5572,
      "step": 970
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.4724926948547363,
      "learning_rate": 1.971203332967781e-05,
      "loss": 0.6275,
      "step": 980
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.643868088722229,
      "learning_rate": 1.970615557281376e-05,
      "loss": 0.5426,
      "step": 990
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.9498915672302246,
      "learning_rate": 1.9700219328516308e-05,
      "loss": 0.5342,
      "step": 1000
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1436902284622192,
      "learning_rate": 1.9694224632556125e-05,
      "loss": 0.532,
      "step": 1010
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.415999412536621,
      "learning_rate": 1.9688171521056105e-05,
      "loss": 0.5437,
      "step": 1020
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.407463550567627,
      "learning_rate": 1.9682060030491136e-05,
      "loss": 0.562,
      "step": 1030
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.9211225509643555,
      "learning_rate": 1.9675890197687886e-05,
      "loss": 0.5571,
      "step": 1040
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0730221271514893,
      "learning_rate": 1.966966205982459e-05,
      "loss": 0.557,
      "step": 1050
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0743625164031982,
      "learning_rate": 1.9663375654430808e-05,
      "loss": 0.5482,
      "step": 1060
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.028625965118408,
      "learning_rate": 1.9657031019387215e-05,
      "loss": 0.518,
      "step": 1070
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3771324157714844,
      "learning_rate": 1.9650628192925372e-05,
      "loss": 0.5353,
      "step": 1080
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.2266383171081543,
      "learning_rate": 1.9644167213627476e-05,
      "loss": 0.5398,
      "step": 1090
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.394151210784912,
      "learning_rate": 1.9637648120426155e-05,
      "loss": 0.4972,
      "step": 1100
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.730908155441284,
      "learning_rate": 1.9631070952604214e-05,
      "loss": 0.5561,
      "step": 1110
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.8700578212738037,
      "learning_rate": 1.9624435749794406e-05,
      "loss": 0.5614,
      "step": 1120
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9121567010879517,
      "learning_rate": 1.961774255197919e-05,
      "loss": 0.5419,
      "step": 1130
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.569247007369995,
      "learning_rate": 1.9610991399490497e-05,
      "loss": 0.524,
      "step": 1140
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.4781911373138428,
      "learning_rate": 1.9604182333009474e-05,
      "loss": 0.5803,
      "step": 1150
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.546515703201294,
      "learning_rate": 1.9597315393566253e-05,
      "loss": 0.5256,
      "step": 1160
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.7645106315612793,
      "learning_rate": 1.9590390622539696e-05,
      "loss": 0.5362,
      "step": 1170
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.673413872718811,
      "learning_rate": 1.9583408061657142e-05,
      "loss": 0.5167,
      "step": 1180
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.2470479011535645,
      "learning_rate": 1.957636775299417e-05,
      "loss": 0.5656,
      "step": 1190
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.6368906497955322,
      "learning_rate": 1.956926973897433e-05,
      "loss": 0.5856,
      "step": 1200
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.1887333393096924,
      "learning_rate": 1.9562114062368888e-05,
      "loss": 0.509,
      "step": 1210
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7698419094085693,
      "learning_rate": 1.955490076629659e-05,
      "loss": 0.5037,
      "step": 1220
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.8750003576278687,
      "learning_rate": 1.9547629894223367e-05,
      "loss": 0.5512,
      "step": 1230
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.615281820297241,
      "learning_rate": 1.9540301489962105e-05,
      "loss": 0.5515,
      "step": 1240
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7702155113220215,
      "learning_rate": 1.9532915597672358e-05,
      "loss": 0.5291,
      "step": 1250
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.559830904006958,
      "learning_rate": 1.9525472261860112e-05,
      "loss": 0.5572,
      "step": 1260
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.5765202045440674,
      "learning_rate": 1.951797152737746e-05,
      "loss": 0.5298,
      "step": 1270
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.277256965637207,
      "learning_rate": 1.951041343942241e-05,
      "loss": 0.5241,
      "step": 1280
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.3888310194015503,
      "learning_rate": 1.9502798043538547e-05,
      "loss": 0.5305,
      "step": 1290
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.141235828399658,
      "learning_rate": 1.9495125385614782e-05,
      "loss": 0.5625,
      "step": 1300
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.225802421569824,
      "learning_rate": 1.9487395511885085e-05,
      "loss": 0.5091,
      "step": 1310
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.3567192554473877,
      "learning_rate": 1.947960846892819e-05,
      "loss": 0.5053,
      "step": 1320
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.502020835876465,
      "learning_rate": 1.947176430366733e-05,
      "loss": 0.4907,
      "step": 1330
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9814784526824951,
      "learning_rate": 1.946386306336994e-05,
      "loss": 0.5563,
      "step": 1340
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.9590063095092773,
      "learning_rate": 1.945590479564738e-05,
      "loss": 0.4863,
      "step": 1350
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.4375131130218506,
      "learning_rate": 1.9447889548454647e-05,
      "loss": 0.5364,
      "step": 1360
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4020805358886719,
      "learning_rate": 1.943981737009008e-05,
      "loss": 0.5182,
      "step": 1370
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4028046131134033,
      "learning_rate": 1.9431688309195086e-05,
      "loss": 0.5133,
      "step": 1380
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.580069899559021,
      "learning_rate": 1.9423502414753823e-05,
      "loss": 0.5382,
      "step": 1390
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.8029708862304688,
      "learning_rate": 1.9415259736092924e-05,
      "loss": 0.5033,
      "step": 1400
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.184006452560425,
      "learning_rate": 1.940696032288119e-05,
      "loss": 0.5124,
      "step": 1410
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.173084020614624,
      "learning_rate": 1.9398604225129298e-05,
      "loss": 0.5231,
      "step": 1420
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1503710746765137,
      "learning_rate": 1.9390191493189482e-05,
      "loss": 0.5316,
      "step": 1430
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.428990125656128,
      "learning_rate": 1.9381722177755266e-05,
      "loss": 0.5208,
      "step": 1440
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.45125150680542,
      "learning_rate": 1.937319632986111e-05,
      "loss": 0.5369,
      "step": 1450
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.0960376262664795,
      "learning_rate": 1.9364614000882147e-05,
      "loss": 0.5359,
      "step": 1460
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.185685157775879,
      "learning_rate": 1.9355975242533845e-05,
      "loss": 0.5171,
      "step": 1470
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4332501888275146,
      "learning_rate": 1.9347280106871704e-05,
      "loss": 0.4842,
      "step": 1480
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.5055408477783203,
      "learning_rate": 1.9338528646290948e-05,
      "loss": 0.4899,
      "step": 1490
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.5619678497314453,
      "learning_rate": 1.9329720913526196e-05,
      "loss": 0.5191,
      "step": 1500
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.7504260540008545,
      "learning_rate": 1.932085696165117e-05,
      "loss": 0.5168,
      "step": 1510
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8793102502822876,
      "learning_rate": 1.9311936844078333e-05,
      "loss": 0.5121,
      "step": 1520
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.163628339767456,
      "learning_rate": 1.9302960614558604e-05,
      "loss": 0.5348,
      "step": 1530
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.467654228210449,
      "learning_rate": 1.929392832718103e-05,
      "loss": 0.5021,
      "step": 1540
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.6908395290374756,
      "learning_rate": 1.928484003637244e-05,
      "loss": 0.5105,
      "step": 1550
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.6350224018096924,
      "learning_rate": 1.927569579689713e-05,
      "loss": 0.5264,
      "step": 1560
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.8099987506866455,
      "learning_rate": 1.926649566385654e-05,
      "loss": 0.4929,
      "step": 1570
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.890320062637329,
      "learning_rate": 1.9257239692688907e-05,
      "loss": 0.5974,
      "step": 1580
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.4845755100250244,
      "learning_rate": 1.9247927939168932e-05,
      "loss": 0.5326,
      "step": 1590
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9992694854736328,
      "learning_rate": 1.9238560459407472e-05,
      "loss": 0.5067,
      "step": 1600
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8103529214859009,
      "learning_rate": 1.922913730985115e-05,
      "loss": 0.5265,
      "step": 1610
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.352590799331665,
      "learning_rate": 1.921965854728207e-05,
      "loss": 0.5063,
      "step": 1620
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.0298409461975098,
      "learning_rate": 1.921012422881743e-05,
      "loss": 0.544,
      "step": 1630
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.436116933822632,
      "learning_rate": 1.9200534411909212e-05,
      "loss": 0.5155,
      "step": 1640
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.960477113723755,
      "learning_rate": 1.9190889154343816e-05,
      "loss": 0.5221,
      "step": 1650
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.9489247798919678,
      "learning_rate": 1.918118851424171e-05,
      "loss": 0.5308,
      "step": 1660
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.062129020690918,
      "learning_rate": 1.9171432550057096e-05,
      "loss": 0.5274,
      "step": 1670
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.18656063079834,
      "learning_rate": 1.9161621320577543e-05,
      "loss": 0.4899,
      "step": 1680
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0934178829193115,
      "learning_rate": 1.915175488492364e-05,
      "loss": 0.5037,
      "step": 1690
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7396160364151,
      "learning_rate": 1.914183330254864e-05,
      "loss": 0.5233,
      "step": 1700
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.7661094665527344,
      "learning_rate": 1.9131856633238096e-05,
      "loss": 0.4855,
      "step": 1710
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.477996349334717,
      "learning_rate": 1.91218249371095e-05,
      "loss": 0.4859,
      "step": 1720
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.4600329399108887,
      "learning_rate": 1.9111738274611936e-05,
      "loss": 0.4886,
      "step": 1730
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.352226495742798,
      "learning_rate": 1.91015967065257e-05,
      "loss": 0.5373,
      "step": 1740
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.814729928970337,
      "learning_rate": 1.9091400293961935e-05,
      "loss": 0.4962,
      "step": 1750
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.053473472595215,
      "learning_rate": 1.9081149098362267e-05,
      "loss": 0.5382,
      "step": 1760
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.375554084777832,
      "learning_rate": 1.907084318149844e-05,
      "loss": 0.5348,
      "step": 1770
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.980591058731079,
      "learning_rate": 1.9060482605471936e-05,
      "loss": 0.5168,
      "step": 1780
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.070223808288574,
      "learning_rate": 1.9050067432713593e-05,
      "loss": 0.5187,
      "step": 1790
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.915954113006592,
      "learning_rate": 1.9039597725983254e-05,
      "loss": 0.5088,
      "step": 1800
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.3617308139801025,
      "learning_rate": 1.902907354836936e-05,
      "loss": 0.5056,
      "step": 1810
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.8337783813476562,
      "learning_rate": 1.901849496328859e-05,
      "loss": 0.4821,
      "step": 1820
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.1903128623962402,
      "learning_rate": 1.900786203448547e-05,
      "loss": 0.5251,
      "step": 1830
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.19681453704834,
      "learning_rate": 1.8997174826031992e-05,
      "loss": 0.4939,
      "step": 1840
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.602724313735962,
      "learning_rate": 1.8986433402327228e-05,
      "loss": 0.4686,
      "step": 1850
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8605190515518188,
      "learning_rate": 1.8975637828096936e-05,
      "loss": 0.4769,
      "step": 1860
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0534961223602295,
      "learning_rate": 1.8964788168393178e-05,
      "loss": 0.488,
      "step": 1870
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.2213735580444336,
      "learning_rate": 1.8953884488593925e-05,
      "loss": 0.4827,
      "step": 1880
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.210944414138794,
      "learning_rate": 1.894292685440266e-05,
      "loss": 0.5005,
      "step": 1890
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.647202730178833,
      "learning_rate": 1.8931915331847988e-05,
      "loss": 0.5124,
      "step": 1900
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.992995262145996,
      "learning_rate": 1.8920849987283237e-05,
      "loss": 0.4993,
      "step": 1910
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.276505947113037,
      "learning_rate": 1.890973088738605e-05,
      "loss": 0.491,
      "step": 1920
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.7235989570617676,
      "learning_rate": 1.8898558099157987e-05,
      "loss": 0.4734,
      "step": 1930
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6206918954849243,
      "learning_rate": 1.8887331689924137e-05,
      "loss": 0.4982,
      "step": 1940
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.3554394245147705,
      "learning_rate": 1.8876051727332684e-05,
      "loss": 0.5243,
      "step": 1950
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.2801318168640137,
      "learning_rate": 1.8864718279354527e-05,
      "loss": 0.4918,
      "step": 1960
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1159415245056152,
      "learning_rate": 1.8853331414282845e-05,
      "loss": 0.5124,
      "step": 1970
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9822361469268799,
      "learning_rate": 1.8841891200732706e-05,
      "loss": 0.5031,
      "step": 1980
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.966780424118042,
      "learning_rate": 1.8830397707640652e-05,
      "loss": 0.4998,
      "step": 1990
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.178546667098999,
      "learning_rate": 1.8818851004264265e-05,
      "loss": 0.5224,
      "step": 2000
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.8754944801330566,
      "learning_rate": 1.880725116018176e-05,
      "loss": 0.5008,
      "step": 2010
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8750978708267212,
      "learning_rate": 1.8795598245291588e-05,
      "loss": 0.5232,
      "step": 2020
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1154704093933105,
      "learning_rate": 1.878389232981197e-05,
      "loss": 0.4813,
      "step": 2030
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9692806005477905,
      "learning_rate": 1.8772133484280513e-05,
      "loss": 0.5121,
      "step": 2040
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5764169692993164,
      "learning_rate": 1.8760321779553767e-05,
      "loss": 0.4912,
      "step": 2050
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.6243109703063965,
      "learning_rate": 1.87484572868068e-05,
      "loss": 0.5017,
      "step": 2060
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.29773211479187,
      "learning_rate": 1.8736540077532773e-05,
      "loss": 0.5331,
      "step": 2070
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.5878783464431763,
      "learning_rate": 1.8724570223542503e-05,
      "loss": 0.5002,
      "step": 2080
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.3286514282226562,
      "learning_rate": 1.871254779696404e-05,
      "loss": 0.5015,
      "step": 2090
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.940979480743408,
      "learning_rate": 1.870047287024222e-05,
      "loss": 0.4929,
      "step": 2100
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.940338373184204,
      "learning_rate": 1.8688345516138237e-05,
      "loss": 0.4831,
      "step": 2110
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5981576442718506,
      "learning_rate": 1.8676165807729206e-05,
      "loss": 0.4701,
      "step": 2120
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.7420263290405273,
      "learning_rate": 1.8663933818407712e-05,
      "loss": 0.5044,
      "step": 2130
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1152398586273193,
      "learning_rate": 1.8651649621881378e-05,
      "loss": 0.5316,
      "step": 2140
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.096395969390869,
      "learning_rate": 1.8639313292172423e-05,
      "loss": 0.5498,
      "step": 2150
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.0350353717803955,
      "learning_rate": 1.86269249036172e-05,
      "loss": 0.5113,
      "step": 2160
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.1402790546417236,
      "learning_rate": 1.861448453086577e-05,
      "loss": 0.5151,
      "step": 2170
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.852443218231201,
      "learning_rate": 1.8601992248881428e-05,
      "loss": 0.5142,
      "step": 2180
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.651730537414551,
      "learning_rate": 1.858944813294028e-05,
      "loss": 0.4962,
      "step": 2190
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.054304599761963,
      "learning_rate": 1.8576852258630757e-05,
      "loss": 0.4654,
      "step": 2200
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.5107483863830566,
      "learning_rate": 1.856420470185319e-05,
      "loss": 0.5092,
      "step": 2210
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.464583396911621,
      "learning_rate": 1.8551505538819325e-05,
      "loss": 0.5347,
      "step": 2220
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.3778529167175293,
      "learning_rate": 1.853875484605189e-05,
      "loss": 0.5217,
      "step": 2230
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6776072978973389,
      "learning_rate": 1.8525952700384118e-05,
      "loss": 0.5131,
      "step": 2240
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.06449294090271,
      "learning_rate": 1.851309917895928e-05,
      "loss": 0.4997,
      "step": 2250
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0016419887542725,
      "learning_rate": 1.8500194359230234e-05,
      "loss": 0.4737,
      "step": 2260
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9955428838729858,
      "learning_rate": 1.8487238318958956e-05,
      "loss": 0.5035,
      "step": 2270
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.0285263061523438,
      "learning_rate": 1.8474231136216056e-05,
      "loss": 0.495,
      "step": 2280
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.130730390548706,
      "learning_rate": 1.8461172889380324e-05,
      "loss": 0.4983,
      "step": 2290
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.919367551803589,
      "learning_rate": 1.8448063657138256e-05,
      "loss": 0.4903,
      "step": 2300
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.8781673908233643,
      "learning_rate": 1.8434903518483575e-05,
      "loss": 0.5206,
      "step": 2310
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.3585431575775146,
      "learning_rate": 1.842169255271675e-05,
      "loss": 0.5069,
      "step": 2320
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.0952959060668945,
      "learning_rate": 1.8408430839444532e-05,
      "loss": 0.4889,
      "step": 2330
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.5002641677856445,
      "learning_rate": 1.839511845857946e-05,
      "loss": 0.491,
      "step": 2340
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.037515878677368,
      "learning_rate": 1.8381755490339395e-05,
      "loss": 0.4961,
      "step": 2350
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.9505791664123535,
      "learning_rate": 1.836834201524702e-05,
      "loss": 0.521,
      "step": 2360
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.4092655181884766,
      "learning_rate": 1.8354878114129368e-05,
      "loss": 0.4672,
      "step": 2370
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.176804304122925,
      "learning_rate": 1.834136386811732e-05,
      "loss": 0.4654,
      "step": 2380
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.484849452972412,
      "learning_rate": 1.832779935864514e-05,
      "loss": 0.5123,
      "step": 2390
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.3028125762939453,
      "learning_rate": 1.831418466744996e-05,
      "loss": 0.508,
      "step": 2400
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.428851366043091,
      "learning_rate": 1.8300519876571298e-05,
      "loss": 0.519,
      "step": 2410
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.644895076751709,
      "learning_rate": 1.8286805068350568e-05,
      "loss": 0.4542,
      "step": 2420
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.14337158203125,
      "learning_rate": 1.8273040325430575e-05,
      "loss": 0.485,
      "step": 2430
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.396541953086853,
      "learning_rate": 1.825922573075502e-05,
      "loss": 0.4509,
      "step": 2440
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9154225587844849,
      "learning_rate": 1.824536136756801e-05,
      "loss": 0.4886,
      "step": 2450
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7437492609024048,
      "learning_rate": 1.823144731941353e-05,
      "loss": 0.4983,
      "step": 2460
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.015225410461426,
      "learning_rate": 1.8217483670134975e-05,
      "loss": 0.4967,
      "step": 2470
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.52972674369812,
      "learning_rate": 1.820347050387462e-05,
      "loss": 0.4912,
      "step": 2480
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.217939853668213,
      "learning_rate": 1.8189407905073117e-05,
      "loss": 0.4648,
      "step": 2490
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.4952890872955322,
      "learning_rate": 1.817529595846899e-05,
      "loss": 0.4639,
      "step": 2500
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.6034467220306396,
      "learning_rate": 1.8161134749098125e-05,
      "loss": 0.4808,
      "step": 2510
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.3597192764282227,
      "learning_rate": 1.814692436229326e-05,
      "loss": 0.4564,
      "step": 2520
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.7161178588867188,
      "learning_rate": 1.813266488368346e-05,
      "loss": 0.4793,
      "step": 2530
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1550705432891846,
      "learning_rate": 1.811835639919361e-05,
      "loss": 0.482,
      "step": 2540
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7534992694854736,
      "learning_rate": 1.8103998995043897e-05,
      "loss": 0.47,
      "step": 2550
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.026285171508789,
      "learning_rate": 1.8089592757749286e-05,
      "loss": 0.4964,
      "step": 2560
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.356091856956482,
      "learning_rate": 1.8075137774119e-05,
      "loss": 0.5138,
      "step": 2570
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.179572343826294,
      "learning_rate": 1.8060634131256006e-05,
      "loss": 0.5132,
      "step": 2580
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.315096139907837,
      "learning_rate": 1.8046081916556468e-05,
      "loss": 0.4551,
      "step": 2590
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.0125863552093506,
      "learning_rate": 1.803148121770925e-05,
      "loss": 0.4839,
      "step": 2600
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.2748889923095703,
      "learning_rate": 1.801683212269536e-05,
      "loss": 0.4634,
      "step": 2610
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9733281135559082,
      "learning_rate": 1.8002134719787444e-05,
      "loss": 0.5225,
      "step": 2620
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.7353618144989014,
      "learning_rate": 1.7987389097549227e-05,
      "loss": 0.4908,
      "step": 2630
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8575961589813232,
      "learning_rate": 1.797259534483501e-05,
      "loss": 0.5166,
      "step": 2640
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.088693857192993,
      "learning_rate": 1.795775355078911e-05,
      "loss": 0.5263,
      "step": 2650
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.1390295028686523,
      "learning_rate": 1.7942863804845332e-05,
      "loss": 0.4487,
      "step": 2660
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.1855170726776123,
      "learning_rate": 1.792792619672643e-05,
      "loss": 0.5093,
      "step": 2670
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.8349621295928955,
      "learning_rate": 1.7912940816443574e-05,
      "loss": 0.4975,
      "step": 2680
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.3540406227111816,
      "learning_rate": 1.7897907754295785e-05,
      "loss": 0.4855,
      "step": 2690
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.157831192016602,
      "learning_rate": 1.788282710086942e-05,
      "loss": 0.4864,
      "step": 2700
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.753117799758911,
      "learning_rate": 1.786769894703761e-05,
      "loss": 0.5063,
      "step": 2710
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.8270668983459473,
      "learning_rate": 1.7852523383959705e-05,
      "loss": 0.4691,
      "step": 2720
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.8202004432678223,
      "learning_rate": 1.7837300503080738e-05,
      "loss": 0.5112,
      "step": 2730
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.7267329692840576,
      "learning_rate": 1.782203039613088e-05,
      "loss": 0.4971,
      "step": 2740
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.7259464263916016,
      "learning_rate": 1.7806713155124864e-05,
      "loss": 0.5237,
      "step": 2750
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.468626499176025,
      "learning_rate": 1.7791348872361446e-05,
      "loss": 0.513,
      "step": 2760
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.515953540802002,
      "learning_rate": 1.7775937640422856e-05,
      "loss": 0.467,
      "step": 2770
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.282536745071411,
      "learning_rate": 1.7760479552174222e-05,
      "loss": 0.4662,
      "step": 2780
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.091183662414551,
      "learning_rate": 1.7744974700763018e-05,
      "loss": 0.4779,
      "step": 2790
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.422262191772461,
      "learning_rate": 1.7729423179618513e-05,
      "loss": 0.49,
      "step": 2800
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5260729789733887,
      "learning_rate": 1.7713825082451185e-05,
      "loss": 0.446,
      "step": 2810
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.9121522903442383,
      "learning_rate": 1.769818050325219e-05,
      "loss": 0.5269,
      "step": 2820
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.12424898147583,
      "learning_rate": 1.7682489536292756e-05,
      "loss": 0.4905,
      "step": 2830
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.7411932945251465,
      "learning_rate": 1.766675227612364e-05,
      "loss": 0.4669,
      "step": 2840
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0233852863311768,
      "learning_rate": 1.7650968817574564e-05,
      "loss": 0.4783,
      "step": 2850
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9073272943496704,
      "learning_rate": 1.763513925575362e-05,
      "loss": 0.5631,
      "step": 2860
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.666140079498291,
      "learning_rate": 1.7619263686046717e-05,
      "loss": 0.4928,
      "step": 2870
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.1087937355041504,
      "learning_rate": 1.760334220411699e-05,
      "loss": 0.4839,
      "step": 2880
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.446394205093384,
      "learning_rate": 1.7587374905904244e-05,
      "loss": 0.5034,
      "step": 2890
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.529792308807373,
      "learning_rate": 1.757136188762435e-05,
      "loss": 0.4807,
      "step": 2900
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.6930389404296875,
      "learning_rate": 1.75553032457687e-05,
      "loss": 0.4556,
      "step": 2910
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8727943897247314,
      "learning_rate": 1.7539199077103583e-05,
      "loss": 0.4873,
      "step": 2920
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.82974112033844,
      "learning_rate": 1.7523049478669634e-05,
      "loss": 0.4647,
      "step": 2930
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.472196578979492,
      "learning_rate": 1.750685454778124e-05,
      "loss": 0.508,
      "step": 2940
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.713311791419983,
      "learning_rate": 1.7490614382025954e-05,
      "loss": 0.4878,
      "step": 2950
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.0454039573669434,
      "learning_rate": 1.7474329079263896e-05,
      "loss": 0.4827,
      "step": 2960
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.6182243824005127,
      "learning_rate": 1.7457998737627183e-05,
      "loss": 0.4756,
      "step": 2970
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.093231439590454,
      "learning_rate": 1.7441623455519322e-05,
      "loss": 0.4797,
      "step": 2980
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.0410704612731934,
      "learning_rate": 1.7425203331614627e-05,
      "loss": 0.4716,
      "step": 2990
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.544192314147949,
      "learning_rate": 1.7408738464857623e-05,
      "loss": 0.468,
      "step": 3000
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.077234983444214,
      "learning_rate": 1.739222895446243e-05,
      "loss": 0.444,
      "step": 3010
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.5196938514709473,
      "learning_rate": 1.7375674899912204e-05,
      "loss": 0.4358,
      "step": 3020
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.0311315059661865,
      "learning_rate": 1.73590764009585e-05,
      "loss": 0.4853,
      "step": 3030
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.7378640174865723,
      "learning_rate": 1.7342433557620694e-05,
      "loss": 0.5166,
      "step": 3040
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.578019380569458,
      "learning_rate": 1.732574647018537e-05,
      "loss": 0.473,
      "step": 3050
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.012407064437866,
      "learning_rate": 1.7309015239205717e-05,
      "loss": 0.4861,
      "step": 3060
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.15518856048584,
      "learning_rate": 1.729223996550093e-05,
      "loss": 0.5076,
      "step": 3070
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.394876003265381,
      "learning_rate": 1.7275420750155592e-05,
      "loss": 0.4704,
      "step": 3080
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.755171537399292,
      "learning_rate": 1.725855769451907e-05,
      "loss": 0.4908,
      "step": 3090
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.0949244499206543,
      "learning_rate": 1.724165090020491e-05,
      "loss": 0.465,
      "step": 3100
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.279771089553833,
      "learning_rate": 1.722470046909021e-05,
      "loss": 0.4848,
      "step": 3110
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.4277713298797607,
      "learning_rate": 1.720770650331502e-05,
      "loss": 0.4825,
      "step": 3120
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9526821374893188,
      "learning_rate": 1.719066910528172e-05,
      "loss": 0.4799,
      "step": 3130
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.9937903881073,
      "learning_rate": 1.7173588377654408e-05,
      "loss": 0.4658,
      "step": 3140
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4448838233947754,
      "learning_rate": 1.7156464423358277e-05,
      "loss": 0.4819,
      "step": 3150
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.660029411315918,
      "learning_rate": 1.7139297345578992e-05,
      "loss": 0.528,
      "step": 3160
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.2981364727020264,
      "learning_rate": 1.712208724776207e-05,
      "loss": 0.4657,
      "step": 3170
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.916989803314209,
      "learning_rate": 1.7104834233612272e-05,
      "loss": 0.474,
      "step": 3180
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.4541797637939453,
      "learning_rate": 1.7087538407092944e-05,
      "loss": 0.4438,
      "step": 3190
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.0017354488372803,
      "learning_rate": 1.707019987242543e-05,
      "loss": 0.462,
      "step": 3200
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.514940023422241,
      "learning_rate": 1.705281873408841e-05,
      "loss": 0.4826,
      "step": 3210
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.8467180728912354,
      "learning_rate": 1.70353950968173e-05,
      "loss": 0.5,
      "step": 3220
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.096592903137207,
      "learning_rate": 1.7017929065603597e-05,
      "loss": 0.5445,
      "step": 3230
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.160984992980957,
      "learning_rate": 1.7000420745694256e-05,
      "loss": 0.424,
      "step": 3240
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.077068328857422,
      "learning_rate": 1.6982870242591057e-05,
      "loss": 0.4638,
      "step": 3250
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.391653060913086,
      "learning_rate": 1.696527766204997e-05,
      "loss": 0.4393,
      "step": 3260
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.522747278213501,
      "learning_rate": 1.6947643110080515e-05,
      "loss": 0.491,
      "step": 3270
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7182343006134033,
      "learning_rate": 1.692996669294512e-05,
      "loss": 0.4484,
      "step": 3280
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.6892387866973877,
      "learning_rate": 1.691224851715849e-05,
      "loss": 0.4715,
      "step": 3290
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.6838314533233643,
      "learning_rate": 1.689448868948695e-05,
      "loss": 0.4612,
      "step": 3300
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0835587978363037,
      "learning_rate": 1.6876687316947825e-05,
      "loss": 0.4677,
      "step": 3310
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.616152286529541,
      "learning_rate": 1.6858844506808776e-05,
      "loss": 0.4622,
      "step": 3320
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.5448880195617676,
      "learning_rate": 1.6840960366587153e-05,
      "loss": 0.4581,
      "step": 3330
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3255362510681152,
      "learning_rate": 1.6823035004049357e-05,
      "loss": 0.4959,
      "step": 3340
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.2266805171966553,
      "learning_rate": 1.680506852721019e-05,
      "loss": 0.483,
      "step": 3350
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.8242974281311035,
      "learning_rate": 1.67870610443322e-05,
      "loss": 0.4897,
      "step": 3360
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.296501398086548,
      "learning_rate": 1.6769012663925025e-05,
      "loss": 0.4626,
      "step": 3370
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.438009262084961,
      "learning_rate": 1.6750923494744747e-05,
      "loss": 0.4387,
      "step": 3380
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.764375925064087,
      "learning_rate": 1.673279364579323e-05,
      "loss": 0.5074,
      "step": 3390
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.018332004547119,
      "learning_rate": 1.6714623226317473e-05,
      "loss": 0.468,
      "step": 3400
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.0587778091430664,
      "learning_rate": 1.6696412345808947e-05,
      "loss": 0.4458,
      "step": 3410
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.2961912155151367,
      "learning_rate": 1.6678161114002916e-05,
      "loss": 0.4712,
      "step": 3420
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.4862515926361084,
      "learning_rate": 1.665986964087781e-05,
      "loss": 0.4533,
      "step": 3430
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4103015661239624,
      "learning_rate": 1.6641538036654548e-05,
      "loss": 0.4691,
      "step": 3440
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.2813827991485596,
      "learning_rate": 1.6623166411795852e-05,
      "loss": 0.457,
      "step": 3450
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.151137590408325,
      "learning_rate": 1.6604754877005623e-05,
      "loss": 0.4496,
      "step": 3460
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.177947521209717,
      "learning_rate": 1.6586303543228235e-05,
      "loss": 0.4561,
      "step": 3470
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0170304775238037,
      "learning_rate": 1.6567812521647894e-05,
      "loss": 0.4595,
      "step": 3480
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.2595248222351074,
      "learning_rate": 1.6549281923687944e-05,
      "loss": 0.4498,
      "step": 3490
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.1031296253204346,
      "learning_rate": 1.6530711861010225e-05,
      "loss": 0.4484,
      "step": 3500
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.973015546798706,
      "learning_rate": 1.6512102445514376e-05,
      "loss": 0.4486,
      "step": 3510
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.192896842956543,
      "learning_rate": 1.6493453789337165e-05,
      "loss": 0.4491,
      "step": 3520
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.724787950515747,
      "learning_rate": 1.647476600485182e-05,
      "loss": 0.4406,
      "step": 3530
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.369314670562744,
      "learning_rate": 1.6456039204667348e-05,
      "loss": 0.4404,
      "step": 3540
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0550458431243896,
      "learning_rate": 1.6437273501627865e-05,
      "loss": 0.4735,
      "step": 3550
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.376682996749878,
      "learning_rate": 1.6418469008811898e-05,
      "loss": 0.4815,
      "step": 3560
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.4055840969085693,
      "learning_rate": 1.639962583953171e-05,
      "loss": 0.4463,
      "step": 3570
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.671496629714966,
      "learning_rate": 1.638074410733264e-05,
      "loss": 0.4591,
      "step": 3580
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.180485486984253,
      "learning_rate": 1.636182392599238e-05,
      "loss": 0.4379,
      "step": 3590
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.298498630523682,
      "learning_rate": 1.6342865409520318e-05,
      "loss": 0.4527,
      "step": 3600
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.222804069519043,
      "learning_rate": 1.6323868672156836e-05,
      "loss": 0.4725,
      "step": 3610
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.4014933109283447,
      "learning_rate": 1.6304833828372646e-05,
      "loss": 0.4536,
      "step": 3620
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.0839030742645264,
      "learning_rate": 1.6285760992868056e-05,
      "loss": 0.486,
      "step": 3630
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.006422758102417,
      "learning_rate": 1.6266650280572326e-05,
      "loss": 0.4555,
      "step": 3640
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.129288673400879,
      "learning_rate": 1.6247501806642943e-05,
      "loss": 0.5041,
      "step": 3650
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.0200536251068115,
      "learning_rate": 1.6228315686464936e-05,
      "loss": 0.4621,
      "step": 3660
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.8396646976470947,
      "learning_rate": 1.62090920356502e-05,
      "loss": 0.4639,
      "step": 3670
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.169480323791504,
      "learning_rate": 1.618983097003676e-05,
      "loss": 0.4271,
      "step": 3680
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.150608539581299,
      "learning_rate": 1.6170532605688115e-05,
      "loss": 0.4576,
      "step": 3690
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.321418285369873,
      "learning_rate": 1.61511970588925e-05,
      "loss": 0.4534,
      "step": 3700
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.142306089401245,
      "learning_rate": 1.6131824446162224e-05,
      "loss": 0.4534,
      "step": 3710
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.610689401626587,
      "learning_rate": 1.6112414884232934e-05,
      "loss": 0.4917,
      "step": 3720
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.37821102142334,
      "learning_rate": 1.6092968490062932e-05,
      "loss": 0.4652,
      "step": 3730
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.4633255004882812,
      "learning_rate": 1.607348538083246e-05,
      "loss": 0.4137,
      "step": 3740
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9766350984573364,
      "learning_rate": 1.6053965673943005e-05,
      "loss": 0.4598,
      "step": 3750
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.868599534034729,
      "learning_rate": 1.6034409487016577e-05,
      "loss": 0.4989,
      "step": 3760
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1539952754974365,
      "learning_rate": 1.6014816937895007e-05,
      "loss": 0.4502,
      "step": 3770
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.1292502880096436,
      "learning_rate": 1.599518814463925e-05,
      "loss": 0.4412,
      "step": 3780
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0141892433166504,
      "learning_rate": 1.5975523225528647e-05,
      "loss": 0.483,
      "step": 3790
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.2689037322998047,
      "learning_rate": 1.5955822299060236e-05,
      "loss": 0.4518,
      "step": 3800
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.707918643951416,
      "learning_rate": 1.593608548394802e-05,
      "loss": 0.4741,
      "step": 3810
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2370872497558594,
      "learning_rate": 1.5916312899122263e-05,
      "loss": 0.4485,
      "step": 3820
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9027130603790283,
      "learning_rate": 1.5896504663728777e-05,
      "loss": 0.4473,
      "step": 3830
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2125988006591797,
      "learning_rate": 1.5876660897128187e-05,
      "loss": 0.4713,
      "step": 3840
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.888824939727783,
      "learning_rate": 1.5856781718895238e-05,
      "loss": 0.4713,
      "step": 3850
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.8174667358398438,
      "learning_rate": 1.5836867248818036e-05,
      "loss": 0.4182,
      "step": 3860
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.8198819160461426,
      "learning_rate": 1.581691760689737e-05,
      "loss": 0.4695,
      "step": 3870
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.07810115814209,
      "learning_rate": 1.5796932913345953e-05,
      "loss": 0.4446,
      "step": 3880
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.2914459705352783,
      "learning_rate": 1.577691328858772e-05,
      "loss": 0.4598,
      "step": 3890
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.147977828979492,
      "learning_rate": 1.5756858853257098e-05,
      "loss": 0.4681,
      "step": 3900
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.1310532093048096,
      "learning_rate": 1.5736769728198263e-05,
      "loss": 0.4946,
      "step": 3910
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.0360231399536133,
      "learning_rate": 1.5716646034464443e-05,
      "loss": 0.4302,
      "step": 3920
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.9941413402557373,
      "learning_rate": 1.569648789331715e-05,
      "loss": 0.4508,
      "step": 3930
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.4243319034576416,
      "learning_rate": 1.567629542622549e-05,
      "loss": 0.439,
      "step": 3940
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8827636241912842,
      "learning_rate": 1.5656068754865388e-05,
      "loss": 0.4301,
      "step": 3950
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.669173002243042,
      "learning_rate": 1.56358080011189e-05,
      "loss": 0.4923,
      "step": 3960
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.703911781311035,
      "learning_rate": 1.5615513287073434e-05,
      "loss": 0.4568,
      "step": 3970
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.6688580513000488,
      "learning_rate": 1.5595184735021055e-05,
      "loss": 0.4715,
      "step": 3980
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.583540678024292,
      "learning_rate": 1.5574822467457723e-05,
      "loss": 0.4737,
      "step": 3990
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.377573013305664,
      "learning_rate": 1.555442660708256e-05,
      "loss": 0.4875,
      "step": 4000
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9603444337844849,
      "learning_rate": 1.553399727679711e-05,
      "loss": 0.4674,
      "step": 4010
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.5341259241104126,
      "learning_rate": 1.5513534599704598e-05,
      "loss": 0.4864,
      "step": 4020
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.2202489376068115,
      "learning_rate": 1.54930386991092e-05,
      "loss": 0.4187,
      "step": 4030
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.872253656387329,
      "learning_rate": 1.5472509698515284e-05,
      "loss": 0.4751,
      "step": 4040
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.4582576751708984,
      "learning_rate": 1.5451947721626676e-05,
      "loss": 0.4287,
      "step": 4050
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.2667319774627686,
      "learning_rate": 1.5431352892345905e-05,
      "loss": 0.4876,
      "step": 4060
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.4830074310302734,
      "learning_rate": 1.541072533477347e-05,
      "loss": 0.4285,
      "step": 4070
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.4203689098358154,
      "learning_rate": 1.5390065173207068e-05,
      "loss": 0.4732,
      "step": 4080
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.5850695371627808,
      "learning_rate": 1.536937253214089e-05,
      "loss": 0.4259,
      "step": 4090
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1941845417022705,
      "learning_rate": 1.5348647536264808e-05,
      "loss": 0.4652,
      "step": 4100
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.262115478515625,
      "learning_rate": 1.532789031046369e-05,
      "loss": 0.4268,
      "step": 4110
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0387816429138184,
      "learning_rate": 1.5307100979816595e-05,
      "loss": 0.4498,
      "step": 4120
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.087073564529419,
      "learning_rate": 1.5286279669596047e-05,
      "loss": 0.4751,
      "step": 4130
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2675862312316895,
      "learning_rate": 1.5265426505267265e-05,
      "loss": 0.4309,
      "step": 4140
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.8600497245788574,
      "learning_rate": 1.5244541612487429e-05,
      "loss": 0.4943,
      "step": 4150
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.6693005561828613,
      "learning_rate": 1.5223625117104898e-05,
      "loss": 0.4676,
      "step": 4160
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0226101875305176,
      "learning_rate": 1.5202677145158462e-05,
      "loss": 0.4566,
      "step": 4170
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5214416980743408,
      "learning_rate": 1.5181697822876587e-05,
      "loss": 0.5008,
      "step": 4180
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.775106430053711,
      "learning_rate": 1.5160687276676651e-05,
      "loss": 0.4652,
      "step": 4190
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.743366003036499,
      "learning_rate": 1.5139645633164177e-05,
      "loss": 0.4636,
      "step": 4200
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.2428972721099854,
      "learning_rate": 1.5118573019132074e-05,
      "loss": 0.407,
      "step": 4210
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.2355058193206787,
      "learning_rate": 1.509746956155988e-05,
      "loss": 0.471,
      "step": 4220
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.0203590393066406,
      "learning_rate": 1.5076335387612987e-05,
      "loss": 0.4481,
      "step": 4230
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7567495107650757,
      "learning_rate": 1.5055170624641871e-05,
      "loss": 0.4768,
      "step": 4240
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1486988067626953,
      "learning_rate": 1.5033975400181345e-05,
      "loss": 0.4246,
      "step": 4250
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.7988100051879883,
      "learning_rate": 1.501274984194976e-05,
      "loss": 0.4565,
      "step": 4260
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.9524941444396973,
      "learning_rate": 1.499149407784827e-05,
      "loss": 0.449,
      "step": 4270
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.853801965713501,
      "learning_rate": 1.4970208235960036e-05,
      "loss": 0.4143,
      "step": 4280
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.591519355773926,
      "learning_rate": 1.4948892444549459e-05,
      "loss": 0.4242,
      "step": 4290
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.811940312385559,
      "learning_rate": 1.4927546832061418e-05,
      "loss": 0.4611,
      "step": 4300
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.060084104537964,
      "learning_rate": 1.4906171527120472e-05,
      "loss": 0.4178,
      "step": 4310
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.4617133140563965,
      "learning_rate": 1.4884766658530126e-05,
      "loss": 0.4563,
      "step": 4320
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.4319794178009033,
      "learning_rate": 1.4863332355272006e-05,
      "loss": 0.4311,
      "step": 4330
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.305912971496582,
      "learning_rate": 1.4841868746505122e-05,
      "loss": 0.4241,
      "step": 4340
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.5800302028656006,
      "learning_rate": 1.482037596156506e-05,
      "loss": 0.4459,
      "step": 4350
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.3404815196990967,
      "learning_rate": 1.4798854129963232e-05,
      "loss": 0.4269,
      "step": 4360
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.373990058898926,
      "learning_rate": 1.4777303381386068e-05,
      "loss": 0.4075,
      "step": 4370
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.8302773237228394,
      "learning_rate": 1.4755723845694245e-05,
      "loss": 0.4079,
      "step": 4380
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.9683265686035156,
      "learning_rate": 1.4734115652921911e-05,
      "loss": 0.4552,
      "step": 4390
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.3729939460754395,
      "learning_rate": 1.4712478933275897e-05,
      "loss": 0.4308,
      "step": 4400
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.5576722621917725,
      "learning_rate": 1.469081381713493e-05,
      "loss": 0.4879,
      "step": 4410
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.370612382888794,
      "learning_rate": 1.4669120435048845e-05,
      "loss": 0.4025,
      "step": 4420
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.757566452026367,
      "learning_rate": 1.4647398917737807e-05,
      "loss": 0.436,
      "step": 4430
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.5821995735168457,
      "learning_rate": 1.4625649396091512e-05,
      "loss": 0.4278,
      "step": 4440
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.2058565616607666,
      "learning_rate": 1.4603872001168415e-05,
      "loss": 0.449,
      "step": 4450
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.282240867614746,
      "learning_rate": 1.4582066864194927e-05,
      "loss": 0.4291,
      "step": 4460
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.515690803527832,
      "learning_rate": 1.4560234116564613e-05,
      "loss": 0.424,
      "step": 4470
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.906923294067383,
      "learning_rate": 1.4538373889837438e-05,
      "loss": 0.4259,
      "step": 4480
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.676865339279175,
      "learning_rate": 1.4516486315738933e-05,
      "loss": 0.4328,
      "step": 4490
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.66235089302063,
      "learning_rate": 1.4494571526159427e-05,
      "loss": 0.4322,
      "step": 4500
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.347494125366211,
      "learning_rate": 1.447262965315324e-05,
      "loss": 0.4033,
      "step": 4510
    },
    {
      "epoch": 1.06,
      "grad_norm": 3.974865198135376,
      "learning_rate": 1.4450660828937897e-05,
      "loss": 0.4162,
      "step": 4520
    },
    {
      "epoch": 1.06,
      "grad_norm": 3.059905529022217,
      "learning_rate": 1.442866518589332e-05,
      "loss": 0.4539,
      "step": 4530
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.590257167816162,
      "learning_rate": 1.440664285656104e-05,
      "loss": 0.4762,
      "step": 4540
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.7257919311523438,
      "learning_rate": 1.4384593973643392e-05,
      "loss": 0.4392,
      "step": 4550
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.834902763366699,
      "learning_rate": 1.436251867000272e-05,
      "loss": 0.4048,
      "step": 4560
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.1755754947662354,
      "learning_rate": 1.4340417078660578e-05,
      "loss": 0.4168,
      "step": 4570
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.832585573196411,
      "learning_rate": 1.4318289332796914e-05,
      "loss": 0.435,
      "step": 4580
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.9887373447418213,
      "learning_rate": 1.429613556574928e-05,
      "loss": 0.4201,
      "step": 4590
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.4929513931274414,
      "learning_rate": 1.427395591101204e-05,
      "loss": 0.434,
      "step": 4600
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.4753077030181885,
      "learning_rate": 1.4251750502235538e-05,
      "loss": 0.4781,
      "step": 4610
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.117757797241211,
      "learning_rate": 1.422951947322531e-05,
      "loss": 0.4326,
      "step": 4620
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.5945711135864258,
      "learning_rate": 1.4207262957941281e-05,
      "loss": 0.4288,
      "step": 4630
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.5918598175048828,
      "learning_rate": 1.4184981090496948e-05,
      "loss": 0.4174,
      "step": 4640
    },
    {
      "epoch": 1.09,
      "grad_norm": 3.289409875869751,
      "learning_rate": 1.416267400515857e-05,
      "loss": 0.4502,
      "step": 4650
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.6366932392120361,
      "learning_rate": 1.4140341836344367e-05,
      "loss": 0.4236,
      "step": 4660
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.681007742881775,
      "learning_rate": 1.4117984718623714e-05,
      "loss": 0.447,
      "step": 4670
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.3204216957092285,
      "learning_rate": 1.4095602786716312e-05,
      "loss": 0.4696,
      "step": 4680
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.6966910362243652,
      "learning_rate": 1.40731961754914e-05,
      "loss": 0.4133,
      "step": 4690
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.356372117996216,
      "learning_rate": 1.4050765019966917e-05,
      "loss": 0.3972,
      "step": 4700
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.413633346557617,
      "learning_rate": 1.4028309455308709e-05,
      "loss": 0.4009,
      "step": 4710
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.2007155418395996,
      "learning_rate": 1.4005829616829707e-05,
      "loss": 0.4061,
      "step": 4720
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.32854962348938,
      "learning_rate": 1.3983325639989112e-05,
      "loss": 0.4047,
      "step": 4730
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.0520002841949463,
      "learning_rate": 1.396079766039157e-05,
      "loss": 0.4581,
      "step": 4740
    },
    {
      "epoch": 1.11,
      "grad_norm": 3.265137195587158,
      "learning_rate": 1.3938245813786373e-05,
      "loss": 0.4233,
      "step": 4750
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.441016912460327,
      "learning_rate": 1.3915670236066625e-05,
      "loss": 0.4433,
      "step": 4760
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.5413093566894531,
      "learning_rate": 1.3893071063268431e-05,
      "loss": 0.4202,
      "step": 4770
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.89445161819458,
      "learning_rate": 1.3870448431570076e-05,
      "loss": 0.4064,
      "step": 4780
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.1020166873931885,
      "learning_rate": 1.38478024772912e-05,
      "loss": 0.4467,
      "step": 4790
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.1119372844696045,
      "learning_rate": 1.3825133336891989e-05,
      "loss": 0.4083,
      "step": 4800
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.6693994998931885,
      "learning_rate": 1.3802441146972338e-05,
      "loss": 0.4492,
      "step": 4810
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.618929862976074,
      "learning_rate": 1.3779726044271033e-05,
      "loss": 0.3887,
      "step": 4820
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.491731643676758,
      "learning_rate": 1.3756988165664931e-05,
      "loss": 0.4164,
      "step": 4830
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.61529278755188,
      "learning_rate": 1.3734227648168126e-05,
      "loss": 0.4401,
      "step": 4840
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.7799088954925537,
      "learning_rate": 1.3711444628931141e-05,
      "loss": 0.4258,
      "step": 4850
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.9384407997131348,
      "learning_rate": 1.3688639245240078e-05,
      "loss": 0.4579,
      "step": 4860
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.2434699535369873,
      "learning_rate": 1.3665811634515817e-05,
      "loss": 0.4599,
      "step": 4870
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.8414459228515625,
      "learning_rate": 1.3642961934313156e-05,
      "loss": 0.4386,
      "step": 4880
    },
    {
      "epoch": 1.15,
      "grad_norm": 2.1854021549224854,
      "learning_rate": 1.3620090282320018e-05,
      "loss": 0.4074,
      "step": 4890
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.8143315315246582,
      "learning_rate": 1.3597196816356588e-05,
      "loss": 0.445,
      "step": 4900
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.8751424551010132,
      "learning_rate": 1.3574281674374508e-05,
      "loss": 0.4341,
      "step": 4910
    },
    {
      "epoch": 1.15,
      "grad_norm": 2.7143642902374268,
      "learning_rate": 1.3551344994456035e-05,
      "loss": 0.4413,
      "step": 4920
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.5385000705718994,
      "learning_rate": 1.3528386914813199e-05,
      "loss": 0.4208,
      "step": 4930
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.1046688556671143,
      "learning_rate": 1.3505407573786995e-05,
      "loss": 0.4298,
      "step": 4940
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.9788825511932373,
      "learning_rate": 1.3482407109846527e-05,
      "loss": 0.4256,
      "step": 4950
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.652227759361267,
      "learning_rate": 1.3459385661588178e-05,
      "loss": 0.4931,
      "step": 4960
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.162010431289673,
      "learning_rate": 1.3436343367734788e-05,
      "loss": 0.4841,
      "step": 4970
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.74999737739563,
      "learning_rate": 1.3413280367134802e-05,
      "loss": 0.4517,
      "step": 4980
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.4762423038482666,
      "learning_rate": 1.3390196798761446e-05,
      "loss": 0.3955,
      "step": 4990
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.5805261135101318,
      "learning_rate": 1.3367092801711874e-05,
      "loss": 0.4394,
      "step": 5000
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.1573379039764404,
      "learning_rate": 1.3343968515206349e-05,
      "loss": 0.4064,
      "step": 5010
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.7383923530578613,
      "learning_rate": 1.3320824078587387e-05,
      "loss": 0.4177,
      "step": 5020
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.563737630844116,
      "learning_rate": 1.3297659631318927e-05,
      "loss": 0.446,
      "step": 5030
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.324249505996704,
      "learning_rate": 1.327447531298549e-05,
      "loss": 0.4141,
      "step": 5040
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.1390395164489746,
      "learning_rate": 1.3251271263291337e-05,
      "loss": 0.4419,
      "step": 5050
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.9619773626327515,
      "learning_rate": 1.3228047622059624e-05,
      "loss": 0.418,
      "step": 5060
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.439617395401001,
      "learning_rate": 1.320480452923156e-05,
      "loss": 0.4371,
      "step": 5070
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.839247465133667,
      "learning_rate": 1.3181542124865568e-05,
      "loss": 0.4255,
      "step": 5080
    },
    {
      "epoch": 1.19,
      "grad_norm": 3.40177059173584,
      "learning_rate": 1.3158260549136443e-05,
      "loss": 0.4133,
      "step": 5090
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.3637773990631104,
      "learning_rate": 1.3134959942334496e-05,
      "loss": 0.4261,
      "step": 5100
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.6658875942230225,
      "learning_rate": 1.3111640444864719e-05,
      "loss": 0.4335,
      "step": 5110
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.6530418395996094,
      "learning_rate": 1.3088302197245935e-05,
      "loss": 0.4915,
      "step": 5120
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.477799654006958,
      "learning_rate": 1.306494534010995e-05,
      "loss": 0.4317,
      "step": 5130
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.11491322517395,
      "learning_rate": 1.304157001420071e-05,
      "loss": 0.394,
      "step": 5140
    },
    {
      "epoch": 1.21,
      "grad_norm": 3.0485496520996094,
      "learning_rate": 1.3018176360373448e-05,
      "loss": 0.4155,
      "step": 5150
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.4527862071990967,
      "learning_rate": 1.2994764519593841e-05,
      "loss": 0.4293,
      "step": 5160
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.451565742492676,
      "learning_rate": 1.2971334632937156e-05,
      "loss": 0.4182,
      "step": 5170
    },
    {
      "epoch": 1.21,
      "grad_norm": 3.2280147075653076,
      "learning_rate": 1.2947886841587396e-05,
      "loss": 0.4072,
      "step": 5180
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.091986656188965,
      "learning_rate": 1.292442128683646e-05,
      "loss": 0.4796,
      "step": 5190
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.4201247692108154,
      "learning_rate": 1.2900938110083284e-05,
      "loss": 0.4325,
      "step": 5200
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.1002941131591797,
      "learning_rate": 1.287743745283299e-05,
      "loss": 0.4264,
      "step": 5210
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.687570095062256,
      "learning_rate": 1.2853919456696038e-05,
      "loss": 0.4292,
      "step": 5220
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.6394386291503906,
      "learning_rate": 1.2830384263387366e-05,
      "loss": 0.4351,
      "step": 5230
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.419731378555298,
      "learning_rate": 1.280683201472553e-05,
      "loss": 0.4339,
      "step": 5240
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.701406240463257,
      "learning_rate": 1.2783262852631875e-05,
      "loss": 0.4522,
      "step": 5250
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.1063625812530518,
      "learning_rate": 1.2759676919129653e-05,
      "loss": 0.3914,
      "step": 5260
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.7429099082946777,
      "learning_rate": 1.2736074356343182e-05,
      "loss": 0.4161,
      "step": 5270
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.3532073497772217,
      "learning_rate": 1.2712455306496976e-05,
      "loss": 0.4037,
      "step": 5280
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.3398191928863525,
      "learning_rate": 1.2688819911914909e-05,
      "loss": 0.3977,
      "step": 5290
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.501803398132324,
      "learning_rate": 1.2665168315019333e-05,
      "loss": 0.432,
      "step": 5300
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.7454497814178467,
      "learning_rate": 1.2641500658330248e-05,
      "loss": 0.4175,
      "step": 5310
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.443138360977173,
      "learning_rate": 1.261781708446441e-05,
      "loss": 0.4298,
      "step": 5320
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.880220651626587,
      "learning_rate": 1.2594117736134495e-05,
      "loss": 0.4573,
      "step": 5330
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.21376633644104,
      "learning_rate": 1.257040275614824e-05,
      "loss": 0.4045,
      "step": 5340
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.0075647830963135,
      "learning_rate": 1.2546672287407562e-05,
      "loss": 0.4111,
      "step": 5350
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.3312268257141113,
      "learning_rate": 1.2522926472907728e-05,
      "loss": 0.4001,
      "step": 5360
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.0677871704101562,
      "learning_rate": 1.249916545573646e-05,
      "loss": 0.4163,
      "step": 5370
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.924070119857788,
      "learning_rate": 1.2475389379073094e-05,
      "loss": 0.4329,
      "step": 5380
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.0825111865997314,
      "learning_rate": 1.2451598386187715e-05,
      "loss": 0.4421,
      "step": 5390
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.2827155590057373,
      "learning_rate": 1.242779262044028e-05,
      "loss": 0.4183,
      "step": 5400
    },
    {
      "epoch": 1.27,
      "grad_norm": 3.721651792526245,
      "learning_rate": 1.2403972225279776e-05,
      "loss": 0.4215,
      "step": 5410
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.9887990951538086,
      "learning_rate": 1.2380137344243338e-05,
      "loss": 0.4299,
      "step": 5420
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.2731363773345947,
      "learning_rate": 1.2356288120955391e-05,
      "loss": 0.4138,
      "step": 5430
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.7345799207687378,
      "learning_rate": 1.2332424699126786e-05,
      "loss": 0.4436,
      "step": 5440
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.3161239624023438,
      "learning_rate": 1.2308547222553929e-05,
      "loss": 0.4293,
      "step": 5450
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.057363510131836,
      "learning_rate": 1.2284655835117917e-05,
      "loss": 0.4214,
      "step": 5460
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.1399004459381104,
      "learning_rate": 1.2260750680783673e-05,
      "loss": 0.4301,
      "step": 5470
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.399179220199585,
      "learning_rate": 1.2236831903599077e-05,
      "loss": 0.43,
      "step": 5480
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.9063313007354736,
      "learning_rate": 1.2212899647694094e-05,
      "loss": 0.416,
      "step": 5490
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.9233620166778564,
      "learning_rate": 1.2188954057279914e-05,
      "loss": 0.4377,
      "step": 5500
    },
    {
      "epoch": 1.29,
      "grad_norm": 3.475787401199341,
      "learning_rate": 1.2164995276648073e-05,
      "loss": 0.4501,
      "step": 5510
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.6476263999938965,
      "learning_rate": 1.2141023450169593e-05,
      "loss": 0.4062,
      "step": 5520
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.7653608322143555,
      "learning_rate": 1.211703872229411e-05,
      "loss": 0.423,
      "step": 5530
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.060560464859009,
      "learning_rate": 1.209304123754899e-05,
      "loss": 0.4671,
      "step": 5540
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.651811122894287,
      "learning_rate": 1.2069031140538488e-05,
      "loss": 0.4249,
      "step": 5550
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.216517686843872,
      "learning_rate": 1.2045008575942835e-05,
      "loss": 0.4102,
      "step": 5560
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.494455099105835,
      "learning_rate": 1.2020973688517413e-05,
      "loss": 0.4169,
      "step": 5570
    },
    {
      "epoch": 1.31,
      "grad_norm": 3.073690414428711,
      "learning_rate": 1.1996926623091839e-05,
      "loss": 0.4165,
      "step": 5580
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.003187656402588,
      "learning_rate": 1.1972867524569125e-05,
      "loss": 0.4324,
      "step": 5590
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.513174533843994,
      "learning_rate": 1.1948796537924786e-05,
      "loss": 0.444,
      "step": 5600
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.3646492958068848,
      "learning_rate": 1.1924713808205975e-05,
      "loss": 0.4334,
      "step": 5610
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.909219264984131,
      "learning_rate": 1.1900619480530611e-05,
      "loss": 0.4119,
      "step": 5620
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.565462350845337,
      "learning_rate": 1.1876513700086488e-05,
      "loss": 0.4136,
      "step": 5630
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.1913716793060303,
      "learning_rate": 1.1852396612130424e-05,
      "loss": 0.422,
      "step": 5640
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.4266469478607178,
      "learning_rate": 1.1828268361987366e-05,
      "loss": 0.3864,
      "step": 5650
    },
    {
      "epoch": 1.33,
      "grad_norm": 4.024113655090332,
      "learning_rate": 1.1804129095049528e-05,
      "loss": 0.4603,
      "step": 5660
    },
    {
      "epoch": 1.33,
      "grad_norm": 2.52059006690979,
      "learning_rate": 1.1779978956775507e-05,
      "loss": 0.4319,
      "step": 5670
    },
    {
      "epoch": 1.33,
      "grad_norm": 2.6520488262176514,
      "learning_rate": 1.1755818092689402e-05,
      "loss": 0.4085,
      "step": 5680
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5698179006576538,
      "learning_rate": 1.1731646648379957e-05,
      "loss": 0.4376,
      "step": 5690
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.699005603790283,
      "learning_rate": 1.1707464769499659e-05,
      "loss": 0.3946,
      "step": 5700
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.2558507919311523,
      "learning_rate": 1.1683272601763882e-05,
      "loss": 0.4114,
      "step": 5710
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.4088921546936035,
      "learning_rate": 1.1659070290949986e-05,
      "loss": 0.4169,
      "step": 5720
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.7113856077194214,
      "learning_rate": 1.163485798289646e-05,
      "loss": 0.4174,
      "step": 5730
    },
    {
      "epoch": 1.35,
      "grad_norm": 3.640072822570801,
      "learning_rate": 1.1610635823502032e-05,
      "loss": 0.4265,
      "step": 5740
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.102118492126465,
      "learning_rate": 1.1586403958724795e-05,
      "loss": 0.4508,
      "step": 5750
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.030365228652954,
      "learning_rate": 1.1562162534581318e-05,
      "loss": 0.3978,
      "step": 5760
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.6213278770446777,
      "learning_rate": 1.153791169714578e-05,
      "loss": 0.3941,
      "step": 5770
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.6485705375671387,
      "learning_rate": 1.1513651592549078e-05,
      "loss": 0.4134,
      "step": 5780
    },
    {
      "epoch": 1.36,
      "grad_norm": 2.195152759552002,
      "learning_rate": 1.1489382366977957e-05,
      "loss": 0.4118,
      "step": 5790
    },
    {
      "epoch": 1.36,
      "grad_norm": 3.877178192138672,
      "learning_rate": 1.1465104166674118e-05,
      "loss": 0.4162,
      "step": 5800
    },
    {
      "epoch": 1.36,
      "grad_norm": 3.038119077682495,
      "learning_rate": 1.1440817137933338e-05,
      "loss": 0.4058,
      "step": 5810
    },
    {
      "epoch": 1.36,
      "grad_norm": 3.686943769454956,
      "learning_rate": 1.1416521427104608e-05,
      "loss": 0.4093,
      "step": 5820
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.756267786026001,
      "learning_rate": 1.1392217180589217e-05,
      "loss": 0.3938,
      "step": 5830
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.9192421436309814,
      "learning_rate": 1.1367904544839899e-05,
      "loss": 0.3884,
      "step": 5840
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.5055880546569824,
      "learning_rate": 1.1343583666359938e-05,
      "loss": 0.3929,
      "step": 5850
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.9986464977264404,
      "learning_rate": 1.1319254691702288e-05,
      "loss": 0.4138,
      "step": 5860
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.1272313594818115,
      "learning_rate": 1.1294917767468685e-05,
      "loss": 0.3823,
      "step": 5870
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.2103681564331055,
      "learning_rate": 1.1270573040308775e-05,
      "loss": 0.4309,
      "step": 5880
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.6729023456573486,
      "learning_rate": 1.1246220656919215e-05,
      "loss": 0.4307,
      "step": 5890
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.390850305557251,
      "learning_rate": 1.1221860764042804e-05,
      "loss": 0.3991,
      "step": 5900
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.9518024921417236,
      "learning_rate": 1.1197493508467583e-05,
      "loss": 0.4297,
      "step": 5910
    },
    {
      "epoch": 1.39,
      "grad_norm": 3.0547449588775635,
      "learning_rate": 1.1173119037025968e-05,
      "loss": 0.4448,
      "step": 5920
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.910167932510376,
      "learning_rate": 1.1148737496593852e-05,
      "loss": 0.3961,
      "step": 5930
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.040271282196045,
      "learning_rate": 1.1124349034089724e-05,
      "loss": 0.4083,
      "step": 5940
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.383133888244629,
      "learning_rate": 1.1099953796473786e-05,
      "loss": 0.4385,
      "step": 5950
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.2600972652435303,
      "learning_rate": 1.1075551930747065e-05,
      "loss": 0.4405,
      "step": 5960
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.2753655910491943,
      "learning_rate": 1.1051143583950527e-05,
      "loss": 0.4078,
      "step": 5970
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.343001127243042,
      "learning_rate": 1.1026728903164192e-05,
      "loss": 0.3973,
      "step": 5980
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.7666661739349365,
      "learning_rate": 1.1002308035506252e-05,
      "loss": 0.4271,
      "step": 5990
    },
    {
      "epoch": 1.41,
      "grad_norm": 2.689923048019409,
      "learning_rate": 1.0977881128132168e-05,
      "loss": 0.4285,
      "step": 6000
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.6380510330200195,
      "learning_rate": 1.095344832823381e-05,
      "loss": 0.435,
      "step": 6010
    },
    {
      "epoch": 1.41,
      "grad_norm": 4.504169940948486,
      "learning_rate": 1.0929009783038542e-05,
      "loss": 0.4114,
      "step": 6020
    },
    {
      "epoch": 1.41,
      "grad_norm": 2.0942277908325195,
      "learning_rate": 1.0904565639808358e-05,
      "loss": 0.3929,
      "step": 6030
    },
    {
      "epoch": 1.42,
      "grad_norm": 3.3159725666046143,
      "learning_rate": 1.088011604583898e-05,
      "loss": 0.4301,
      "step": 6040
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.1334471702575684,
      "learning_rate": 1.0855661148458972e-05,
      "loss": 0.4167,
      "step": 6050
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.836062431335449,
      "learning_rate": 1.083120109502886e-05,
      "loss": 0.4078,
      "step": 6060
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.429600477218628,
      "learning_rate": 1.0806736032940242e-05,
      "loss": 0.4128,
      "step": 6070
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.3999927043914795,
      "learning_rate": 1.0782266109614893e-05,
      "loss": 0.4054,
      "step": 6080
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.94681978225708,
      "learning_rate": 1.075779147250388e-05,
      "loss": 0.4335,
      "step": 6090
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.133025646209717,
      "learning_rate": 1.0733312269086679e-05,
      "loss": 0.4431,
      "step": 6100
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.587627649307251,
      "learning_rate": 1.0708828646870274e-05,
      "loss": 0.4521,
      "step": 6110
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.8573906421661377,
      "learning_rate": 1.0684340753388283e-05,
      "loss": 0.4348,
      "step": 6120
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.190426826477051,
      "learning_rate": 1.0659848736200059e-05,
      "loss": 0.4424,
      "step": 6130
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.6641998291015625,
      "learning_rate": 1.0635352742889801e-05,
      "loss": 0.4433,
      "step": 6140
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.6666946411132812,
      "learning_rate": 1.0610852921065672e-05,
      "loss": 0.4626,
      "step": 6150
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.196863174438477,
      "learning_rate": 1.0586349418358908e-05,
      "loss": 0.4742,
      "step": 6160
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.7317209243774414,
      "learning_rate": 1.0561842382422919e-05,
      "loss": 0.466,
      "step": 6170
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.0939958095550537,
      "learning_rate": 1.05373319609324e-05,
      "loss": 0.3936,
      "step": 6180
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.9880199432373047,
      "learning_rate": 1.0512818301582459e-05,
      "loss": 0.4552,
      "step": 6190
    },
    {
      "epoch": 1.45,
      "grad_norm": 3.3993287086486816,
      "learning_rate": 1.0488301552087712e-05,
      "loss": 0.4509,
      "step": 6200
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.7993645668029785,
      "learning_rate": 1.0463781860181385e-05,
      "loss": 0.4365,
      "step": 6210
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.8924977779388428,
      "learning_rate": 1.0439259373614452e-05,
      "loss": 0.4599,
      "step": 6220
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.8954365253448486,
      "learning_rate": 1.041473424015471e-05,
      "loss": 0.4141,
      "step": 6230
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.0512120723724365,
      "learning_rate": 1.0390206607585916e-05,
      "loss": 0.4545,
      "step": 6240
    },
    {
      "epoch": 1.47,
      "grad_norm": 2.942566394805908,
      "learning_rate": 1.0365676623706886e-05,
      "loss": 0.3981,
      "step": 6250
    },
    {
      "epoch": 1.47,
      "grad_norm": 4.272647380828857,
      "learning_rate": 1.0341144436330598e-05,
      "loss": 0.4593,
      "step": 6260
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.7299587726593018,
      "learning_rate": 1.0316610193283316e-05,
      "loss": 0.4012,
      "step": 6270
    },
    {
      "epoch": 1.47,
      "grad_norm": 2.4987165927886963,
      "learning_rate": 1.0292074042403682e-05,
      "loss": 0.3712,
      "step": 6280
    },
    {
      "epoch": 1.47,
      "grad_norm": 2.660616636276245,
      "learning_rate": 1.0267536131541841e-05,
      "loss": 0.4495,
      "step": 6290
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.2739005088806152,
      "learning_rate": 1.0242996608558542e-05,
      "loss": 0.4406,
      "step": 6300
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.0238559246063232,
      "learning_rate": 1.021845562132425e-05,
      "loss": 0.4753,
      "step": 6310
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.7996561527252197,
      "learning_rate": 1.0193913317718245e-05,
      "loss": 0.4285,
      "step": 6320
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.8807166814804077,
      "learning_rate": 1.016936984562775e-05,
      "loss": 0.4651,
      "step": 6330
    },
    {
      "epoch": 1.49,
      "grad_norm": 2.433218479156494,
      "learning_rate": 1.0144825352947025e-05,
      "loss": 0.3965,
      "step": 6340
    },
    {
      "epoch": 1.49,
      "grad_norm": 2.6461801528930664,
      "learning_rate": 1.0120279987576475e-05,
      "loss": 0.4443,
      "step": 6350
    },
    {
      "epoch": 1.49,
      "grad_norm": 3.1662182807922363,
      "learning_rate": 1.0095733897421773e-05,
      "loss": 0.4232,
      "step": 6360
    },
    {
      "epoch": 1.49,
      "grad_norm": 2.5991127490997314,
      "learning_rate": 1.0071187230392949e-05,
      "loss": 0.4232,
      "step": 6370
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.476163387298584,
      "learning_rate": 1.0046640134403518e-05,
      "loss": 0.3816,
      "step": 6380
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.0029523372650146,
      "learning_rate": 1.0022092757369575e-05,
      "loss": 0.4371,
      "step": 6390
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.1122887134552,
      "learning_rate": 9.99754524720891e-06,
      "loss": 0.4303,
      "step": 6400
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.4014029502868652,
      "learning_rate": 9.972997751840114e-06,
      "loss": 0.4366,
      "step": 6410
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.659879207611084,
      "learning_rate": 9.948450419181694e-06,
      "loss": 0.4061,
      "step": 6420
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.754465341567993,
      "learning_rate": 9.923903397151165e-06,
      "loss": 0.4327,
      "step": 6430
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.965275764465332,
      "learning_rate": 9.899356833664182e-06,
      "loss": 0.3984,
      "step": 6440
    },
    {
      "epoch": 1.51,
      "grad_norm": 4.408227443695068,
      "learning_rate": 9.874810876633633e-06,
      "loss": 0.4175,
      "step": 6450
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.6011650562286377,
      "learning_rate": 9.850265673968755e-06,
      "loss": 0.4264,
      "step": 6460
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.312695026397705,
      "learning_rate": 9.825721373574224e-06,
      "loss": 0.4074,
      "step": 6470
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.6017991304397583,
      "learning_rate": 9.801178123349298e-06,
      "loss": 0.4013,
      "step": 6480
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.6826746463775635,
      "learning_rate": 9.776636071186903e-06,
      "loss": 0.4264,
      "step": 6490
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.5056049823760986,
      "learning_rate": 9.752095364972733e-06,
      "loss": 0.4025,
      "step": 6500
    },
    {
      "epoch": 1.53,
      "grad_norm": 2.5435829162597656,
      "learning_rate": 9.727556152584386e-06,
      "loss": 0.4416,
      "step": 6510
    },
    {
      "epoch": 1.53,
      "grad_norm": 2.9535160064697266,
      "learning_rate": 9.703018581890453e-06,
      "loss": 0.4046,
      "step": 6520
    },
    {
      "epoch": 1.53,
      "grad_norm": 2.4770615100860596,
      "learning_rate": 9.678482800749637e-06,
      "loss": 0.4481,
      "step": 6530
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.6340632438659668,
      "learning_rate": 9.653948957009842e-06,
      "loss": 0.4093,
      "step": 6540
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.5105984210968018,
      "learning_rate": 9.629417198507317e-06,
      "loss": 0.3766,
      "step": 6550
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.347519874572754,
      "learning_rate": 9.604887673065739e-06,
      "loss": 0.4688,
      "step": 6560
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.4546990394592285,
      "learning_rate": 9.58036052849532e-06,
      "loss": 0.4211,
      "step": 6570
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.1615915298461914,
      "learning_rate": 9.555835912591937e-06,
      "loss": 0.4398,
      "step": 6580
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.556452751159668,
      "learning_rate": 9.531313973136224e-06,
      "loss": 0.4469,
      "step": 6590
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.188995838165283,
      "learning_rate": 9.506794857892693e-06,
      "loss": 0.4516,
      "step": 6600
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.600950002670288,
      "learning_rate": 9.48227871460883e-06,
      "loss": 0.3914,
      "step": 6610
    },
    {
      "epoch": 1.55,
      "grad_norm": 3.106096029281616,
      "learning_rate": 9.457765691014215e-06,
      "loss": 0.4011,
      "step": 6620
    },
    {
      "epoch": 1.55,
      "grad_norm": 3.239328145980835,
      "learning_rate": 9.433255934819637e-06,
      "loss": 0.4407,
      "step": 6630
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.675119400024414,
      "learning_rate": 9.408749593716182e-06,
      "loss": 0.4048,
      "step": 6640
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.7327470779418945,
      "learning_rate": 9.384246815374367e-06,
      "loss": 0.4143,
      "step": 6650
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.7134315967559814,
      "learning_rate": 9.359747747443241e-06,
      "loss": 0.4246,
      "step": 6660
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.9312355518341064,
      "learning_rate": 9.335252537549493e-06,
      "loss": 0.4031,
      "step": 6670
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.9970333576202393,
      "learning_rate": 9.31076133329656e-06,
      "loss": 0.4261,
      "step": 6680
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.210000514984131,
      "learning_rate": 9.286274282263748e-06,
      "loss": 0.4221,
      "step": 6690
    },
    {
      "epoch": 1.57,
      "grad_norm": 2.6400630474090576,
      "learning_rate": 9.261791532005336e-06,
      "loss": 0.4405,
      "step": 6700
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.813339948654175,
      "learning_rate": 9.237313230049679e-06,
      "loss": 0.4176,
      "step": 6710
    },
    {
      "epoch": 1.58,
      "grad_norm": 4.368515968322754,
      "learning_rate": 9.212839523898336e-06,
      "loss": 0.412,
      "step": 6720
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.9583981037139893,
      "learning_rate": 9.18837056102517e-06,
      "loss": 0.4084,
      "step": 6730
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.2839670181274414,
      "learning_rate": 9.163906488875469e-06,
      "loss": 0.425,
      "step": 6740
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.2705867290496826,
      "learning_rate": 9.139447454865034e-06,
      "loss": 0.4315,
      "step": 6750
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.066089391708374,
      "learning_rate": 9.114993606379319e-06,
      "loss": 0.396,
      "step": 6760
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.1531569957733154,
      "learning_rate": 9.090545090772532e-06,
      "loss": 0.4251,
      "step": 6770
    },
    {
      "epoch": 1.59,
      "grad_norm": 4.118584632873535,
      "learning_rate": 9.066102055366737e-06,
      "loss": 0.3726,
      "step": 6780
    },
    {
      "epoch": 1.59,
      "grad_norm": 3.1699228286743164,
      "learning_rate": 9.041664647450987e-06,
      "loss": 0.3801,
      "step": 6790
    },
    {
      "epoch": 1.59,
      "grad_norm": 4.943721771240234,
      "learning_rate": 9.017233014280416e-06,
      "loss": 0.4367,
      "step": 6800
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.3100037574768066,
      "learning_rate": 8.992807303075369e-06,
      "loss": 0.4112,
      "step": 6810
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.346444845199585,
      "learning_rate": 8.968387661020488e-06,
      "loss": 0.4054,
      "step": 6820
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.3539719581604,
      "learning_rate": 8.943974235263869e-06,
      "loss": 0.3801,
      "step": 6830
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.7516427040100098,
      "learning_rate": 8.91956717291613e-06,
      "loss": 0.3849,
      "step": 6840
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.8994077444076538,
      "learning_rate": 8.895166621049554e-06,
      "loss": 0.4002,
      "step": 6850
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.046363592147827,
      "learning_rate": 8.87077272669719e-06,
      "loss": 0.418,
      "step": 6860
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.4630486965179443,
      "learning_rate": 8.84638563685197e-06,
      "loss": 0.3862,
      "step": 6870
    },
    {
      "epoch": 1.61,
      "grad_norm": 4.387174606323242,
      "learning_rate": 8.822005498465825e-06,
      "loss": 0.4447,
      "step": 6880
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.0758891105651855,
      "learning_rate": 8.797632458448795e-06,
      "loss": 0.4124,
      "step": 6890
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.3683199882507324,
      "learning_rate": 8.773266663668149e-06,
      "loss": 0.4241,
      "step": 6900
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.194495439529419,
      "learning_rate": 8.748908260947502e-06,
      "loss": 0.4167,
      "step": 6910
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.4825315475463867,
      "learning_rate": 8.724557397065912e-06,
      "loss": 0.402,
      "step": 6920
    },
    {
      "epoch": 1.62,
      "grad_norm": 4.178393840789795,
      "learning_rate": 8.700214218757021e-06,
      "loss": 0.4278,
      "step": 6930
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.399979591369629,
      "learning_rate": 8.675878872708157e-06,
      "loss": 0.4536,
      "step": 6940
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.5618929862976074,
      "learning_rate": 8.651551505559456e-06,
      "loss": 0.41,
      "step": 6950
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.4062232971191406,
      "learning_rate": 8.627232263902963e-06,
      "loss": 0.4035,
      "step": 6960
    },
    {
      "epoch": 1.63,
      "grad_norm": 4.055943489074707,
      "learning_rate": 8.602921294281771e-06,
      "loss": 0.4188,
      "step": 6970
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.6123123168945312,
      "learning_rate": 8.57861874318913e-06,
      "loss": 0.3876,
      "step": 6980
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.3802664279937744,
      "learning_rate": 8.554324757067544e-06,
      "loss": 0.3907,
      "step": 6990
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.413532018661499,
      "learning_rate": 8.530039482307926e-06,
      "loss": 0.4153,
      "step": 7000
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.0546398162841797,
      "learning_rate": 8.505763065248684e-06,
      "loss": 0.4266,
      "step": 7010
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.463625192642212,
      "learning_rate": 8.481495652174859e-06,
      "loss": 0.4149,
      "step": 7020
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.5626883506774902,
      "learning_rate": 8.457237389317226e-06,
      "loss": 0.431,
      "step": 7030
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.1309969425201416,
      "learning_rate": 8.432988422851428e-06,
      "loss": 0.3982,
      "step": 7040
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.1702613830566406,
      "learning_rate": 8.408748898897099e-06,
      "loss": 0.4459,
      "step": 7050
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.7572267055511475,
      "learning_rate": 8.384518963516954e-06,
      "loss": 0.4492,
      "step": 7060
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.1804287433624268,
      "learning_rate": 8.360298762715947e-06,
      "loss": 0.4303,
      "step": 7070
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.7193331718444824,
      "learning_rate": 8.33608844244036e-06,
      "loss": 0.4436,
      "step": 7080
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.0767486095428467,
      "learning_rate": 8.311888148576956e-06,
      "loss": 0.4289,
      "step": 7090
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.4777424335479736,
      "learning_rate": 8.287698026952055e-06,
      "loss": 0.4248,
      "step": 7100
    },
    {
      "epoch": 1.67,
      "grad_norm": 3.1276767253875732,
      "learning_rate": 8.263518223330698e-06,
      "loss": 0.3958,
      "step": 7110
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.251704216003418,
      "learning_rate": 8.23934888341575e-06,
      "loss": 0.3958,
      "step": 7120
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.9061574935913086,
      "learning_rate": 8.21519015284702e-06,
      "loss": 0.4557,
      "step": 7130
    },
    {
      "epoch": 1.67,
      "grad_norm": 4.1332502365112305,
      "learning_rate": 8.191042177200389e-06,
      "loss": 0.4257,
      "step": 7140
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.951140284538269,
      "learning_rate": 8.16690510198693e-06,
      "loss": 0.4053,
      "step": 7150
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.6600043773651123,
      "learning_rate": 8.142779072652035e-06,
      "loss": 0.4213,
      "step": 7160
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.3192520141601562,
      "learning_rate": 8.118664234574532e-06,
      "loss": 0.4385,
      "step": 7170
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.176237106323242,
      "learning_rate": 8.094560733065809e-06,
      "loss": 0.4164,
      "step": 7180
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.8220553398132324,
      "learning_rate": 8.070468713368954e-06,
      "loss": 0.3564,
      "step": 7190
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.6268515586853027,
      "learning_rate": 8.046388320657861e-06,
      "loss": 0.4191,
      "step": 7200
    },
    {
      "epoch": 1.69,
      "grad_norm": 3.216064453125,
      "learning_rate": 8.022319700036354e-06,
      "loss": 0.3966,
      "step": 7210
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.732172966003418,
      "learning_rate": 7.998262996537334e-06,
      "loss": 0.4219,
      "step": 7220
    },
    {
      "epoch": 1.69,
      "grad_norm": 3.1506922245025635,
      "learning_rate": 7.974218355121885e-06,
      "loss": 0.3686,
      "step": 7230
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.7282040119171143,
      "learning_rate": 7.950185920678408e-06,
      "loss": 0.4652,
      "step": 7240
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.6950740814208984,
      "learning_rate": 7.926165838021748e-06,
      "loss": 0.4229,
      "step": 7250
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.6706998348236084,
      "learning_rate": 7.902158251892318e-06,
      "loss": 0.413,
      "step": 7260
    },
    {
      "epoch": 1.7,
      "grad_norm": 4.237908840179443,
      "learning_rate": 7.878163306955239e-06,
      "loss": 0.4308,
      "step": 7270
    },
    {
      "epoch": 1.71,
      "grad_norm": 2.9995172023773193,
      "learning_rate": 7.85418114779944e-06,
      "loss": 0.3978,
      "step": 7280
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.8392722606658936,
      "learning_rate": 7.83021191893682e-06,
      "loss": 0.3993,
      "step": 7290
    },
    {
      "epoch": 1.71,
      "grad_norm": 3.386892557144165,
      "learning_rate": 7.806255764801363e-06,
      "loss": 0.4303,
      "step": 7300
    },
    {
      "epoch": 1.71,
      "grad_norm": 4.373202800750732,
      "learning_rate": 7.782312829748255e-06,
      "loss": 0.4157,
      "step": 7310
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.539707660675049,
      "learning_rate": 7.75838325805304e-06,
      "loss": 0.423,
      "step": 7320
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.4264276027679443,
      "learning_rate": 7.734467193910729e-06,
      "loss": 0.4655,
      "step": 7330
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.6690571308135986,
      "learning_rate": 7.710564781434947e-06,
      "loss": 0.4458,
      "step": 7340
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.6965302228927612,
      "learning_rate": 7.686676164657042e-06,
      "loss": 0.4238,
      "step": 7350
    },
    {
      "epoch": 1.73,
      "grad_norm": 3.241941213607788,
      "learning_rate": 7.662801487525244e-06,
      "loss": 0.4317,
      "step": 7360
    },
    {
      "epoch": 1.73,
      "grad_norm": 3.1051106452941895,
      "learning_rate": 7.638940893903787e-06,
      "loss": 0.4239,
      "step": 7370
    },
    {
      "epoch": 1.73,
      "grad_norm": 3.6628589630126953,
      "learning_rate": 7.615094527572027e-06,
      "loss": 0.3884,
      "step": 7380
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.9945217370986938,
      "learning_rate": 7.591262532223602e-06,
      "loss": 0.4169,
      "step": 7390
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.2202718257904053,
      "learning_rate": 7.567445051465549e-06,
      "loss": 0.4261,
      "step": 7400
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.9653825759887695,
      "learning_rate": 7.543642228817443e-06,
      "loss": 0.3934,
      "step": 7410
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.025116443634033,
      "learning_rate": 7.51985420771053e-06,
      "loss": 0.4296,
      "step": 7420
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.5917747020721436,
      "learning_rate": 7.496081131486867e-06,
      "loss": 0.4275,
      "step": 7430
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.9372626543045044,
      "learning_rate": 7.4723231433984615e-06,
      "loss": 0.4204,
      "step": 7440
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.3966798782348633,
      "learning_rate": 7.448580386606386e-06,
      "loss": 0.4131,
      "step": 7450
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.2845683097839355,
      "learning_rate": 7.424853004179948e-06,
      "loss": 0.3966,
      "step": 7460
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.9293949604034424,
      "learning_rate": 7.401141139095809e-06,
      "loss": 0.412,
      "step": 7470
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.6454274654388428,
      "learning_rate": 7.377444934237121e-06,
      "loss": 0.4074,
      "step": 7480
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.013523817062378,
      "learning_rate": 7.353764532392673e-06,
      "loss": 0.3942,
      "step": 7490
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.9336414337158203,
      "learning_rate": 7.33010007625603e-06,
      "loss": 0.4071,
      "step": 7500
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.6774048805236816,
      "learning_rate": 7.306451708424675e-06,
      "loss": 0.4101,
      "step": 7510
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.3519582748413086,
      "learning_rate": 7.282819571399129e-06,
      "loss": 0.4654,
      "step": 7520
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.0705857276916504,
      "learning_rate": 7.259203807582127e-06,
      "loss": 0.4063,
      "step": 7530
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.185506582260132,
      "learning_rate": 7.235604559277736e-06,
      "loss": 0.4028,
      "step": 7540
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.3239009380340576,
      "learning_rate": 7.212021968690508e-06,
      "loss": 0.4082,
      "step": 7550
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.7727603912353516,
      "learning_rate": 7.1884561779246055e-06,
      "loss": 0.4239,
      "step": 7560
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.0244147777557373,
      "learning_rate": 7.1649073289829725e-06,
      "loss": 0.4478,
      "step": 7570
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.7497613430023193,
      "learning_rate": 7.141375563766462e-06,
      "loss": 0.3981,
      "step": 7580
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.012847423553467,
      "learning_rate": 7.117861024072976e-06,
      "loss": 0.3885,
      "step": 7590
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.3844501972198486,
      "learning_rate": 7.094363851596626e-06,
      "loss": 0.4177,
      "step": 7600
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.553884983062744,
      "learning_rate": 7.070884187926874e-06,
      "loss": 0.4126,
      "step": 7610
    },
    {
      "epoch": 1.79,
      "grad_norm": 3.2890100479125977,
      "learning_rate": 7.047422174547675e-06,
      "loss": 0.3926,
      "step": 7620
    },
    {
      "epoch": 1.79,
      "grad_norm": 3.4646310806274414,
      "learning_rate": 7.023977952836617e-06,
      "loss": 0.4225,
      "step": 7630
    },
    {
      "epoch": 1.79,
      "grad_norm": 3.0665433406829834,
      "learning_rate": 7.000551664064093e-06,
      "loss": 0.396,
      "step": 7640
    },
    {
      "epoch": 1.79,
      "grad_norm": 4.366447448730469,
      "learning_rate": 6.9771434493924296e-06,
      "loss": 0.4263,
      "step": 7650
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.4953198432922363,
      "learning_rate": 6.95375344987504e-06,
      "loss": 0.409,
      "step": 7660
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.446820020675659,
      "learning_rate": 6.930381806455579e-06,
      "loss": 0.433,
      "step": 7670
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.4392452239990234,
      "learning_rate": 6.907028659967095e-06,
      "loss": 0.3962,
      "step": 7680
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.2202565670013428,
      "learning_rate": 6.883694151131173e-06,
      "loss": 0.4336,
      "step": 7690
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.5522964000701904,
      "learning_rate": 6.860378420557086e-06,
      "loss": 0.4081,
      "step": 7700
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.9425866603851318,
      "learning_rate": 6.837081608740961e-06,
      "loss": 0.4137,
      "step": 7710
    },
    {
      "epoch": 1.81,
      "grad_norm": 2.608241558074951,
      "learning_rate": 6.813803856064925e-06,
      "loss": 0.3904,
      "step": 7720
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.8257609605789185,
      "learning_rate": 6.790545302796247e-06,
      "loss": 0.3848,
      "step": 7730
    },
    {
      "epoch": 1.81,
      "grad_norm": 3.569911241531372,
      "learning_rate": 6.7673060890865184e-06,
      "loss": 0.4074,
      "step": 7740
    },
    {
      "epoch": 1.82,
      "grad_norm": 4.337077617645264,
      "learning_rate": 6.744086354970785e-06,
      "loss": 0.4162,
      "step": 7750
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.6076483726501465,
      "learning_rate": 6.720886240366715e-06,
      "loss": 0.4374,
      "step": 7760
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.249657154083252,
      "learning_rate": 6.697705885073752e-06,
      "loss": 0.4162,
      "step": 7770
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.738389492034912,
      "learning_rate": 6.674545428772277e-06,
      "loss": 0.4241,
      "step": 7780
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.226423978805542,
      "learning_rate": 6.651405011022762e-06,
      "loss": 0.4017,
      "step": 7790
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.7415919303894043,
      "learning_rate": 6.628284771264924e-06,
      "loss": 0.4193,
      "step": 7800
    },
    {
      "epoch": 1.83,
      "grad_norm": 2.2767016887664795,
      "learning_rate": 6.605184848816901e-06,
      "loss": 0.3957,
      "step": 7810
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.0039710998535156,
      "learning_rate": 6.5821053828743975e-06,
      "loss": 0.3757,
      "step": 7820
    },
    {
      "epoch": 1.84,
      "grad_norm": 3.5754072666168213,
      "learning_rate": 6.559046512509859e-06,
      "loss": 0.4431,
      "step": 7830
    },
    {
      "epoch": 1.84,
      "grad_norm": 3.591914653778076,
      "learning_rate": 6.536008376671609e-06,
      "loss": 0.4146,
      "step": 7840
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.4757025241851807,
      "learning_rate": 6.512991114183043e-06,
      "loss": 0.4416,
      "step": 7850
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.6828629970550537,
      "learning_rate": 6.4899948637417775e-06,
      "loss": 0.3687,
      "step": 7860
    },
    {
      "epoch": 1.84,
      "grad_norm": 3.5056276321411133,
      "learning_rate": 6.4670197639188045e-06,
      "loss": 0.3878,
      "step": 7870
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.4080612659454346,
      "learning_rate": 6.444065953157676e-06,
      "loss": 0.3695,
      "step": 7880
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.9565749168395996,
      "learning_rate": 6.4211335697736565e-06,
      "loss": 0.4235,
      "step": 7890
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.4975216388702393,
      "learning_rate": 6.3982227519528986e-06,
      "loss": 0.4007,
      "step": 7900
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.6987144947052,
      "learning_rate": 6.375333637751591e-06,
      "loss": 0.4561,
      "step": 7910
    },
    {
      "epoch": 1.86,
      "grad_norm": 3.054764986038208,
      "learning_rate": 6.352466365095151e-06,
      "loss": 0.4062,
      "step": 7920
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.2188777923583984,
      "learning_rate": 6.329621071777388e-06,
      "loss": 0.4299,
      "step": 7930
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.6217567920684814,
      "learning_rate": 6.3067978954596534e-06,
      "loss": 0.4,
      "step": 7940
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.700129270553589,
      "learning_rate": 6.283996973670037e-06,
      "loss": 0.4382,
      "step": 7950
    },
    {
      "epoch": 1.87,
      "grad_norm": 4.202287197113037,
      "learning_rate": 6.261218443802526e-06,
      "loss": 0.4001,
      "step": 7960
    },
    {
      "epoch": 1.87,
      "grad_norm": 4.5533223152160645,
      "learning_rate": 6.238462443116178e-06,
      "loss": 0.4298,
      "step": 7970
    },
    {
      "epoch": 1.87,
      "grad_norm": 3.3329553604125977,
      "learning_rate": 6.215729108734283e-06,
      "loss": 0.4144,
      "step": 7980
    },
    {
      "epoch": 1.87,
      "grad_norm": 4.497241497039795,
      "learning_rate": 6.193018577643566e-06,
      "loss": 0.4447,
      "step": 7990
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.3096911907196045,
      "learning_rate": 6.170330986693335e-06,
      "loss": 0.3996,
      "step": 8000
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.400831937789917,
      "learning_rate": 6.147666472594658e-06,
      "loss": 0.3961,
      "step": 8010
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.8470686674118042,
      "learning_rate": 6.125025171919558e-06,
      "loss": 0.3628,
      "step": 8020
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.137700080871582,
      "learning_rate": 6.102407221100175e-06,
      "loss": 0.3851,
      "step": 8030
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.175135135650635,
      "learning_rate": 6.079812756427946e-06,
      "loss": 0.4144,
      "step": 8040
    },
    {
      "epoch": 1.89,
      "grad_norm": 3.460914134979248,
      "learning_rate": 6.0572419140527824e-06,
      "loss": 0.4733,
      "step": 8050
    },
    {
      "epoch": 1.89,
      "grad_norm": 2.312005043029785,
      "learning_rate": 6.034694829982257e-06,
      "loss": 0.3913,
      "step": 8060
    },
    {
      "epoch": 1.89,
      "grad_norm": 2.469682216644287,
      "learning_rate": 6.012171640080782e-06,
      "loss": 0.372,
      "step": 8070
    },
    {
      "epoch": 1.89,
      "grad_norm": 4.082304954528809,
      "learning_rate": 5.989672480068774e-06,
      "loss": 0.3756,
      "step": 8080
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.9270691871643066,
      "learning_rate": 5.967197485521863e-06,
      "loss": 0.4365,
      "step": 8090
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.9562108516693115,
      "learning_rate": 5.944746791870062e-06,
      "loss": 0.4302,
      "step": 8100
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.5169003009796143,
      "learning_rate": 5.922320534396947e-06,
      "loss": 0.4585,
      "step": 8110
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.2815041542053223,
      "learning_rate": 5.899918848238846e-06,
      "loss": 0.389,
      "step": 8120
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.4863498210906982,
      "learning_rate": 5.877541868384029e-06,
      "loss": 0.421,
      "step": 8130
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.0380122661590576,
      "learning_rate": 5.855189729671891e-06,
      "loss": 0.405,
      "step": 8140
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.0629916191101074,
      "learning_rate": 5.832862566792125e-06,
      "loss": 0.4224,
      "step": 8150
    },
    {
      "epoch": 1.91,
      "grad_norm": 2.630268096923828,
      "learning_rate": 5.810560514283947e-06,
      "loss": 0.4106,
      "step": 8160
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.2821390628814697,
      "learning_rate": 5.7882837065352495e-06,
      "loss": 0.4342,
      "step": 8170
    },
    {
      "epoch": 1.92,
      "grad_norm": 4.314237117767334,
      "learning_rate": 5.766032277781808e-06,
      "loss": 0.4439,
      "step": 8180
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.176600694656372,
      "learning_rate": 5.743806362106461e-06,
      "loss": 0.3785,
      "step": 8190
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.0774779319763184,
      "learning_rate": 5.721606093438321e-06,
      "loss": 0.4113,
      "step": 8200
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.271517515182495,
      "learning_rate": 5.699431605551957e-06,
      "loss": 0.4032,
      "step": 8210
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.2360026836395264,
      "learning_rate": 5.677283032066576e-06,
      "loss": 0.3909,
      "step": 8220
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.386648178100586,
      "learning_rate": 5.6551605064452405e-06,
      "loss": 0.41,
      "step": 8230
    },
    {
      "epoch": 1.93,
      "grad_norm": 2.479307174682617,
      "learning_rate": 5.633064161994051e-06,
      "loss": 0.4451,
      "step": 8240
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.702563524246216,
      "learning_rate": 5.610994131861347e-06,
      "loss": 0.4025,
      "step": 8250
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.131250858306885,
      "learning_rate": 5.588950549036894e-06,
      "loss": 0.3706,
      "step": 8260
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.8344920873641968,
      "learning_rate": 5.566933546351101e-06,
      "loss": 0.405,
      "step": 8270
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.288322925567627,
      "learning_rate": 5.5449432564742074e-06,
      "loss": 0.4201,
      "step": 8280
    },
    {
      "epoch": 1.94,
      "grad_norm": 2.902527093887329,
      "learning_rate": 5.52297981191549e-06,
      "loss": 0.4336,
      "step": 8290
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.5054404735565186,
      "learning_rate": 5.501043345022448e-06,
      "loss": 0.4236,
      "step": 8300
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.9434545040130615,
      "learning_rate": 5.479133987980032e-06,
      "loss": 0.3628,
      "step": 8310
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.2499237060546875,
      "learning_rate": 5.457251872809831e-06,
      "loss": 0.4277,
      "step": 8320
    },
    {
      "epoch": 1.95,
      "grad_norm": 5.177332878112793,
      "learning_rate": 5.435397131369271e-06,
      "loss": 0.371,
      "step": 8330
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.8803932666778564,
      "learning_rate": 5.41356989535084e-06,
      "loss": 0.3924,
      "step": 8340
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.496318817138672,
      "learning_rate": 5.391770296281278e-06,
      "loss": 0.402,
      "step": 8350
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.801665782928467,
      "learning_rate": 5.3699984655207915e-06,
      "loss": 0.4332,
      "step": 8360
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.1198790073394775,
      "learning_rate": 5.348254534262262e-06,
      "loss": 0.4149,
      "step": 8370
    },
    {
      "epoch": 1.96,
      "grad_norm": 2.9764788150787354,
      "learning_rate": 5.326538633530451e-06,
      "loss": 0.3882,
      "step": 8380
    },
    {
      "epoch": 1.97,
      "grad_norm": 3.9789886474609375,
      "learning_rate": 5.304850894181217e-06,
      "loss": 0.3694,
      "step": 8390
    },
    {
      "epoch": 1.97,
      "grad_norm": 4.903828144073486,
      "learning_rate": 5.283191446900716e-06,
      "loss": 0.3763,
      "step": 8400
    },
    {
      "epoch": 1.97,
      "grad_norm": 2.433743715286255,
      "learning_rate": 5.26156042220463e-06,
      "loss": 0.4176,
      "step": 8410
    },
    {
      "epoch": 1.97,
      "grad_norm": 4.181704998016357,
      "learning_rate": 5.239957950437366e-06,
      "loss": 0.3987,
      "step": 8420
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.6027626991271973,
      "learning_rate": 5.218384161771286e-06,
      "loss": 0.3961,
      "step": 8430
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.872938394546509,
      "learning_rate": 5.196839186205897e-06,
      "loss": 0.4673,
      "step": 8440
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.0004923343658447,
      "learning_rate": 5.175323153567097e-06,
      "loss": 0.3901,
      "step": 8450
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.7978624105453491,
      "learning_rate": 5.153836193506378e-06,
      "loss": 0.412,
      "step": 8460
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.090113878250122,
      "learning_rate": 5.1323784355000374e-06,
      "loss": 0.4199,
      "step": 8470
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.8945703506469727,
      "learning_rate": 5.110950008848417e-06,
      "loss": 0.3844,
      "step": 8480
    },
    {
      "epoch": 1.99,
      "grad_norm": 4.174066543579102,
      "learning_rate": 5.089551042675107e-06,
      "loss": 0.3818,
      "step": 8490
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.676335334777832,
      "learning_rate": 5.068181665926182e-06,
      "loss": 0.3865,
      "step": 8500
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.852668046951294,
      "learning_rate": 5.046842007369404e-06,
      "loss": 0.4195,
      "step": 8510
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.8397223949432373,
      "learning_rate": 5.025532195593468e-06,
      "loss": 0.402,
      "step": 8520
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.6208388805389404,
      "learning_rate": 5.004252359007218e-06,
      "loss": 0.4106,
      "step": 8530
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.0921661853790283,
      "learning_rate": 4.983002625838869e-06,
      "loss": 0.3802,
      "step": 8540
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.9490928649902344,
      "learning_rate": 4.961783124135244e-06,
      "loss": 0.4148,
      "step": 8550
    },
    {
      "epoch": 2.01,
      "grad_norm": 2.991419553756714,
      "learning_rate": 4.94059398176099e-06,
      "loss": 0.4158,
      "step": 8560
    },
    {
      "epoch": 2.01,
      "grad_norm": 3.408399820327759,
      "learning_rate": 4.9194353263978254e-06,
      "loss": 0.4007,
      "step": 8570
    },
    {
      "epoch": 2.01,
      "grad_norm": 4.0110039710998535,
      "learning_rate": 4.898307285543743e-06,
      "loss": 0.3411,
      "step": 8580
    },
    {
      "epoch": 2.01,
      "grad_norm": 2.060717821121216,
      "learning_rate": 4.877209986512271e-06,
      "loss": 0.3928,
      "step": 8590
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.1638946533203125,
      "learning_rate": 4.856143556431697e-06,
      "loss": 0.3904,
      "step": 8600
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.721694231033325,
      "learning_rate": 4.835108122244281e-06,
      "loss": 0.4184,
      "step": 8610
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.1395678520202637,
      "learning_rate": 4.814103810705524e-06,
      "loss": 0.3996,
      "step": 8620
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.7739949226379395,
      "learning_rate": 4.793130748383381e-06,
      "loss": 0.3904,
      "step": 8630
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.6604456901550293,
      "learning_rate": 4.772189061657511e-06,
      "loss": 0.3955,
      "step": 8640
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.4442403316497803,
      "learning_rate": 4.751278876718497e-06,
      "loss": 0.4426,
      "step": 8650
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.0341060161590576,
      "learning_rate": 4.7304003195671085e-06,
      "loss": 0.3616,
      "step": 8660
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.0301930904388428,
      "learning_rate": 4.709553516013535e-06,
      "loss": 0.3881,
      "step": 8670
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.8413169384002686,
      "learning_rate": 4.688738591676613e-06,
      "loss": 0.3674,
      "step": 8680
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.4952170848846436,
      "learning_rate": 4.66795567198309e-06,
      "loss": 0.3978,
      "step": 8690
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.638702869415283,
      "learning_rate": 4.647204882166857e-06,
      "loss": 0.3872,
      "step": 8700
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.370265007019043,
      "learning_rate": 4.626486347268198e-06,
      "loss": 0.4101,
      "step": 8710
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.4984383583068848,
      "learning_rate": 4.605800192133032e-06,
      "loss": 0.4026,
      "step": 8720
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.449488878250122,
      "learning_rate": 4.585146541412168e-06,
      "loss": 0.3943,
      "step": 8730
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.686100721359253,
      "learning_rate": 4.564525519560549e-06,
      "loss": 0.3586,
      "step": 8740
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.1368014812469482,
      "learning_rate": 4.543937250836493e-06,
      "loss": 0.3683,
      "step": 8750
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.205008029937744,
      "learning_rate": 4.523381859300968e-06,
      "loss": 0.4251,
      "step": 8760
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.201176643371582,
      "learning_rate": 4.502859468816822e-06,
      "loss": 0.3814,
      "step": 8770
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.5772249698638916,
      "learning_rate": 4.482370203048052e-06,
      "loss": 0.3928,
      "step": 8780
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.555835723876953,
      "learning_rate": 4.461914185459039e-06,
      "loss": 0.3898,
      "step": 8790
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.836660623550415,
      "learning_rate": 4.441491539313828e-06,
      "loss": 0.407,
      "step": 8800
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.604099750518799,
      "learning_rate": 4.421102387675376e-06,
      "loss": 0.3643,
      "step": 8810
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.308995008468628,
      "learning_rate": 4.400746853404795e-06,
      "loss": 0.4097,
      "step": 8820
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.3131651878356934,
      "learning_rate": 4.380425059160638e-06,
      "loss": 0.4169,
      "step": 8830
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.6960439682006836,
      "learning_rate": 4.360137127398141e-06,
      "loss": 0.411,
      "step": 8840
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.5986807346343994,
      "learning_rate": 4.3398831803684984e-06,
      "loss": 0.403,
      "step": 8850
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.747532606124878,
      "learning_rate": 4.319663340118105e-06,
      "loss": 0.392,
      "step": 8860
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.767754554748535,
      "learning_rate": 4.299477728487848e-06,
      "loss": 0.3806,
      "step": 8870
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.836519718170166,
      "learning_rate": 4.279326467112355e-06,
      "loss": 0.4048,
      "step": 8880
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.2731173038482666,
      "learning_rate": 4.259209677419263e-06,
      "loss": 0.4056,
      "step": 8890
    },
    {
      "epoch": 2.09,
      "grad_norm": 3.088973045349121,
      "learning_rate": 4.239127480628493e-06,
      "loss": 0.3595,
      "step": 8900
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.9384567737579346,
      "learning_rate": 4.219079997751515e-06,
      "loss": 0.4016,
      "step": 8910
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.192263126373291,
      "learning_rate": 4.199067349590621e-06,
      "loss": 0.3743,
      "step": 8920
    },
    {
      "epoch": 2.09,
      "grad_norm": 3.193791389465332,
      "learning_rate": 4.179089656738188e-06,
      "loss": 0.3926,
      "step": 8930
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.0479860305786133,
      "learning_rate": 4.159147039575966e-06,
      "loss": 0.3893,
      "step": 8940
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.614553928375244,
      "learning_rate": 4.13923961827435e-06,
      "loss": 0.3739,
      "step": 8950
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.3922536373138428,
      "learning_rate": 4.119367512791638e-06,
      "loss": 0.4226,
      "step": 8960
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.0778346061706543,
      "learning_rate": 4.099530842873333e-06,
      "loss": 0.4236,
      "step": 8970
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.9641613960266113,
      "learning_rate": 4.079729728051405e-06,
      "loss": 0.3714,
      "step": 8980
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.66074800491333,
      "learning_rate": 4.059964287643583e-06,
      "loss": 0.4034,
      "step": 8990
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.3668508529663086,
      "learning_rate": 4.0402346407526135e-06,
      "loss": 0.4041,
      "step": 9000
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.898232936859131,
      "learning_rate": 4.020540906265574e-06,
      "loss": 0.3644,
      "step": 9010
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.70735764503479,
      "learning_rate": 4.000883202853135e-06,
      "loss": 0.3756,
      "step": 9020
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.9705519676208496,
      "learning_rate": 3.981261648968846e-06,
      "loss": 0.3882,
      "step": 9030
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.218613624572754,
      "learning_rate": 3.961676362848432e-06,
      "loss": 0.3785,
      "step": 9040
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.495288133621216,
      "learning_rate": 3.942127462509074e-06,
      "loss": 0.4008,
      "step": 9050
    },
    {
      "epoch": 2.12,
      "grad_norm": 3.1823835372924805,
      "learning_rate": 3.9226150657487e-06,
      "loss": 0.3855,
      "step": 9060
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.732357382774353,
      "learning_rate": 3.903139290145274e-06,
      "loss": 0.3948,
      "step": 9070
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.9666528701782227,
      "learning_rate": 3.883700253056085e-06,
      "loss": 0.4046,
      "step": 9080
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.0271778106689453,
      "learning_rate": 3.864298071617051e-06,
      "loss": 0.3904,
      "step": 9090
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.929211139678955,
      "learning_rate": 3.844932862741991e-06,
      "loss": 0.382,
      "step": 9100
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.370004177093506,
      "learning_rate": 3.825604743121947e-06,
      "loss": 0.3734,
      "step": 9110
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.812628746032715,
      "learning_rate": 3.8063138292244616e-06,
      "loss": 0.4164,
      "step": 9120
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.3857364654541016,
      "learning_rate": 3.7870602372928923e-06,
      "loss": 0.391,
      "step": 9130
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.0652713775634766,
      "learning_rate": 3.767844083345683e-06,
      "loss": 0.3557,
      "step": 9140
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.510103702545166,
      "learning_rate": 3.7486654831757018e-06,
      "loss": 0.405,
      "step": 9150
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.649291515350342,
      "learning_rate": 3.7295245523495194e-06,
      "loss": 0.3822,
      "step": 9160
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.192020893096924,
      "learning_rate": 3.710421406206711e-06,
      "loss": 0.4065,
      "step": 9170
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.2358734607696533,
      "learning_rate": 3.6913561598591775e-06,
      "loss": 0.393,
      "step": 9180
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.5899245738983154,
      "learning_rate": 3.6723289281904383e-06,
      "loss": 0.3652,
      "step": 9190
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.0858638286590576,
      "learning_rate": 3.653339825854951e-06,
      "loss": 0.3408,
      "step": 9200
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.7746856212615967,
      "learning_rate": 3.6343889672773993e-06,
      "loss": 0.4191,
      "step": 9210
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.89181387424469,
      "learning_rate": 3.615476466652028e-06,
      "loss": 0.4006,
      "step": 9220
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.350372552871704,
      "learning_rate": 3.5966024379419416e-06,
      "loss": 0.4038,
      "step": 9230
    },
    {
      "epoch": 2.17,
      "grad_norm": 4.003699779510498,
      "learning_rate": 3.5777669948784212e-06,
      "loss": 0.3683,
      "step": 9240
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.270850658416748,
      "learning_rate": 3.5589702509602364e-06,
      "loss": 0.3861,
      "step": 9250
    },
    {
      "epoch": 2.17,
      "grad_norm": 2.827578067779541,
      "learning_rate": 3.5402123194529635e-06,
      "loss": 0.3826,
      "step": 9260
    },
    {
      "epoch": 2.17,
      "grad_norm": 2.1912269592285156,
      "learning_rate": 3.521493313388307e-06,
      "loss": 0.3993,
      "step": 9270
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.813685655593872,
      "learning_rate": 3.502813345563403e-06,
      "loss": 0.3845,
      "step": 9280
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.463724136352539,
      "learning_rate": 3.4841725285401617e-06,
      "loss": 0.3636,
      "step": 9290
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.6514055728912354,
      "learning_rate": 3.4655709746445767e-06,
      "loss": 0.3731,
      "step": 9300
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.833357572555542,
      "learning_rate": 3.4470087959660403e-06,
      "loss": 0.3815,
      "step": 9310
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.8226606845855713,
      "learning_rate": 3.4284861043566884e-06,
      "loss": 0.3827,
      "step": 9320
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.3005518913269043,
      "learning_rate": 3.4100030114307103e-06,
      "loss": 0.3675,
      "step": 9330
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.0613551139831543,
      "learning_rate": 3.3915596285636843e-06,
      "loss": 0.3819,
      "step": 9340
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.143155813217163,
      "learning_rate": 3.3731560668918963e-06,
      "loss": 0.3839,
      "step": 9350
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.536623001098633,
      "learning_rate": 3.3547924373116836e-06,
      "loss": 0.353,
      "step": 9360
    },
    {
      "epoch": 2.2,
      "grad_norm": 4.5732808113098145,
      "learning_rate": 3.3364688504787634e-06,
      "loss": 0.3707,
      "step": 9370
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.5751781463623047,
      "learning_rate": 3.318185416807551e-06,
      "loss": 0.4136,
      "step": 9380
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.441108465194702,
      "learning_rate": 3.2999422464705176e-06,
      "loss": 0.3715,
      "step": 9390
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.4601709842681885,
      "learning_rate": 3.281739449397512e-06,
      "loss": 0.389,
      "step": 9400
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.976980209350586,
      "learning_rate": 3.263577135275101e-06,
      "loss": 0.3964,
      "step": 9410
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.7868874073028564,
      "learning_rate": 3.2454554135459073e-06,
      "loss": 0.3753,
      "step": 9420
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.8872528076171875,
      "learning_rate": 3.2273743934079548e-06,
      "loss": 0.3974,
      "step": 9430
    },
    {
      "epoch": 2.21,
      "grad_norm": 4.353122711181641,
      "learning_rate": 3.2093341838140045e-06,
      "loss": 0.3719,
      "step": 9440
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.101534366607666,
      "learning_rate": 3.1913348934709076e-06,
      "loss": 0.3946,
      "step": 9450
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.3232064247131348,
      "learning_rate": 3.1733766308389303e-06,
      "loss": 0.3931,
      "step": 9460
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.7429261207580566,
      "learning_rate": 3.1554595041311243e-06,
      "loss": 0.4239,
      "step": 9470
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.1902987957000732,
      "learning_rate": 3.1375836213126653e-06,
      "loss": 0.3902,
      "step": 9480
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.4730403423309326,
      "learning_rate": 3.1197490901001925e-06,
      "loss": 0.3592,
      "step": 9490
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.35923171043396,
      "learning_rate": 3.101956017961175e-06,
      "loss": 0.4074,
      "step": 9500
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.973860263824463,
      "learning_rate": 3.0842045121132546e-06,
      "loss": 0.435,
      "step": 9510
    },
    {
      "epoch": 2.23,
      "grad_norm": 3.817166566848755,
      "learning_rate": 3.0664946795236096e-06,
      "loss": 0.3809,
      "step": 9520
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.428107261657715,
      "learning_rate": 3.048826626908289e-06,
      "loss": 0.3768,
      "step": 9530
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.654602527618408,
      "learning_rate": 3.031200460731595e-06,
      "loss": 0.3967,
      "step": 9540
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.4655317068099976,
      "learning_rate": 3.013616287205431e-06,
      "loss": 0.3763,
      "step": 9550
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.632425308227539,
      "learning_rate": 2.99607421228865e-06,
      "loss": 0.359,
      "step": 9560
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.5488102436065674,
      "learning_rate": 2.9785743416864378e-06,
      "loss": 0.401,
      "step": 9570
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.292022228240967,
      "learning_rate": 2.96111678084966e-06,
      "loss": 0.3729,
      "step": 9580
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.009103298187256,
      "learning_rate": 2.9437016349742332e-06,
      "loss": 0.3944,
      "step": 9590
    },
    {
      "epoch": 2.25,
      "grad_norm": 3.6498894691467285,
      "learning_rate": 2.926329009000489e-06,
      "loss": 0.3557,
      "step": 9600
    },
    {
      "epoch": 2.25,
      "grad_norm": 3.0054640769958496,
      "learning_rate": 2.908999007612542e-06,
      "loss": 0.3726,
      "step": 9610
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.6946535110473633,
      "learning_rate": 2.8917117352376623e-06,
      "loss": 0.4007,
      "step": 9620
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.2552292346954346,
      "learning_rate": 2.8744672960456345e-06,
      "loss": 0.4113,
      "step": 9630
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.0078799724578857,
      "learning_rate": 2.8572657939481476e-06,
      "loss": 0.3891,
      "step": 9640
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.7434916496276855,
      "learning_rate": 2.8401073325981565e-06,
      "loss": 0.3973,
      "step": 9650
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.4723057746887207,
      "learning_rate": 2.8229920153892653e-06,
      "loss": 0.4057,
      "step": 9660
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.0995378494262695,
      "learning_rate": 2.8059199454550866e-06,
      "loss": 0.4215,
      "step": 9670
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.9050135612487793,
      "learning_rate": 2.7888912256686486e-06,
      "loss": 0.3659,
      "step": 9680
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.907557249069214,
      "learning_rate": 2.771905958641754e-06,
      "loss": 0.3523,
      "step": 9690
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.8512353897094727,
      "learning_rate": 2.754964246724361e-06,
      "loss": 0.4126,
      "step": 9700
    },
    {
      "epoch": 2.28,
      "grad_norm": 3.226012706756592,
      "learning_rate": 2.738066192003983e-06,
      "loss": 0.3808,
      "step": 9710
    },
    {
      "epoch": 2.28,
      "grad_norm": 3.948450803756714,
      "learning_rate": 2.721211896305059e-06,
      "loss": 0.37,
      "step": 9720
    },
    {
      "epoch": 2.28,
      "grad_norm": 4.303784370422363,
      "learning_rate": 2.7044014611883484e-06,
      "loss": 0.3454,
      "step": 9730
    },
    {
      "epoch": 2.28,
      "grad_norm": 4.263374328613281,
      "learning_rate": 2.687634987950304e-06,
      "loss": 0.3986,
      "step": 9740
    },
    {
      "epoch": 2.29,
      "grad_norm": 3.2843267917633057,
      "learning_rate": 2.6709125776224853e-06,
      "loss": 0.3376,
      "step": 9750
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.806291103363037,
      "learning_rate": 2.6542343309709307e-06,
      "loss": 0.3405,
      "step": 9760
    },
    {
      "epoch": 2.29,
      "grad_norm": 4.383668899536133,
      "learning_rate": 2.6376003484955604e-06,
      "loss": 0.3776,
      "step": 9770
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.9362993240356445,
      "learning_rate": 2.6210107304295627e-06,
      "loss": 0.3931,
      "step": 9780
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.88704514503479,
      "learning_rate": 2.604465576738798e-06,
      "loss": 0.4012,
      "step": 9790
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.767136335372925,
      "learning_rate": 2.5879649871211954e-06,
      "loss": 0.367,
      "step": 9800
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.894627571105957,
      "learning_rate": 2.5715090610061376e-06,
      "loss": 0.3936,
      "step": 9810
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.054836750030518,
      "learning_rate": 2.5550978975538878e-06,
      "loss": 0.3455,
      "step": 9820
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.480489492416382,
      "learning_rate": 2.538731595654972e-06,
      "loss": 0.4006,
      "step": 9830
    },
    {
      "epoch": 2.31,
      "grad_norm": 1.9834613800048828,
      "learning_rate": 2.522410253929585e-06,
      "loss": 0.3292,
      "step": 9840
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.346869468688965,
      "learning_rate": 2.506133970727006e-06,
      "loss": 0.4189,
      "step": 9850
    },
    {
      "epoch": 2.31,
      "grad_norm": 3.562286138534546,
      "learning_rate": 2.4899028441249994e-06,
      "loss": 0.4108,
      "step": 9860
    },
    {
      "epoch": 2.31,
      "grad_norm": 3.2093968391418457,
      "learning_rate": 2.4737169719292265e-06,
      "loss": 0.411,
      "step": 9870
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.128685235977173,
      "learning_rate": 2.4575764516726443e-06,
      "loss": 0.3741,
      "step": 9880
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.768772840499878,
      "learning_rate": 2.4414813806149383e-06,
      "loss": 0.3891,
      "step": 9890
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.355452299118042,
      "learning_rate": 2.4254318557419256e-06,
      "loss": 0.4241,
      "step": 9900
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.7831993103027344,
      "learning_rate": 2.4094279737649617e-06,
      "loss": 0.3596,
      "step": 9910
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.4763031005859375,
      "learning_rate": 2.393469831120374e-06,
      "loss": 0.4025,
      "step": 9920
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.3505165576934814,
      "learning_rate": 2.377557523968872e-06,
      "loss": 0.3479,
      "step": 9930
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.6916604042053223,
      "learning_rate": 2.361691148194971e-06,
      "loss": 0.3959,
      "step": 9940
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.3710107803344727,
      "learning_rate": 2.345870799406409e-06,
      "loss": 0.3896,
      "step": 9950
    },
    {
      "epoch": 2.33,
      "grad_norm": 1.5621559619903564,
      "learning_rate": 2.3300965729335766e-06,
      "loss": 0.3308,
      "step": 9960
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.944754123687744,
      "learning_rate": 2.3143685638289427e-06,
      "loss": 0.3782,
      "step": 9970
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.4713783264160156,
      "learning_rate": 2.2986868668664695e-06,
      "loss": 0.4115,
      "step": 9980
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.843522548675537,
      "learning_rate": 2.283051576541062e-06,
      "loss": 0.3849,
      "step": 9990
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.923384428024292,
      "learning_rate": 2.267462787067981e-06,
      "loss": 0.3363,
      "step": 10000
    },
    {
      "epoch": 2.35,
      "grad_norm": 3.479248285293579,
      "learning_rate": 2.2519205923822894e-06,
      "loss": 0.3613,
      "step": 10010
    },
    {
      "epoch": 2.35,
      "grad_norm": 3.8600308895111084,
      "learning_rate": 2.2364250861382684e-06,
      "loss": 0.4037,
      "step": 10020
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.1725454330444336,
      "learning_rate": 2.2209763617088697e-06,
      "loss": 0.3943,
      "step": 10030
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.546734094619751,
      "learning_rate": 2.2055745121851512e-06,
      "loss": 0.3683,
      "step": 10040
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.9342422485351562,
      "learning_rate": 2.1902196303756994e-06,
      "loss": 0.3852,
      "step": 10050
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.60894513130188,
      "learning_rate": 2.174911808806094e-06,
      "loss": 0.3795,
      "step": 10060
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.6537396907806396,
      "learning_rate": 2.1596511397183315e-06,
      "loss": 0.3644,
      "step": 10070
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.5633394718170166,
      "learning_rate": 2.1444377150702845e-06,
      "loss": 0.3791,
      "step": 10080
    },
    {
      "epoch": 2.37,
      "grad_norm": 3.4576332569122314,
      "learning_rate": 2.1292716265351278e-06,
      "loss": 0.4154,
      "step": 10090
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.9501338005065918,
      "learning_rate": 2.1141529655008065e-06,
      "loss": 0.4244,
      "step": 10100
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.7130937576293945,
      "learning_rate": 2.0990818230694764e-06,
      "loss": 0.374,
      "step": 10110
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.9744243621826172,
      "learning_rate": 2.084058290056956e-06,
      "loss": 0.358,
      "step": 10120
    },
    {
      "epoch": 2.37,
      "grad_norm": 3.9309871196746826,
      "learning_rate": 2.0690824569921696e-06,
      "loss": 0.3813,
      "step": 10130
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.138256549835205,
      "learning_rate": 2.0541544141166214e-06,
      "loss": 0.3814,
      "step": 10140
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.715277671813965,
      "learning_rate": 2.0392742513838347e-06,
      "loss": 0.3991,
      "step": 10150
    },
    {
      "epoch": 2.38,
      "grad_norm": 4.771007537841797,
      "learning_rate": 2.0244420584588207e-06,
      "loss": 0.3737,
      "step": 10160
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.302447557449341,
      "learning_rate": 2.009657924717532e-06,
      "loss": 0.363,
      "step": 10170
    },
    {
      "epoch": 2.39,
      "grad_norm": 3.3276658058166504,
      "learning_rate": 1.994921939246326e-06,
      "loss": 0.375,
      "step": 10180
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.537552833557129,
      "learning_rate": 1.980234190841421e-06,
      "loss": 0.3923,
      "step": 10190
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.603708267211914,
      "learning_rate": 1.965594768008381e-06,
      "loss": 0.3587,
      "step": 10200
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.627779483795166,
      "learning_rate": 1.951003758961558e-06,
      "loss": 0.4015,
      "step": 10210
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.0792691707611084,
      "learning_rate": 1.9364612516235816e-06,
      "loss": 0.3562,
      "step": 10220
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.2021331787109375,
      "learning_rate": 1.921967333624808e-06,
      "loss": 0.4059,
      "step": 10230
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.5363831520080566,
      "learning_rate": 1.9075220923028114e-06,
      "loss": 0.3736,
      "step": 10240
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.2585349082946777,
      "learning_rate": 1.8931256147018518e-06,
      "loss": 0.3604,
      "step": 10250
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.832237958908081,
      "learning_rate": 1.8787779875723389e-06,
      "loss": 0.3852,
      "step": 10260
    },
    {
      "epoch": 2.41,
      "grad_norm": 3.0897152423858643,
      "learning_rate": 1.8644792973703252e-06,
      "loss": 0.3519,
      "step": 10270
    },
    {
      "epoch": 2.41,
      "grad_norm": 5.072335720062256,
      "learning_rate": 1.85022963025698e-06,
      "loss": 0.391,
      "step": 10280
    },
    {
      "epoch": 2.41,
      "grad_norm": 4.547714710235596,
      "learning_rate": 1.8360290720980666e-06,
      "loss": 0.3475,
      "step": 10290
    },
    {
      "epoch": 2.41,
      "grad_norm": 3.4344189167022705,
      "learning_rate": 1.8218777084634243e-06,
      "loss": 0.3974,
      "step": 10300
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.274144172668457,
      "learning_rate": 1.8077756246264588e-06,
      "loss": 0.3767,
      "step": 10310
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.107835292816162,
      "learning_rate": 1.7937229055636264e-06,
      "loss": 0.3767,
      "step": 10320
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.386108160018921,
      "learning_rate": 1.7797196359539182e-06,
      "loss": 0.4117,
      "step": 10330
    },
    {
      "epoch": 2.42,
      "grad_norm": 4.066636562347412,
      "learning_rate": 1.7657659001783545e-06,
      "loss": 0.3434,
      "step": 10340
    },
    {
      "epoch": 2.43,
      "grad_norm": 4.271104335784912,
      "learning_rate": 1.7518617823194705e-06,
      "loss": 0.3811,
      "step": 10350
    },
    {
      "epoch": 2.43,
      "grad_norm": 3.1811959743499756,
      "learning_rate": 1.738007366160821e-06,
      "loss": 0.3805,
      "step": 10360
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.7323389053344727,
      "learning_rate": 1.7242027351864576e-06,
      "loss": 0.4173,
      "step": 10370
    },
    {
      "epoch": 2.43,
      "grad_norm": 1.5881712436676025,
      "learning_rate": 1.7104479725804413e-06,
      "loss": 0.4131,
      "step": 10380
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.6099812984466553,
      "learning_rate": 1.6967431612263397e-06,
      "loss": 0.3611,
      "step": 10390
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.125607967376709,
      "learning_rate": 1.6830883837067147e-06,
      "loss": 0.4071,
      "step": 10400
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.87692928314209,
      "learning_rate": 1.6694837223026405e-06,
      "loss": 0.4012,
      "step": 10410
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.396075487136841,
      "learning_rate": 1.6559292589932007e-06,
      "loss": 0.3906,
      "step": 10420
    },
    {
      "epoch": 2.44,
      "grad_norm": 4.004175662994385,
      "learning_rate": 1.6424250754549953e-06,
      "loss": 0.3756,
      "step": 10430
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.079820156097412,
      "learning_rate": 1.628971253061642e-06,
      "loss": 0.3767,
      "step": 10440
    },
    {
      "epoch": 2.45,
      "grad_norm": 3.421445846557617,
      "learning_rate": 1.615567872883298e-06,
      "loss": 0.407,
      "step": 10450
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.709463357925415,
      "learning_rate": 1.602215015686166e-06,
      "loss": 0.4022,
      "step": 10460
    },
    {
      "epoch": 2.45,
      "grad_norm": 1.8369698524475098,
      "learning_rate": 1.5889127619319998e-06,
      "loss": 0.3679,
      "step": 10470
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.871640682220459,
      "learning_rate": 1.5756611917776344e-06,
      "loss": 0.3647,
      "step": 10480
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.5096709728240967,
      "learning_rate": 1.5624603850744924e-06,
      "loss": 0.4194,
      "step": 10490
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.3804550170898438,
      "learning_rate": 1.549310421368103e-06,
      "loss": 0.4072,
      "step": 10500
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.824488878250122,
      "learning_rate": 1.5362113798976297e-06,
      "loss": 0.4096,
      "step": 10510
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.9721462726593018,
      "learning_rate": 1.523163339595385e-06,
      "loss": 0.4042,
      "step": 10520
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.6367759704589844,
      "learning_rate": 1.5101663790863597e-06,
      "loss": 0.3822,
      "step": 10530
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.6138715744018555,
      "learning_rate": 1.497220576687749e-06,
      "loss": 0.3791,
      "step": 10540
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.334911584854126,
      "learning_rate": 1.4843260104084734e-06,
      "loss": 0.3425,
      "step": 10550
    },
    {
      "epoch": 2.48,
      "grad_norm": 3.2606217861175537,
      "learning_rate": 1.471482757948719e-06,
      "loss": 0.409,
      "step": 10560
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.5642940998077393,
      "learning_rate": 1.4586908966994672e-06,
      "loss": 0.4042,
      "step": 10570
    },
    {
      "epoch": 2.48,
      "grad_norm": 3.3610050678253174,
      "learning_rate": 1.4459505037420186e-06,
      "loss": 0.3944,
      "step": 10580
    },
    {
      "epoch": 2.48,
      "grad_norm": 4.160482883453369,
      "learning_rate": 1.43326165584754e-06,
      "loss": 0.3996,
      "step": 10590
    },
    {
      "epoch": 2.48,
      "grad_norm": 3.8800241947174072,
      "learning_rate": 1.4206244294765981e-06,
      "loss": 0.3704,
      "step": 10600
    },
    {
      "epoch": 2.49,
      "grad_norm": 3.6919877529144287,
      "learning_rate": 1.4080389007787009e-06,
      "loss": 0.4195,
      "step": 10610
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.1619300842285156,
      "learning_rate": 1.3955051455918257e-06,
      "loss": 0.3815,
      "step": 10620
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.0310404300689697,
      "learning_rate": 1.3830232394419818e-06,
      "loss": 0.3943,
      "step": 10630
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.292635679244995,
      "learning_rate": 1.3705932575427472e-06,
      "loss": 0.4225,
      "step": 10640
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.8091516494750977,
      "learning_rate": 1.3582152747948052e-06,
      "loss": 0.3548,
      "step": 10650
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.4524617195129395,
      "learning_rate": 1.345889365785511e-06,
      "loss": 0.3795,
      "step": 10660
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.990755081176758,
      "learning_rate": 1.3336156047884285e-06,
      "loss": 0.3591,
      "step": 10670
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.614517688751221,
      "learning_rate": 1.321394065762891e-06,
      "loss": 0.3852,
      "step": 10680
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.6699728965759277,
      "learning_rate": 1.3092248223535498e-06,
      "loss": 0.3744,
      "step": 10690
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.644176721572876,
      "learning_rate": 1.2971079478899328e-06,
      "loss": 0.397,
      "step": 10700
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.466343879699707,
      "learning_rate": 1.2850435153860075e-06,
      "loss": 0.3834,
      "step": 10710
    },
    {
      "epoch": 2.51,
      "grad_norm": 4.884903430938721,
      "learning_rate": 1.2730315975397267e-06,
      "loss": 0.3933,
      "step": 10720
    },
    {
      "epoch": 2.52,
      "grad_norm": 5.263946533203125,
      "learning_rate": 1.261072266732607e-06,
      "loss": 0.402,
      "step": 10730
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.875532865524292,
      "learning_rate": 1.2491655950292848e-06,
      "loss": 0.3634,
      "step": 10740
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.3294451236724854,
      "learning_rate": 1.2373116541770836e-06,
      "loss": 0.3856,
      "step": 10750
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.0804154872894287,
      "learning_rate": 1.2255105156055757e-06,
      "loss": 0.4333,
      "step": 10760
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.4845120906829834,
      "learning_rate": 1.2137622504261626e-06,
      "loss": 0.4192,
      "step": 10770
    },
    {
      "epoch": 2.53,
      "grad_norm": 4.4185943603515625,
      "learning_rate": 1.20206692943164e-06,
      "loss": 0.3811,
      "step": 10780
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.7194368839263916,
      "learning_rate": 1.1904246230957684e-06,
      "loss": 0.3856,
      "step": 10790
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.3055598735809326,
      "learning_rate": 1.1788354015728543e-06,
      "loss": 0.3954,
      "step": 10800
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.361755847930908,
      "learning_rate": 1.1672993346973283e-06,
      "loss": 0.4158,
      "step": 10810
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.892812728881836,
      "learning_rate": 1.1558164919833193e-06,
      "loss": 0.3549,
      "step": 10820
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.2370967864990234,
      "learning_rate": 1.1443869426242326e-06,
      "loss": 0.3478,
      "step": 10830
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.5568082332611084,
      "learning_rate": 1.1330107554923453e-06,
      "loss": 0.3559,
      "step": 10840
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.893488645553589,
      "learning_rate": 1.12168799913838e-06,
      "loss": 0.3724,
      "step": 10850
    },
    {
      "epoch": 2.55,
      "grad_norm": 5.066401958465576,
      "learning_rate": 1.1104187417910971e-06,
      "loss": 0.3505,
      "step": 10860
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.725731134414673,
      "learning_rate": 1.0992030513568808e-06,
      "loss": 0.3691,
      "step": 10870
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.910102605819702,
      "learning_rate": 1.0880409954193338e-06,
      "loss": 0.3808,
      "step": 10880
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.351019859313965,
      "learning_rate": 1.076932641238868e-06,
      "loss": 0.3708,
      "step": 10890
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.9762675762176514,
      "learning_rate": 1.0658780557522908e-06,
      "loss": 0.343,
      "step": 10900
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.104644298553467,
      "learning_rate": 1.0548773055724204e-06,
      "loss": 0.3832,
      "step": 10910
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.851790189743042,
      "learning_rate": 1.0439304569876697e-06,
      "loss": 0.3583,
      "step": 10920
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.63916277885437,
      "learning_rate": 1.0330375759616472e-06,
      "loss": 0.3731,
      "step": 10930
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.351245164871216,
      "learning_rate": 1.0221987281327684e-06,
      "loss": 0.3678,
      "step": 10940
    },
    {
      "epoch": 2.57,
      "grad_norm": 3.451423168182373,
      "learning_rate": 1.0114139788138522e-06,
      "loss": 0.371,
      "step": 10950
    },
    {
      "epoch": 2.57,
      "grad_norm": 4.588995933532715,
      "learning_rate": 1.0006833929917336e-06,
      "loss": 0.3922,
      "step": 10960
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.442748546600342,
      "learning_rate": 9.900070353268643e-07,
      "loss": 0.3685,
      "step": 10970
    },
    {
      "epoch": 2.57,
      "grad_norm": 3.175523281097412,
      "learning_rate": 9.79384970152928e-07,
      "loss": 0.3675,
      "step": 10980
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.803100824356079,
      "learning_rate": 9.68817261476459e-07,
      "loss": 0.3551,
      "step": 10990
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.734088659286499,
      "learning_rate": 9.583039729764388e-07,
      "loss": 0.3574,
      "step": 11000
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.0548362731933594,
      "learning_rate": 9.478451680039313e-07,
      "loss": 0.3867,
      "step": 11010
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.1878583431243896,
      "learning_rate": 9.374409095816928e-07,
      "loss": 0.4019,
      "step": 11020
    },
    {
      "epoch": 2.59,
      "grad_norm": 3.4004156589508057,
      "learning_rate": 9.270912604037874e-07,
      "loss": 0.4149,
      "step": 11030
    },
    {
      "epoch": 2.59,
      "grad_norm": 3.659848213195801,
      "learning_rate": 9.167962828352206e-07,
      "loss": 0.3511,
      "step": 11040
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.9497597217559814,
      "learning_rate": 9.065560389115536e-07,
      "loss": 0.3589,
      "step": 11050
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.7044689655303955,
      "learning_rate": 8.963705903385344e-07,
      "loss": 0.384,
      "step": 11060
    },
    {
      "epoch": 2.59,
      "grad_norm": 1.9762952327728271,
      "learning_rate": 8.862399984917214e-07,
      "loss": 0.3888,
      "step": 11070
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.657782793045044,
      "learning_rate": 8.761643244161211e-07,
      "loss": 0.341,
      "step": 11080
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.1777327060699463,
      "learning_rate": 8.661436288258163e-07,
      "loss": 0.4135,
      "step": 11090
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.227238178253174,
      "learning_rate": 8.561779721035978e-07,
      "loss": 0.3948,
      "step": 11100
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.7682294845581055,
      "learning_rate": 8.462674143006e-07,
      "loss": 0.3853,
      "step": 11110
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.740546703338623,
      "learning_rate": 8.364120151359478e-07,
      "loss": 0.3993,
      "step": 11120
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.679737091064453,
      "learning_rate": 8.266118339963891e-07,
      "loss": 0.3757,
      "step": 11130
    },
    {
      "epoch": 2.61,
      "grad_norm": 3.2048277854919434,
      "learning_rate": 8.168669299359334e-07,
      "loss": 0.375,
      "step": 11140
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.371166944503784,
      "learning_rate": 8.071773616755074e-07,
      "loss": 0.3841,
      "step": 11150
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.362480163574219,
      "learning_rate": 7.97543187602593e-07,
      "loss": 0.3983,
      "step": 11160
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.950016736984253,
      "learning_rate": 7.879644657708773e-07,
      "loss": 0.4125,
      "step": 11170
    },
    {
      "epoch": 2.62,
      "grad_norm": 5.351341724395752,
      "learning_rate": 7.784412538998997e-07,
      "loss": 0.3802,
      "step": 11180
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.3937830924987793,
      "learning_rate": 7.689736093747124e-07,
      "loss": 0.364,
      "step": 11190
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.6537110805511475,
      "learning_rate": 7.595615892455255e-07,
      "loss": 0.3861,
      "step": 11200
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.3515892028808594,
      "learning_rate": 7.502052502273682e-07,
      "loss": 0.3914,
      "step": 11210
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.1236095428466797,
      "learning_rate": 7.409046486997484e-07,
      "loss": 0.3721,
      "step": 11220
    },
    {
      "epoch": 2.63,
      "grad_norm": 3.5615248680114746,
      "learning_rate": 7.31659840706308e-07,
      "loss": 0.3773,
      "step": 11230
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.900974988937378,
      "learning_rate": 7.224708819544879e-07,
      "loss": 0.376,
      "step": 11240
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.8757340908050537,
      "learning_rate": 7.133378278151926e-07,
      "loss": 0.3696,
      "step": 11250
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.1902077198028564,
      "learning_rate": 7.042607333224549e-07,
      "loss": 0.413,
      "step": 11260
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.9412379264831543,
      "learning_rate": 6.952396531731087e-07,
      "loss": 0.3576,
      "step": 11270
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.5904691219329834,
      "learning_rate": 6.862746417264532e-07,
      "loss": 0.343,
      "step": 11280
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.5337886810302734,
      "learning_rate": 6.773657530039279e-07,
      "loss": 0.3692,
      "step": 11290
    },
    {
      "epoch": 2.65,
      "grad_norm": 3.9511945247650146,
      "learning_rate": 6.685130406887919e-07,
      "loss": 0.3971,
      "step": 11300
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.4803733825683594,
      "learning_rate": 6.597165581257914e-07,
      "loss": 0.3848,
      "step": 11310
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.956869125366211,
      "learning_rate": 6.509763583208451e-07,
      "loss": 0.3669,
      "step": 11320
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.4283440113067627,
      "learning_rate": 6.422924939407205e-07,
      "loss": 0.4174,
      "step": 11330
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.409334421157837,
      "learning_rate": 6.336650173127224e-07,
      "loss": 0.3854,
      "step": 11340
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.138591766357422,
      "learning_rate": 6.250939804243705e-07,
      "loss": 0.3446,
      "step": 11350
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.0040223598480225,
      "learning_rate": 6.165794349230891e-07,
      "loss": 0.3698,
      "step": 11360
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.6735284328460693,
      "learning_rate": 6.081214321159001e-07,
      "loss": 0.3484,
      "step": 11370
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.849212169647217,
      "learning_rate": 5.99720022969107e-07,
      "loss": 0.3829,
      "step": 11380
    },
    {
      "epoch": 2.67,
      "grad_norm": 3.8272147178649902,
      "learning_rate": 5.913752581079901e-07,
      "loss": 0.3892,
      "step": 11390
    },
    {
      "epoch": 2.67,
      "grad_norm": 4.034846305847168,
      "learning_rate": 5.830871878165045e-07,
      "loss": 0.4044,
      "step": 11400
    },
    {
      "epoch": 2.67,
      "grad_norm": 3.057882308959961,
      "learning_rate": 5.748558620369749e-07,
      "loss": 0.3673,
      "step": 11410
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.5725260972976685,
      "learning_rate": 5.666813303697893e-07,
      "loss": 0.4054,
      "step": 11420
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.075887441635132,
      "learning_rate": 5.5856364207311e-07,
      "loss": 0.3655,
      "step": 11430
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.829664945602417,
      "learning_rate": 5.505028460625728e-07,
      "loss": 0.395,
      "step": 11440
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.623361110687256,
      "learning_rate": 5.424989909109901e-07,
      "loss": 0.3987,
      "step": 11450
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.584177017211914,
      "learning_rate": 5.345521248480556e-07,
      "loss": 0.3765,
      "step": 11460
    },
    {
      "epoch": 2.69,
      "grad_norm": 3.137078046798706,
      "learning_rate": 5.266622957600643e-07,
      "loss": 0.3756,
      "step": 11470
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.7847135066986084,
      "learning_rate": 5.188295511896136e-07,
      "loss": 0.4045,
      "step": 11480
    },
    {
      "epoch": 2.69,
      "grad_norm": 3.6629209518432617,
      "learning_rate": 5.110539383353208e-07,
      "loss": 0.3741,
      "step": 11490
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.9027774333953857,
      "learning_rate": 5.033355040515386e-07,
      "loss": 0.4022,
      "step": 11500
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.1269962787628174,
      "learning_rate": 4.956742948480742e-07,
      "loss": 0.4044,
      "step": 11510
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.5231072902679443,
      "learning_rate": 4.880703568899047e-07,
      "loss": 0.3472,
      "step": 11520
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.9449763298034668,
      "learning_rate": 4.805237359969039e-07,
      "loss": 0.3905,
      "step": 11530
    },
    {
      "epoch": 2.71,
      "grad_norm": 5.7259521484375,
      "learning_rate": 4.730344776435625e-07,
      "loss": 0.4007,
      "step": 11540
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.601130723953247,
      "learning_rate": 4.656026269587155e-07,
      "loss": 0.3754,
      "step": 11550
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.8623437881469727,
      "learning_rate": 4.582282287252715e-07,
      "loss": 0.3948,
      "step": 11560
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.9097723960876465,
      "learning_rate": 4.509113273799415e-07,
      "loss": 0.4008,
      "step": 11570
    },
    {
      "epoch": 2.71,
      "grad_norm": 4.244448661804199,
      "learning_rate": 4.436519670129713e-07,
      "loss": 0.3847,
      "step": 11580
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.470428705215454,
      "learning_rate": 4.364501913678754e-07,
      "loss": 0.3538,
      "step": 11590
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.761895179748535,
      "learning_rate": 4.293060438411711e-07,
      "loss": 0.3518,
      "step": 11600
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.1638011932373047,
      "learning_rate": 4.222195674821239e-07,
      "loss": 0.4032,
      "step": 11610
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.8923568725585938,
      "learning_rate": 4.1519080499248243e-07,
      "loss": 0.3735,
      "step": 11620
    },
    {
      "epoch": 2.73,
      "grad_norm": 4.365993499755859,
      "learning_rate": 4.0821979872622487e-07,
      "loss": 0.397,
      "step": 11630
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.7389700412750244,
      "learning_rate": 4.0130659068929435e-07,
      "loss": 0.4241,
      "step": 11640
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.1027414798736572,
      "learning_rate": 3.944512225393593e-07,
      "loss": 0.3897,
      "step": 11650
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.7576842308044434,
      "learning_rate": 3.8765373558555695e-07,
      "loss": 0.3297,
      "step": 11660
    },
    {
      "epoch": 2.74,
      "grad_norm": 4.3896660804748535,
      "learning_rate": 3.80914170788238e-07,
      "loss": 0.3428,
      "step": 11670
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.927300214767456,
      "learning_rate": 3.7423256875872895e-07,
      "loss": 0.3747,
      "step": 11680
    },
    {
      "epoch": 2.74,
      "grad_norm": 4.0605034828186035,
      "learning_rate": 3.676089697590846e-07,
      "loss": 0.3766,
      "step": 11690
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.318037509918213,
      "learning_rate": 3.610434137018426e-07,
      "loss": 0.3848,
      "step": 11700
    },
    {
      "epoch": 2.74,
      "grad_norm": 4.039327144622803,
      "learning_rate": 3.545359401497839e-07,
      "loss": 0.3769,
      "step": 11710
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.8590893745422363,
      "learning_rate": 3.480865883156992e-07,
      "loss": 0.3889,
      "step": 11720
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.0854382514953613,
      "learning_rate": 3.4169539706214503e-07,
      "loss": 0.3857,
      "step": 11730
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.4471588134765625,
      "learning_rate": 3.353624049012161e-07,
      "loss": 0.3551,
      "step": 11740
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.8320484161376953,
      "learning_rate": 3.290876499943096e-07,
      "loss": 0.4341,
      "step": 11750
    },
    {
      "epoch": 2.76,
      "grad_norm": 3.905731678009033,
      "learning_rate": 3.228711701518961e-07,
      "loss": 0.404,
      "step": 11760
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.7810447216033936,
      "learning_rate": 3.167130028332921e-07,
      "loss": 0.392,
      "step": 11770
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.8259286880493164,
      "learning_rate": 3.1061318514643226e-07,
      "loss": 0.4003,
      "step": 11780
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.0525779724121094,
      "learning_rate": 3.0457175384764894e-07,
      "loss": 0.364,
      "step": 11790
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.7873775959014893,
      "learning_rate": 2.9858874534145267e-07,
      "loss": 0.3618,
      "step": 11800
    },
    {
      "epoch": 2.77,
      "grad_norm": 3.0628552436828613,
      "learning_rate": 2.9266419568030224e-07,
      "loss": 0.4144,
      "step": 11810
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.218933343887329,
      "learning_rate": 2.8679814056439936e-07,
      "loss": 0.3772,
      "step": 11820
    },
    {
      "epoch": 2.77,
      "grad_norm": 1.699150800704956,
      "learning_rate": 2.8099061534146877e-07,
      "loss": 0.3886,
      "step": 11830
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.082019329071045,
      "learning_rate": 2.752416550065462e-07,
      "loss": 0.3976,
      "step": 11840
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.5119099617004395,
      "learning_rate": 2.6955129420176193e-07,
      "loss": 0.3825,
      "step": 11850
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.077516555786133,
      "learning_rate": 2.6391956721614096e-07,
      "loss": 0.3639,
      "step": 11860
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.875473737716675,
      "learning_rate": 2.5834650798539087e-07,
      "loss": 0.3207,
      "step": 11870
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.1974143981933594,
      "learning_rate": 2.528321500916986e-07,
      "loss": 0.4094,
      "step": 11880
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.425230026245117,
      "learning_rate": 2.4737652676352755e-07,
      "loss": 0.3782,
      "step": 11890
    },
    {
      "epoch": 2.79,
      "grad_norm": 4.115848064422607,
      "learning_rate": 2.419796708754185e-07,
      "loss": 0.3977,
      "step": 11900
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.987154483795166,
      "learning_rate": 2.3664161494779015e-07,
      "loss": 0.3889,
      "step": 11910
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.6865129470825195,
      "learning_rate": 2.3136239114674774e-07,
      "loss": 0.371,
      "step": 11920
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.923612594604492,
      "learning_rate": 2.26142031283878e-07,
      "loss": 0.4005,
      "step": 11930
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.366070032119751,
      "learning_rate": 2.2098056681607138e-07,
      "loss": 0.413,
      "step": 11940
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.5388269424438477,
      "learning_rate": 2.1587802884532328e-07,
      "loss": 0.4164,
      "step": 11950
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.3580970764160156,
      "learning_rate": 2.108344481185487e-07,
      "loss": 0.3488,
      "step": 11960
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.5700790882110596,
      "learning_rate": 2.0584985502740018e-07,
      "loss": 0.3721,
      "step": 11970
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.6368393898010254,
      "learning_rate": 2.0092427960808015e-07,
      "loss": 0.3583,
      "step": 11980
    },
    {
      "epoch": 2.81,
      "grad_norm": 3.029144763946533,
      "learning_rate": 1.9605775154116103e-07,
      "loss": 0.3904,
      "step": 11990
    },
    {
      "epoch": 2.81,
      "grad_norm": 3.990659236907959,
      "learning_rate": 1.9125030015140878e-07,
      "loss": 0.369,
      "step": 12000
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.0248043537139893,
      "learning_rate": 1.865019544076052e-07,
      "loss": 0.3784,
      "step": 12010
    },
    {
      "epoch": 2.82,
      "grad_norm": 4.045870304107666,
      "learning_rate": 1.8181274292236928e-07,
      "loss": 0.4233,
      "step": 12020
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.6931400299072266,
      "learning_rate": 1.7718269395199272e-07,
      "loss": 0.3384,
      "step": 12030
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.9686943292617798,
      "learning_rate": 1.7261183539626358e-07,
      "loss": 0.3661,
      "step": 12040
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.0518999099731445,
      "learning_rate": 1.6810019479829964e-07,
      "loss": 0.3454,
      "step": 12050
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.3656809329986572,
      "learning_rate": 1.636477993443808e-07,
      "loss": 0.3843,
      "step": 12060
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.3163890838623047,
      "learning_rate": 1.592546758637903e-07,
      "loss": 0.3781,
      "step": 12070
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.6899404525756836,
      "learning_rate": 1.5492085082864815e-07,
      "loss": 0.3676,
      "step": 12080
    },
    {
      "epoch": 2.83,
      "grad_norm": 3.966268539428711,
      "learning_rate": 1.5064635035375252e-07,
      "loss": 0.4211,
      "step": 12090
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.9691076278686523,
      "learning_rate": 1.464312001964252e-07,
      "loss": 0.375,
      "step": 12100
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.7826614379882812,
      "learning_rate": 1.422754257563519e-07,
      "loss": 0.3845,
      "step": 12110
    },
    {
      "epoch": 2.84,
      "grad_norm": 4.1369781494140625,
      "learning_rate": 1.3817905207543558e-07,
      "loss": 0.3717,
      "step": 12120
    },
    {
      "epoch": 2.84,
      "grad_norm": 3.525137186050415,
      "learning_rate": 1.3414210383763672e-07,
      "loss": 0.3561,
      "step": 12130
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.507636308670044,
      "learning_rate": 1.3016460536883213e-07,
      "loss": 0.4003,
      "step": 12140
    },
    {
      "epoch": 2.85,
      "grad_norm": 3.020801544189453,
      "learning_rate": 1.262465806366664e-07,
      "loss": 0.3749,
      "step": 12150
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.004884958267212,
      "learning_rate": 1.2238805325040404e-07,
      "loss": 0.3737,
      "step": 12160
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.8594006299972534,
      "learning_rate": 1.1858904646079306e-07,
      "loss": 0.377,
      "step": 12170
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.0575156211853027,
      "learning_rate": 1.1484958315991946e-07,
      "loss": 0.3861,
      "step": 12180
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.237276554107666,
      "learning_rate": 1.1116968588107401e-07,
      "loss": 0.3833,
      "step": 12190
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.583688497543335,
      "learning_rate": 1.0754937679861021e-07,
      "loss": 0.3567,
      "step": 12200
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.420612335205078,
      "learning_rate": 1.0398867772781874e-07,
      "loss": 0.3526,
      "step": 12210
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.827350616455078,
      "learning_rate": 1.0048761012478869e-07,
      "loss": 0.4146,
      "step": 12220
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.0952603816986084,
      "learning_rate": 9.704619508628222e-08,
      "loss": 0.3811,
      "step": 12230
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.5166516304016113,
      "learning_rate": 9.366445334960783e-08,
      "loss": 0.3643,
      "step": 12240
    },
    {
      "epoch": 2.87,
      "grad_norm": 3.8018903732299805,
      "learning_rate": 9.034240529249283e-08,
      "loss": 0.3758,
      "step": 12250
    },
    {
      "epoch": 2.87,
      "grad_norm": 3.5485246181488037,
      "learning_rate": 8.708007093296223e-08,
      "loss": 0.384,
      "step": 12260
    },
    {
      "epoch": 2.88,
      "grad_norm": 4.619715690612793,
      "learning_rate": 8.387746992921775e-08,
      "loss": 0.4024,
      "step": 12270
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.2958548069000244,
      "learning_rate": 8.073462157951906e-08,
      "loss": 0.3697,
      "step": 12280
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.802377462387085,
      "learning_rate": 7.765154482206715e-08,
      "loss": 0.3817,
      "step": 12290
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.8762433528900146,
      "learning_rate": 7.462825823489339e-08,
      "loss": 0.4205,
      "step": 12300
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.7600536346435547,
      "learning_rate": 7.166478003574173e-08,
      "loss": 0.3501,
      "step": 12310
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.4940383434295654,
      "learning_rate": 6.876112808196556e-08,
      "loss": 0.3735,
      "step": 12320
    },
    {
      "epoch": 2.89,
      "grad_norm": 3.093907594680786,
      "learning_rate": 6.591731987041439e-08,
      "loss": 0.4052,
      "step": 12330
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.8524112701416016,
      "learning_rate": 6.313337253733176e-08,
      "loss": 0.3702,
      "step": 12340
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.944607138633728,
      "learning_rate": 6.040930285824975e-08,
      "loss": 0.4022,
      "step": 12350
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.245241641998291,
      "learning_rate": 5.7745127247891275e-08,
      "loss": 0.3946,
      "step": 12360
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.105684280395508,
      "learning_rate": 5.5140861760067945e-08,
      "loss": 0.403,
      "step": 12370
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.717053174972534,
      "learning_rate": 5.259652208758348e-08,
      "loss": 0.3629,
      "step": 12380
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.302375078201294,
      "learning_rate": 5.011212356214157e-08,
      "loss": 0.3698,
      "step": 12390
    },
    {
      "epoch": 2.91,
      "grad_norm": 4.1521124839782715,
      "learning_rate": 4.7687681154253704e-08,
      "loss": 0.3793,
      "step": 12400
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.048163890838623,
      "learning_rate": 4.5323209473141506e-08,
      "loss": 0.3975,
      "step": 12410
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.5831704139709473,
      "learning_rate": 4.3018722766661194e-08,
      "loss": 0.4235,
      "step": 12420
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.6671104431152344,
      "learning_rate": 4.077423492120702e-08,
      "loss": 0.4185,
      "step": 12430
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.596649169921875,
      "learning_rate": 3.8589759461632456e-08,
      "loss": 0.4371,
      "step": 12440
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.7276511192321777,
      "learning_rate": 3.646530955116689e-08,
      "loss": 0.3382,
      "step": 12450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.6402902603149414,
      "learning_rate": 3.440089799134128e-08,
      "loss": 0.3545,
      "step": 12460
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.5018980503082275,
      "learning_rate": 3.2396537221901506e-08,
      "loss": 0.3777,
      "step": 12470
    },
    {
      "epoch": 2.93,
      "grad_norm": 4.304654598236084,
      "learning_rate": 3.045223932074182e-08,
      "loss": 0.3956,
      "step": 12480
    },
    {
      "epoch": 2.93,
      "grad_norm": 6.248740196228027,
      "learning_rate": 2.8568016003829304e-08,
      "loss": 0.3696,
      "step": 12490
    },
    {
      "epoch": 2.93,
      "grad_norm": 3.4459569454193115,
      "learning_rate": 2.6743878625133945e-08,
      "loss": 0.3814,
      "step": 12500
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.2026071548461914,
      "learning_rate": 2.497983817655536e-08,
      "loss": 0.4098,
      "step": 12510
    },
    {
      "epoch": 2.93,
      "grad_norm": 4.902469158172607,
      "learning_rate": 2.327590528786394e-08,
      "loss": 0.3759,
      "step": 12520
    },
    {
      "epoch": 2.94,
      "grad_norm": 4.272819519042969,
      "learning_rate": 2.163209022663426e-08,
      "loss": 0.3897,
      "step": 12530
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.8879313468933105,
      "learning_rate": 2.0048402898179554e-08,
      "loss": 0.4071,
      "step": 12540
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.3437840938568115,
      "learning_rate": 1.852485284549621e-08,
      "loss": 0.3768,
      "step": 12550
    },
    {
      "epoch": 2.94,
      "grad_norm": 4.912047863006592,
      "learning_rate": 1.7061449249204942e-08,
      "loss": 0.3705,
      "step": 12560
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.092841386795044,
      "learning_rate": 1.565820092749637e-08,
      "loss": 0.3792,
      "step": 12570
    },
    {
      "epoch": 2.95,
      "grad_norm": 3.8317313194274902,
      "learning_rate": 1.4315116336074409e-08,
      "loss": 0.3127,
      "step": 12580
    },
    {
      "epoch": 2.95,
      "grad_norm": 3.8071157932281494,
      "learning_rate": 1.3032203568110746e-08,
      "loss": 0.397,
      "step": 12590
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.487450361251831,
      "learning_rate": 1.1809470354190444e-08,
      "loss": 0.3904,
      "step": 12600
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.8016974925994873,
      "learning_rate": 1.0646924062270858e-08,
      "loss": 0.3669,
      "step": 12610
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.4149723052978516,
      "learning_rate": 9.544571697632787e-09,
      "loss": 0.4014,
      "step": 12620
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.090906858444214,
      "learning_rate": 8.502419902839399e-09,
      "loss": 0.4152,
      "step": 12630
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.6523220539093018,
      "learning_rate": 7.520474957699586e-09,
      "loss": 0.3525,
      "step": 12640
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.3670170307159424,
      "learning_rate": 6.5987427792235656e-09,
      "loss": 0.3695,
      "step": 12650
    },
    {
      "epoch": 2.97,
      "grad_norm": 2.940164566040039,
      "learning_rate": 5.737228921594007e-09,
      "loss": 0.3729,
      "step": 12660
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.383000135421753,
      "learning_rate": 4.935938576127175e-09,
      "loss": 0.3689,
      "step": 12670
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.395860433578491,
      "learning_rate": 4.194876571246287e-09,
      "loss": 0.3606,
      "step": 12680
    },
    {
      "epoch": 2.97,
      "grad_norm": 2.633347988128662,
      "learning_rate": 3.514047372448204e-09,
      "loss": 0.3946,
      "step": 12690
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.826387643814087,
      "learning_rate": 2.8934550822790063e-09,
      "loss": 0.3838,
      "step": 12700
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.3059167861938477,
      "learning_rate": 2.33310344031068e-09,
      "loss": 0.3925,
      "step": 12710
    },
    {
      "epoch": 2.98,
      "grad_norm": 4.970250129699707,
      "learning_rate": 1.832995823112249e-09,
      "loss": 0.3948,
      "step": 12720
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.128957748413086,
      "learning_rate": 1.3931352442386748e-09,
      "loss": 0.3683,
      "step": 12730
    },
    {
      "epoch": 2.99,
      "grad_norm": 3.055300712585449,
      "learning_rate": 1.0135243542042095e-09,
      "loss": 0.3915,
      "step": 12740
    },
    {
      "epoch": 2.99,
      "grad_norm": 3.909820795059204,
      "learning_rate": 6.94165440471295e-10,
      "loss": 0.3888,
      "step": 12750
    },
    {
      "epoch": 2.99,
      "grad_norm": 1.9958070516586304,
      "learning_rate": 4.350604274361292e-10,
      "loss": 0.3803,
      "step": 12760
    },
    {
      "epoch": 2.99,
      "grad_norm": 2.740621328353882,
      "learning_rate": 2.362108764153437e-10,
      "loss": 0.3581,
      "step": 12770
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.434354782104492,
      "learning_rate": 9.7617985638232e-11,
      "loss": 0.4241,
      "step": 12780
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.8624496459960938,
      "learning_rate": 1.9282590238978162e-11,
      "loss": 0.3861,
      "step": 12790
    },
    {
      "epoch": 3.0,
      "step": 12798,
      "total_flos": 5.124513249311588e+18,
      "train_loss": 0.4418002160978906,
      "train_runtime": 38482.8995,
      "train_samples_per_second": 5.321,
      "train_steps_per_second": 0.333
    }
  ],
  "logging_steps": 10,
  "max_steps": 12798,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "total_flos": 5.124513249311588e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
