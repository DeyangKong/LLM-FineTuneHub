{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 21330,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.3361248970031738,
      "learning_rate": 2.9999983730312198e-05,
      "loss": 1.0698,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6639860272407532,
      "learning_rate": 2.9999934921284086e-05,
      "loss": 0.8513,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3019295930862427,
      "learning_rate": 2.9999853573021545e-05,
      "loss": 0.7834,
      "step": 30
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3847985565662384,
      "learning_rate": 2.999973968570104e-05,
      "loss": 0.7365,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.44184410572052,
      "learning_rate": 2.9999593259569632e-05,
      "loss": 0.6997,
      "step": 50
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6054216027259827,
      "learning_rate": 2.999941429494495e-05,
      "loss": 0.7033,
      "step": 60
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3620087802410126,
      "learning_rate": 2.999920279221524e-05,
      "loss": 0.7114,
      "step": 70
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.33169299364089966,
      "learning_rate": 2.9998958751839292e-05,
      "loss": 0.6702,
      "step": 80
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.32312771677970886,
      "learning_rate": 2.9998682174346518e-05,
      "loss": 0.6777,
      "step": 90
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2858169674873352,
      "learning_rate": 2.9998373060336884e-05,
      "loss": 0.6401,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3635552227497101,
      "learning_rate": 2.9998031410480953e-05,
      "loss": 0.6479,
      "step": 110
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4416467547416687,
      "learning_rate": 2.9997657225519864e-05,
      "loss": 0.6635,
      "step": 120
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5377140045166016,
      "learning_rate": 2.9997250506265333e-05,
      "loss": 0.6734,
      "step": 130
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3399363160133362,
      "learning_rate": 2.999681125359965e-05,
      "loss": 0.658,
      "step": 140
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5311886072158813,
      "learning_rate": 2.9996339468475684e-05,
      "loss": 0.6082,
      "step": 150
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4212040305137634,
      "learning_rate": 2.999583515191687e-05,
      "loss": 0.6362,
      "step": 160
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.47801703214645386,
      "learning_rate": 2.999529830501723e-05,
      "loss": 0.6438,
      "step": 170
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4872238039970398,
      "learning_rate": 2.9994728928941327e-05,
      "loss": 0.6078,
      "step": 180
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5087769031524658,
      "learning_rate": 2.9994127024924312e-05,
      "loss": 0.6077,
      "step": 190
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5751664638519287,
      "learning_rate": 2.9993492594271893e-05,
      "loss": 0.6322,
      "step": 200
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.545198917388916,
      "learning_rate": 2.999282563836033e-05,
      "loss": 0.5953,
      "step": 210
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5815283060073853,
      "learning_rate": 2.999212615863644e-05,
      "loss": 0.6415,
      "step": 220
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8225445747375488,
      "learning_rate": 2.999139415661761e-05,
      "loss": 0.5913,
      "step": 230
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6760162711143494,
      "learning_rate": 2.999062963389176e-05,
      "loss": 0.5956,
      "step": 240
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5202820897102356,
      "learning_rate": 2.9989832592117358e-05,
      "loss": 0.5821,
      "step": 250
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5199437737464905,
      "learning_rate": 2.9989003033023435e-05,
      "loss": 0.6005,
      "step": 260
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7125833034515381,
      "learning_rate": 2.9988140958409528e-05,
      "loss": 0.5635,
      "step": 270
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5988360643386841,
      "learning_rate": 2.998724637014574e-05,
      "loss": 0.5894,
      "step": 280
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1226781606674194,
      "learning_rate": 2.9986319270172695e-05,
      "loss": 0.6131,
      "step": 290
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5941458940505981,
      "learning_rate": 2.9985359660501534e-05,
      "loss": 0.5771,
      "step": 300
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.604820966720581,
      "learning_rate": 2.998436754321394e-05,
      "loss": 0.6032,
      "step": 310
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8794967532157898,
      "learning_rate": 2.9983342920462094e-05,
      "loss": 0.5895,
      "step": 320
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.938445508480072,
      "learning_rate": 2.9982285794468713e-05,
      "loss": 0.6032,
      "step": 330
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1918933391571045,
      "learning_rate": 2.998119616752701e-05,
      "loss": 0.6136,
      "step": 340
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.136940836906433,
      "learning_rate": 2.9980074042000695e-05,
      "loss": 0.5754,
      "step": 350
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6816131472587585,
      "learning_rate": 2.997891942032399e-05,
      "loss": 0.5774,
      "step": 360
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9491977691650391,
      "learning_rate": 2.9977732305001616e-05,
      "loss": 0.5809,
      "step": 370
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.834243655204773,
      "learning_rate": 2.997651269860876e-05,
      "loss": 0.5834,
      "step": 380
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0217373371124268,
      "learning_rate": 2.9975260603791104e-05,
      "loss": 0.5971,
      "step": 390
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9397445917129517,
      "learning_rate": 2.9973976023264813e-05,
      "loss": 0.578,
      "step": 400
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7408536672592163,
      "learning_rate": 2.9972658959816513e-05,
      "loss": 0.5652,
      "step": 410
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7405884861946106,
      "learning_rate": 2.9971309416303304e-05,
      "loss": 0.5522,
      "step": 420
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7014537453651428,
      "learning_rate": 2.9969927395652728e-05,
      "loss": 0.6088,
      "step": 430
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8091213703155518,
      "learning_rate": 2.9968512900862808e-05,
      "loss": 0.5682,
      "step": 440
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7838720679283142,
      "learning_rate": 2.996706593500198e-05,
      "loss": 0.5911,
      "step": 450
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.189134120941162,
      "learning_rate": 2.996558650120915e-05,
      "loss": 0.5779,
      "step": 460
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7622726559638977,
      "learning_rate": 2.9964074602693628e-05,
      "loss": 0.5623,
      "step": 470
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9440715909004211,
      "learning_rate": 2.996253024273517e-05,
      "loss": 0.5923,
      "step": 480
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8952877521514893,
      "learning_rate": 2.9960953424683937e-05,
      "loss": 0.5965,
      "step": 490
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9626635909080505,
      "learning_rate": 2.9959344151960516e-05,
      "loss": 0.5656,
      "step": 500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7700825929641724,
      "learning_rate": 2.9957702428055884e-05,
      "loss": 0.5882,
      "step": 510
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1436644792556763,
      "learning_rate": 2.9956028256531422e-05,
      "loss": 0.5768,
      "step": 520
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7246100902557373,
      "learning_rate": 2.9954321641018888e-05,
      "loss": 0.6295,
      "step": 530
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5793034434318542,
      "learning_rate": 2.995258258522044e-05,
      "loss": 0.5719,
      "step": 540
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6315279603004456,
      "learning_rate": 2.995081109290859e-05,
      "loss": 0.5477,
      "step": 550
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8405856490135193,
      "learning_rate": 2.9949007167926226e-05,
      "loss": 0.5316,
      "step": 560
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1311230659484863,
      "learning_rate": 2.9947170814186583e-05,
      "loss": 0.5565,
      "step": 570
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.162283182144165,
      "learning_rate": 2.994530203567325e-05,
      "loss": 0.5505,
      "step": 580
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.311356544494629,
      "learning_rate": 2.9943400836440155e-05,
      "loss": 0.5545,
      "step": 590
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7079957723617554,
      "learning_rate": 2.994146722061155e-05,
      "loss": 0.5639,
      "step": 600
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.059201955795288,
      "learning_rate": 2.9939501192382016e-05,
      "loss": 0.5717,
      "step": 610
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.112125277519226,
      "learning_rate": 2.993750275601644e-05,
      "loss": 0.5839,
      "step": 620
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.3845127820968628,
      "learning_rate": 2.993547191585001e-05,
      "loss": 0.5654,
      "step": 630
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0711784362792969,
      "learning_rate": 2.993340867628821e-05,
      "loss": 0.5585,
      "step": 640
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6867411732673645,
      "learning_rate": 2.9931313041806817e-05,
      "loss": 0.5444,
      "step": 650
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.771367073059082,
      "learning_rate": 2.992918501695187e-05,
      "loss": 0.5411,
      "step": 660
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.4923714399337769,
      "learning_rate": 2.9927024606339674e-05,
      "loss": 0.5873,
      "step": 670
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0082402229309082,
      "learning_rate": 2.992483181465679e-05,
      "loss": 0.5528,
      "step": 680
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8891072869300842,
      "learning_rate": 2.992260664666002e-05,
      "loss": 0.5742,
      "step": 690
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.643844485282898,
      "learning_rate": 2.9920349107176403e-05,
      "loss": 0.5474,
      "step": 700
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2681769132614136,
      "learning_rate": 2.9918059201103208e-05,
      "loss": 0.5434,
      "step": 710
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8258549571037292,
      "learning_rate": 2.99157369334079e-05,
      "loss": 0.5719,
      "step": 720
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9345334768295288,
      "learning_rate": 2.9913382309128165e-05,
      "loss": 0.5208,
      "step": 730
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3024746179580688,
      "learning_rate": 2.991099533337186e-05,
      "loss": 0.5803,
      "step": 740
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6835887432098389,
      "learning_rate": 2.9908576011317036e-05,
      "loss": 0.5883,
      "step": 750
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9781241416931152,
      "learning_rate": 2.9906124348211908e-05,
      "loss": 0.5419,
      "step": 760
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9332737326622009,
      "learning_rate": 2.990364034937485e-05,
      "loss": 0.5413,
      "step": 770
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8725729584693909,
      "learning_rate": 2.990112402019438e-05,
      "loss": 0.568,
      "step": 780
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.808799684047699,
      "learning_rate": 2.9898575366129145e-05,
      "loss": 0.5558,
      "step": 790
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8203064799308777,
      "learning_rate": 2.9895994392707924e-05,
      "loss": 0.5676,
      "step": 800
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4316537380218506,
      "learning_rate": 2.98933811055296e-05,
      "loss": 0.5437,
      "step": 810
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6284337043762207,
      "learning_rate": 2.9890735510263158e-05,
      "loss": 0.5604,
      "step": 820
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8138266801834106,
      "learning_rate": 2.988805761264766e-05,
      "loss": 0.5477,
      "step": 830
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.820452868938446,
      "learning_rate": 2.9885347418492256e-05,
      "loss": 0.5379,
      "step": 840
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9850758910179138,
      "learning_rate": 2.9882604933676132e-05,
      "loss": 0.5552,
      "step": 850
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1424262523651123,
      "learning_rate": 2.9879830164148555e-05,
      "loss": 0.5264,
      "step": 860
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9457502365112305,
      "learning_rate": 2.98770231159288e-05,
      "loss": 0.5534,
      "step": 870
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.833551824092865,
      "learning_rate": 2.9874183795106175e-05,
      "loss": 0.5079,
      "step": 880
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8011655807495117,
      "learning_rate": 2.9871312207839997e-05,
      "loss": 0.5501,
      "step": 890
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8385795950889587,
      "learning_rate": 2.986840836035957e-05,
      "loss": 0.5641,
      "step": 900
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0151418447494507,
      "learning_rate": 2.9865472258964197e-05,
      "loss": 0.5703,
      "step": 910
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.482707142829895,
      "learning_rate": 2.986250391002313e-05,
      "loss": 0.546,
      "step": 920
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0793448686599731,
      "learning_rate": 2.985950331997559e-05,
      "loss": 0.538,
      "step": 930
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5477705001831055,
      "learning_rate": 2.9856470495330725e-05,
      "loss": 0.5403,
      "step": 940
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.5993403196334839,
      "learning_rate": 2.9853405442667622e-05,
      "loss": 0.5317,
      "step": 950
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.51067316532135,
      "learning_rate": 2.9850308168635267e-05,
      "loss": 0.5389,
      "step": 960
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.4799081087112427,
      "learning_rate": 2.9847178679952565e-05,
      "loss": 0.5387,
      "step": 970
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7593156695365906,
      "learning_rate": 2.9844016983408272e-05,
      "loss": 0.5042,
      "step": 980
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3341701030731201,
      "learning_rate": 2.9840823085861047e-05,
      "loss": 0.5546,
      "step": 990
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1396812200546265,
      "learning_rate": 2.983759699423937e-05,
      "loss": 0.5406,
      "step": 1000
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1151999235153198,
      "learning_rate": 2.9834338715541586e-05,
      "loss": 0.5432,
      "step": 1010
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9377124309539795,
      "learning_rate": 2.9831048256835847e-05,
      "loss": 0.5327,
      "step": 1020
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6596654057502747,
      "learning_rate": 2.9827725625260122e-05,
      "loss": 0.5304,
      "step": 1030
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0347524881362915,
      "learning_rate": 2.9824370828022163e-05,
      "loss": 0.5292,
      "step": 1040
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.046687364578247,
      "learning_rate": 2.9820983872399505e-05,
      "loss": 0.5413,
      "step": 1050
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1617515087127686,
      "learning_rate": 2.9817564765739443e-05,
      "loss": 0.5202,
      "step": 1060
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0195029973983765,
      "learning_rate": 2.9814113515459022e-05,
      "loss": 0.4965,
      "step": 1070
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8863911628723145,
      "learning_rate": 2.9810630129045003e-05,
      "loss": 0.5099,
      "step": 1080
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.271362543106079,
      "learning_rate": 2.9807114614053868e-05,
      "loss": 0.5713,
      "step": 1090
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0920730829238892,
      "learning_rate": 2.98035669781118e-05,
      "loss": 0.5226,
      "step": 1100
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1847076416015625,
      "learning_rate": 2.9799987228914652e-05,
      "loss": 0.541,
      "step": 1110
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8481972217559814,
      "learning_rate": 2.9796375374227948e-05,
      "loss": 0.5116,
      "step": 1120
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7442216873168945,
      "learning_rate": 2.979273142188685e-05,
      "loss": 0.5348,
      "step": 1130
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8003334403038025,
      "learning_rate": 2.9789055379796153e-05,
      "loss": 0.5645,
      "step": 1140
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8661179542541504,
      "learning_rate": 2.978534725593027e-05,
      "loss": 0.5974,
      "step": 1150
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.1317024230957031,
      "learning_rate": 2.9781607058333196e-05,
      "loss": 0.4949,
      "step": 1160
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8474709391593933,
      "learning_rate": 2.9777834795118516e-05,
      "loss": 0.5078,
      "step": 1170
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7527980804443359,
      "learning_rate": 2.9774030474469373e-05,
      "loss": 0.5601,
      "step": 1180
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.826906681060791,
      "learning_rate": 2.977019410463844e-05,
      "loss": 0.5034,
      "step": 1190
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8797146081924438,
      "learning_rate": 2.9766325693947925e-05,
      "loss": 0.5461,
      "step": 1200
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.1060789823532104,
      "learning_rate": 2.9762425250789542e-05,
      "loss": 0.5281,
      "step": 1210
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8717914819717407,
      "learning_rate": 2.9758492783624486e-05,
      "loss": 0.534,
      "step": 1220
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.9064494371414185,
      "learning_rate": 2.975452830098343e-05,
      "loss": 0.5195,
      "step": 1230
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.1789436340332031,
      "learning_rate": 2.975053181146649e-05,
      "loss": 0.4973,
      "step": 1240
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8303424119949341,
      "learning_rate": 2.9746503323743215e-05,
      "loss": 0.5311,
      "step": 1250
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1357572078704834,
      "learning_rate": 2.9742442846552578e-05,
      "loss": 0.5173,
      "step": 1260
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3913912773132324,
      "learning_rate": 2.9738350388702928e-05,
      "loss": 0.5526,
      "step": 1270
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.8932881355285645,
      "learning_rate": 2.973422595907201e-05,
      "loss": 0.5339,
      "step": 1280
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7641925811767578,
      "learning_rate": 2.9730069566606912e-05,
      "loss": 0.551,
      "step": 1290
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0446699857711792,
      "learning_rate": 2.9725881220324055e-05,
      "loss": 0.537,
      "step": 1300
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.4739354848861694,
      "learning_rate": 2.9721660929309192e-05,
      "loss": 0.5041,
      "step": 1310
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0693180561065674,
      "learning_rate": 2.9717408702717364e-05,
      "loss": 0.5211,
      "step": 1320
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5925896167755127,
      "learning_rate": 2.9713124549772888e-05,
      "loss": 0.5353,
      "step": 1330
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.129401445388794,
      "learning_rate": 2.9708808479769346e-05,
      "loss": 0.5181,
      "step": 1340
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0871678590774536,
      "learning_rate": 2.9704460502069544e-05,
      "loss": 0.554,
      "step": 1350
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2944105863571167,
      "learning_rate": 2.970008062610552e-05,
      "loss": 0.5151,
      "step": 1360
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3731188774108887,
      "learning_rate": 2.9695668861378504e-05,
      "loss": 0.5374,
      "step": 1370
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.4594699144363403,
      "learning_rate": 2.96912252174589e-05,
      "loss": 0.5244,
      "step": 1380
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.4813332557678223,
      "learning_rate": 2.9686749703986266e-05,
      "loss": 0.5212,
      "step": 1390
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1205382347106934,
      "learning_rate": 2.9682242330669296e-05,
      "loss": 0.5251,
      "step": 1400
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.073574423789978,
      "learning_rate": 2.96777031072858e-05,
      "loss": 0.5028,
      "step": 1410
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8006014823913574,
      "learning_rate": 2.9673132043682675e-05,
      "loss": 0.5217,
      "step": 1420
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.3353512287139893,
      "learning_rate": 2.9668529149775894e-05,
      "loss": 0.4926,
      "step": 1430
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9757609367370605,
      "learning_rate": 2.9663894435550477e-05,
      "loss": 0.4656,
      "step": 1440
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.285632610321045,
      "learning_rate": 2.9659227911060462e-05,
      "loss": 0.5319,
      "step": 1450
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.154537558555603,
      "learning_rate": 2.9654529586428917e-05,
      "loss": 0.5329,
      "step": 1460
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.0655783414840698,
      "learning_rate": 2.9649799471847864e-05,
      "loss": 0.5497,
      "step": 1470
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.364614486694336,
      "learning_rate": 2.9645037577578315e-05,
      "loss": 0.5538,
      "step": 1480
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7339190244674683,
      "learning_rate": 2.96402439139502e-05,
      "loss": 0.4818,
      "step": 1490
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3157507181167603,
      "learning_rate": 2.9635418491362373e-05,
      "loss": 0.5143,
      "step": 1500
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7378132343292236,
      "learning_rate": 2.9630561320282582e-05,
      "loss": 0.5354,
      "step": 1510
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0230302810668945,
      "learning_rate": 2.9625672411247452e-05,
      "loss": 0.5167,
      "step": 1520
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8874860405921936,
      "learning_rate": 2.9620751774862456e-05,
      "loss": 0.5177,
      "step": 1530
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4334073066711426,
      "learning_rate": 2.9615799421801878e-05,
      "loss": 0.4756,
      "step": 1540
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1005847454071045,
      "learning_rate": 2.961081536280883e-05,
      "loss": 0.5067,
      "step": 1550
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.3602874279022217,
      "learning_rate": 2.960579960869518e-05,
      "loss": 0.5157,
      "step": 1560
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.5202380418777466,
      "learning_rate": 2.960075217034157e-05,
      "loss": 0.5077,
      "step": 1570
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8375280499458313,
      "learning_rate": 2.959567305869736e-05,
      "loss": 0.5486,
      "step": 1580
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.0259093046188354,
      "learning_rate": 2.9590562284780622e-05,
      "loss": 0.5065,
      "step": 1590
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9311881065368652,
      "learning_rate": 2.9585419859678124e-05,
      "loss": 0.539,
      "step": 1600
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.905029296875,
      "learning_rate": 2.9580245794545282e-05,
      "loss": 0.5079,
      "step": 1610
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.881696879863739,
      "learning_rate": 2.957504010060615e-05,
      "loss": 0.5311,
      "step": 1620
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8692256212234497,
      "learning_rate": 2.9569802789153402e-05,
      "loss": 0.5288,
      "step": 1630
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9339629411697388,
      "learning_rate": 2.956453387154829e-05,
      "loss": 0.5033,
      "step": 1640
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.95414799451828,
      "learning_rate": 2.9559233359220635e-05,
      "loss": 0.5141,
      "step": 1650
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8185336589813232,
      "learning_rate": 2.955390126366879e-05,
      "loss": 0.5133,
      "step": 1660
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4629324674606323,
      "learning_rate": 2.954853759645964e-05,
      "loss": 0.5122,
      "step": 1670
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.018308162689209,
      "learning_rate": 2.9543142369228523e-05,
      "loss": 0.5147,
      "step": 1680
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.3066731691360474,
      "learning_rate": 2.953771559367928e-05,
      "loss": 0.5436,
      "step": 1690
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3730499744415283,
      "learning_rate": 2.9532257281584158e-05,
      "loss": 0.5358,
      "step": 1700
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7860349416732788,
      "learning_rate": 2.952676744478383e-05,
      "loss": 0.5266,
      "step": 1710
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.112399697303772,
      "learning_rate": 2.9521246095187357e-05,
      "loss": 0.4953,
      "step": 1720
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.473350167274475,
      "learning_rate": 2.9515693244772156e-05,
      "loss": 0.5277,
      "step": 1730
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1748642921447754,
      "learning_rate": 2.951010890558398e-05,
      "loss": 0.5119,
      "step": 1740
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.2541190385818481,
      "learning_rate": 2.9504493089736882e-05,
      "loss": 0.4968,
      "step": 1750
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1321238279342651,
      "learning_rate": 2.9498845809413218e-05,
      "loss": 0.4963,
      "step": 1760
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9064121842384338,
      "learning_rate": 2.9493167076863575e-05,
      "loss": 0.5482,
      "step": 1770
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.3875963687896729,
      "learning_rate": 2.9487456904406783e-05,
      "loss": 0.4993,
      "step": 1780
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3420660495758057,
      "learning_rate": 2.9481715304429876e-05,
      "loss": 0.5281,
      "step": 1790
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.17208731174469,
      "learning_rate": 2.9475942289388056e-05,
      "loss": 0.5693,
      "step": 1800
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.0820159912109375,
      "learning_rate": 2.947013787180468e-05,
      "loss": 0.5081,
      "step": 1810
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.799117922782898,
      "learning_rate": 2.9464302064271217e-05,
      "loss": 0.4978,
      "step": 1820
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.856259822845459,
      "learning_rate": 2.945843487944724e-05,
      "loss": 0.5191,
      "step": 1830
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4396560192108154,
      "learning_rate": 2.9452536330060382e-05,
      "loss": 0.514,
      "step": 1840
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8104409575462341,
      "learning_rate": 2.944660642890632e-05,
      "loss": 0.5079,
      "step": 1850
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3361843824386597,
      "learning_rate": 2.9440645188848737e-05,
      "loss": 0.5,
      "step": 1860
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.6293330192565918,
      "learning_rate": 2.9434652622819304e-05,
      "loss": 0.4701,
      "step": 1870
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4148057699203491,
      "learning_rate": 2.9428628743817647e-05,
      "loss": 0.5395,
      "step": 1880
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.191306233406067,
      "learning_rate": 2.9422573564911305e-05,
      "loss": 0.4894,
      "step": 1890
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.688835620880127,
      "learning_rate": 2.9416487099235744e-05,
      "loss": 0.5157,
      "step": 1900
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5499587059020996,
      "learning_rate": 2.941036935999427e-05,
      "loss": 0.5007,
      "step": 1910
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1303294897079468,
      "learning_rate": 2.9404220360458052e-05,
      "loss": 0.4963,
      "step": 1920
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0226608514785767,
      "learning_rate": 2.9398040113966062e-05,
      "loss": 0.5196,
      "step": 1930
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.9192051291465759,
      "learning_rate": 2.939182863392505e-05,
      "loss": 0.495,
      "step": 1940
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.0153130292892456,
      "learning_rate": 2.938558593380954e-05,
      "loss": 0.5465,
      "step": 1950
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.63677978515625,
      "learning_rate": 2.9379312027161763e-05,
      "loss": 0.5162,
      "step": 1960
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.0675976276397705,
      "learning_rate": 2.9373006927591657e-05,
      "loss": 0.5453,
      "step": 1970
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.952395498752594,
      "learning_rate": 2.9366670648776818e-05,
      "loss": 0.518,
      "step": 1980
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.284996747970581,
      "learning_rate": 2.936030320446248e-05,
      "loss": 0.5272,
      "step": 1990
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1438769102096558,
      "learning_rate": 2.935390460846149e-05,
      "loss": 0.4834,
      "step": 2000
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9927088618278503,
      "learning_rate": 2.9347474874654277e-05,
      "loss": 0.4802,
      "step": 2010
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6525582075119019,
      "learning_rate": 2.9341014016988795e-05,
      "loss": 0.4977,
      "step": 2020
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2762994766235352,
      "learning_rate": 2.9334522049480546e-05,
      "loss": 0.4916,
      "step": 2030
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9195089340209961,
      "learning_rate": 2.9327998986212484e-05,
      "loss": 0.5216,
      "step": 2040
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.035333275794983,
      "learning_rate": 2.9321444841335045e-05,
      "loss": 0.4969,
      "step": 2050
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.0036110877990723,
      "learning_rate": 2.931485962906608e-05,
      "loss": 0.4982,
      "step": 2060
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.4604309797286987,
      "learning_rate": 2.9308243363690844e-05,
      "loss": 0.4969,
      "step": 2070
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0871920585632324,
      "learning_rate": 2.9301596059561927e-05,
      "loss": 0.5394,
      "step": 2080
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.3185445070266724,
      "learning_rate": 2.9294917731099286e-05,
      "loss": 0.4856,
      "step": 2090
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.343459963798523,
      "learning_rate": 2.9288208392790164e-05,
      "loss": 0.4999,
      "step": 2100
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.394468903541565,
      "learning_rate": 2.928146805918906e-05,
      "loss": 0.4969,
      "step": 2110
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.0931059122085571,
      "learning_rate": 2.9274696744917733e-05,
      "loss": 0.5303,
      "step": 2120
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.886235237121582,
      "learning_rate": 2.9267894464665143e-05,
      "loss": 0.5063,
      "step": 2130
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.073417067527771,
      "learning_rate": 2.9261061233187415e-05,
      "loss": 0.5028,
      "step": 2140
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.2645972967147827,
      "learning_rate": 2.9254197065307823e-05,
      "loss": 0.4616,
      "step": 2150
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.0778700113296509,
      "learning_rate": 2.924730197591674e-05,
      "loss": 0.5115,
      "step": 2160
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.3443355560302734,
      "learning_rate": 2.924037597997164e-05,
      "loss": 0.4866,
      "step": 2170
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1257672309875488,
      "learning_rate": 2.923341909249702e-05,
      "loss": 0.484,
      "step": 2180
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.7573772668838501,
      "learning_rate": 2.9226431328584402e-05,
      "loss": 0.4542,
      "step": 2190
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.859388828277588,
      "learning_rate": 2.9219412703392283e-05,
      "loss": 0.4629,
      "step": 2200
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.1479812860488892,
      "learning_rate": 2.9212363232146114e-05,
      "loss": 0.4804,
      "step": 2210
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.7459514141082764,
      "learning_rate": 2.9205282930138244e-05,
      "loss": 0.4765,
      "step": 2220
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.8610090017318726,
      "learning_rate": 2.9198171812727918e-05,
      "loss": 0.4728,
      "step": 2230
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.7356300354003906,
      "learning_rate": 2.9191029895341227e-05,
      "loss": 0.4619,
      "step": 2240
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.040696144104004,
      "learning_rate": 2.918385719347107e-05,
      "loss": 0.4559,
      "step": 2250
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.9416906237602234,
      "learning_rate": 2.917665372267713e-05,
      "loss": 0.5467,
      "step": 2260
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.305238127708435,
      "learning_rate": 2.9169419498585837e-05,
      "loss": 0.4625,
      "step": 2270
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.1869240999221802,
      "learning_rate": 2.9162154536890337e-05,
      "loss": 0.4544,
      "step": 2280
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.0961028337478638,
      "learning_rate": 2.9154858853350444e-05,
      "loss": 0.4625,
      "step": 2290
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.7960920929908752,
      "learning_rate": 2.9147532463792625e-05,
      "loss": 0.5184,
      "step": 2300
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.283911943435669,
      "learning_rate": 2.9140175384109964e-05,
      "loss": 0.4438,
      "step": 2310
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.8557581901550293,
      "learning_rate": 2.9132787630262103e-05,
      "loss": 0.5115,
      "step": 2320
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.043853759765625,
      "learning_rate": 2.9125369218275243e-05,
      "loss": 0.4719,
      "step": 2330
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0871646404266357,
      "learning_rate": 2.911792016424208e-05,
      "loss": 0.4673,
      "step": 2340
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.1854665279388428,
      "learning_rate": 2.9110440484321782e-05,
      "loss": 0.474,
      "step": 2350
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.0011831521987915,
      "learning_rate": 2.910293019473996e-05,
      "loss": 0.4753,
      "step": 2360
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.3891254663467407,
      "learning_rate": 2.9095389311788626e-05,
      "loss": 0.4874,
      "step": 2370
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.122887134552002,
      "learning_rate": 2.908781785182615e-05,
      "loss": 0.4755,
      "step": 2380
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7649800777435303,
      "learning_rate": 2.908021583127724e-05,
      "loss": 0.5086,
      "step": 2390
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.4153987169265747,
      "learning_rate": 2.9072583266632894e-05,
      "loss": 0.4957,
      "step": 2400
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.8377899527549744,
      "learning_rate": 2.9064920174450374e-05,
      "loss": 0.4871,
      "step": 2410
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.2118074893951416,
      "learning_rate": 2.9057226571353157e-05,
      "loss": 0.4856,
      "step": 2420
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.929845929145813,
      "learning_rate": 2.904950247403092e-05,
      "loss": 0.4611,
      "step": 2430
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.201027750968933,
      "learning_rate": 2.9041747899239476e-05,
      "loss": 0.4861,
      "step": 2440
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.1435000896453857,
      "learning_rate": 2.9033962863800764e-05,
      "loss": 0.4624,
      "step": 2450
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.035665512084961,
      "learning_rate": 2.9026147384602796e-05,
      "loss": 0.4688,
      "step": 2460
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.6234469413757324,
      "learning_rate": 2.9018301478599628e-05,
      "loss": 0.462,
      "step": 2470
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.970832347869873,
      "learning_rate": 2.9010425162811314e-05,
      "loss": 0.4562,
      "step": 2480
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.1267218589782715,
      "learning_rate": 2.9002518454323883e-05,
      "loss": 0.4979,
      "step": 2490
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0334815979003906,
      "learning_rate": 2.8994581370289296e-05,
      "loss": 0.4604,
      "step": 2500
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.8199236392974854,
      "learning_rate": 2.89866139279254e-05,
      "loss": 0.4285,
      "step": 2510
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.1049504280090332,
      "learning_rate": 2.89786161445159e-05,
      "loss": 0.4832,
      "step": 2520
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.6299999952316284,
      "learning_rate": 2.8970588037410322e-05,
      "loss": 0.4888,
      "step": 2530
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.032638430595398,
      "learning_rate": 2.8962529624023977e-05,
      "loss": 0.4864,
      "step": 2540
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0187019109725952,
      "learning_rate": 2.8954440921837904e-05,
      "loss": 0.4654,
      "step": 2550
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0633821487426758,
      "learning_rate": 2.894632194839887e-05,
      "loss": 0.4756,
      "step": 2560
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.357506275177002,
      "learning_rate": 2.893817272131929e-05,
      "loss": 0.4597,
      "step": 2570
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.1932923793792725,
      "learning_rate": 2.8929993258277212e-05,
      "loss": 0.4793,
      "step": 2580
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.4133319854736328,
      "learning_rate": 2.8921783577016284e-05,
      "loss": 0.4912,
      "step": 2590
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.4109588861465454,
      "learning_rate": 2.8913543695345695e-05,
      "loss": 0.4566,
      "step": 2600
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1606450080871582,
      "learning_rate": 2.8905273631140155e-05,
      "loss": 0.4774,
      "step": 2610
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.1689058542251587,
      "learning_rate": 2.889697340233984e-05,
      "loss": 0.4895,
      "step": 2620
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.675499677658081,
      "learning_rate": 2.8888643026950377e-05,
      "loss": 0.4335,
      "step": 2630
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0121769905090332,
      "learning_rate": 2.888028252304277e-05,
      "loss": 0.4883,
      "step": 2640
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.1471048593521118,
      "learning_rate": 2.8871891908753398e-05,
      "loss": 0.4803,
      "step": 2650
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.2788931131362915,
      "learning_rate": 2.886347120228395e-05,
      "loss": 0.4559,
      "step": 2660
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.8931013941764832,
      "learning_rate": 2.885502042190139e-05,
      "loss": 0.4722,
      "step": 2670
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.8747751712799072,
      "learning_rate": 2.8846539585937934e-05,
      "loss": 0.4624,
      "step": 2680
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.1933190822601318,
      "learning_rate": 2.883802871279098e-05,
      "loss": 0.4266,
      "step": 2690
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.415618658065796,
      "learning_rate": 2.88294878209231e-05,
      "loss": 0.4655,
      "step": 2700
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.2060954570770264,
      "learning_rate": 2.882091692886198e-05,
      "loss": 0.448,
      "step": 2710
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.8257298469543457,
      "learning_rate": 2.8812316055200384e-05,
      "loss": 0.469,
      "step": 2720
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.920045018196106,
      "learning_rate": 2.880368521859611e-05,
      "loss": 0.4899,
      "step": 2730
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5735077857971191,
      "learning_rate": 2.8795024437771974e-05,
      "loss": 0.5053,
      "step": 2740
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.1100642681121826,
      "learning_rate": 2.878633373151572e-05,
      "loss": 0.4449,
      "step": 2750
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.2140487432479858,
      "learning_rate": 2.877761311868004e-05,
      "loss": 0.4704,
      "step": 2760
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.4811910390853882,
      "learning_rate": 2.8768862618182474e-05,
      "loss": 0.4662,
      "step": 2770
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.5807896852493286,
      "learning_rate": 2.876008224900542e-05,
      "loss": 0.4617,
      "step": 2780
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.0406607389450073,
      "learning_rate": 2.8751272030196054e-05,
      "loss": 0.4873,
      "step": 2790
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.0451412200927734,
      "learning_rate": 2.8742431980866314e-05,
      "loss": 0.4666,
      "step": 2800
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1476202011108398,
      "learning_rate": 2.8733562120192845e-05,
      "loss": 0.4875,
      "step": 2810
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.8863814473152161,
      "learning_rate": 2.872466246741696e-05,
      "loss": 0.4725,
      "step": 2820
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.9370803833007812,
      "learning_rate": 2.8715733041844607e-05,
      "loss": 0.4636,
      "step": 2830
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.08553147315979,
      "learning_rate": 2.8706773862846307e-05,
      "loss": 0.483,
      "step": 2840
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.958651602268219,
      "learning_rate": 2.869778494985714e-05,
      "loss": 0.5201,
      "step": 2850
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.8070350289344788,
      "learning_rate": 2.868876632237668e-05,
      "loss": 0.4783,
      "step": 2860
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.9471110105514526,
      "learning_rate": 2.8679717999968953e-05,
      "loss": 0.4792,
      "step": 2870
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4955767393112183,
      "learning_rate": 2.867064000226242e-05,
      "loss": 0.4773,
      "step": 2880
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.5183688402175903,
      "learning_rate": 2.8661532348949897e-05,
      "loss": 0.4601,
      "step": 2890
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.1221933364868164,
      "learning_rate": 2.865239505978855e-05,
      "loss": 0.439,
      "step": 2900
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.2781819105148315,
      "learning_rate": 2.8643228154599817e-05,
      "loss": 0.4454,
      "step": 2910
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.1139684915542603,
      "learning_rate": 2.863403165326939e-05,
      "loss": 0.4589,
      "step": 2920
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.1875102519989014,
      "learning_rate": 2.8624805575747167e-05,
      "loss": 0.4843,
      "step": 2930
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.697344422340393,
      "learning_rate": 2.8615549942047203e-05,
      "loss": 0.5065,
      "step": 2940
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.6875698566436768,
      "learning_rate": 2.8606264772247662e-05,
      "loss": 0.451,
      "step": 2950
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.245599389076233,
      "learning_rate": 2.8596950086490786e-05,
      "loss": 0.4652,
      "step": 2960
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.5888018608093262,
      "learning_rate": 2.858760590498285e-05,
      "loss": 0.4855,
      "step": 2970
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.8360762596130371,
      "learning_rate": 2.8578232247994108e-05,
      "loss": 0.511,
      "step": 2980
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.55333411693573,
      "learning_rate": 2.856882913585875e-05,
      "loss": 0.4462,
      "step": 2990
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.1975091695785522,
      "learning_rate": 2.855939658897488e-05,
      "loss": 0.4844,
      "step": 3000
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.6132621765136719,
      "learning_rate": 2.8549934627804434e-05,
      "loss": 0.4756,
      "step": 3010
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.328480839729309,
      "learning_rate": 2.8540443272873168e-05,
      "loss": 0.4405,
      "step": 3020
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1405067443847656,
      "learning_rate": 2.853092254477061e-05,
      "loss": 0.4862,
      "step": 3030
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.0185706615447998,
      "learning_rate": 2.8521372464149984e-05,
      "loss": 0.4384,
      "step": 3040
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.725371241569519,
      "learning_rate": 2.8511793051728205e-05,
      "loss": 0.457,
      "step": 3050
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.2865664958953857,
      "learning_rate": 2.8502184328285812e-05,
      "loss": 0.4353,
      "step": 3060
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.2376914024353027,
      "learning_rate": 2.849254631466693e-05,
      "loss": 0.4782,
      "step": 3070
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.6578880548477173,
      "learning_rate": 2.848287903177922e-05,
      "loss": 0.4658,
      "step": 3080
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.16180419921875,
      "learning_rate": 2.8473182500593847e-05,
      "loss": 0.4486,
      "step": 3090
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.1238185167312622,
      "learning_rate": 2.8463456742145402e-05,
      "loss": 0.5049,
      "step": 3100
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.9456716179847717,
      "learning_rate": 2.8453701777531903e-05,
      "loss": 0.4778,
      "step": 3110
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.8398154973983765,
      "learning_rate": 2.844391762791471e-05,
      "loss": 0.4827,
      "step": 3120
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.4947811365127563,
      "learning_rate": 2.8434104314518496e-05,
      "loss": 0.4721,
      "step": 3130
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.3506712913513184,
      "learning_rate": 2.8424261858631205e-05,
      "loss": 0.4827,
      "step": 3140
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.119447112083435,
      "learning_rate": 2.841439028160399e-05,
      "loss": 0.4597,
      "step": 3150
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.1213074922561646,
      "learning_rate": 2.8404489604851186e-05,
      "loss": 0.4575,
      "step": 3160
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0942198038101196,
      "learning_rate": 2.8394559849850242e-05,
      "loss": 0.5174,
      "step": 3170
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.045803427696228,
      "learning_rate": 2.8384601038141703e-05,
      "loss": 0.4768,
      "step": 3180
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.9952573776245117,
      "learning_rate": 2.8374613191329127e-05,
      "loss": 0.4603,
      "step": 3190
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0345330238342285,
      "learning_rate": 2.8364596331079072e-05,
      "loss": 0.4546,
      "step": 3200
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.2971161603927612,
      "learning_rate": 2.835455047912103e-05,
      "loss": 0.4804,
      "step": 3210
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.0246069431304932,
      "learning_rate": 2.834447565724738e-05,
      "loss": 0.4642,
      "step": 3220
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.9295899271965027,
      "learning_rate": 2.8334371887313353e-05,
      "loss": 0.4864,
      "step": 3230
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.5011094808578491,
      "learning_rate": 2.832423919123698e-05,
      "loss": 0.4616,
      "step": 3240
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.8694456219673157,
      "learning_rate": 2.8314077590999025e-05,
      "loss": 0.4505,
      "step": 3250
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.297137975692749,
      "learning_rate": 2.8303887108642966e-05,
      "loss": 0.4556,
      "step": 3260
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.5731983184814453,
      "learning_rate": 2.829366776627493e-05,
      "loss": 0.4944,
      "step": 3270
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.2686042785644531,
      "learning_rate": 2.8283419586063654e-05,
      "loss": 0.4993,
      "step": 3280
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3515297174453735,
      "learning_rate": 2.8273142590240432e-05,
      "loss": 0.4654,
      "step": 3290
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0121647119522095,
      "learning_rate": 2.826283680109906e-05,
      "loss": 0.4584,
      "step": 3300
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.2766629457473755,
      "learning_rate": 2.8252502240995808e-05,
      "loss": 0.4776,
      "step": 3310
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1267263889312744,
      "learning_rate": 2.824213893234935e-05,
      "loss": 0.4459,
      "step": 3320
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.3323806524276733,
      "learning_rate": 2.8231746897640718e-05,
      "loss": 0.4341,
      "step": 3330
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.3115599155426025,
      "learning_rate": 2.822132615941328e-05,
      "loss": 0.4796,
      "step": 3340
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.687508463859558,
      "learning_rate": 2.8210876740272642e-05,
      "loss": 0.4696,
      "step": 3350
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.306183099746704,
      "learning_rate": 2.8200398662886656e-05,
      "loss": 0.4592,
      "step": 3360
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.1663932800292969,
      "learning_rate": 2.8189891949985317e-05,
      "loss": 0.4334,
      "step": 3370
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.4361337423324585,
      "learning_rate": 2.8179356624360758e-05,
      "loss": 0.4629,
      "step": 3380
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.9847166538238525,
      "learning_rate": 2.816879270886717e-05,
      "loss": 0.451,
      "step": 3390
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.3623108863830566,
      "learning_rate": 2.8158200226420768e-05,
      "loss": 0.4602,
      "step": 3400
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.2259776592254639,
      "learning_rate": 2.8147579199999736e-05,
      "loss": 0.47,
      "step": 3410
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0359135866165161,
      "learning_rate": 2.813692965264418e-05,
      "loss": 0.4869,
      "step": 3420
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.4720304012298584,
      "learning_rate": 2.8126251607456073e-05,
      "loss": 0.4533,
      "step": 3430
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.0603368282318115,
      "learning_rate": 2.8115545087599214e-05,
      "loss": 0.4405,
      "step": 3440
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.2190958261489868,
      "learning_rate": 2.810481011629916e-05,
      "loss": 0.4834,
      "step": 3450
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1007909774780273,
      "learning_rate": 2.80940467168432e-05,
      "loss": 0.5032,
      "step": 3460
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.432427167892456,
      "learning_rate": 2.8083254912580287e-05,
      "loss": 0.4934,
      "step": 3470
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.4079219102859497,
      "learning_rate": 2.807243472692099e-05,
      "loss": 0.466,
      "step": 3480
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1285967826843262,
      "learning_rate": 2.8061586183337453e-05,
      "loss": 0.4779,
      "step": 3490
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.4254275560379028,
      "learning_rate": 2.805070930536333e-05,
      "loss": 0.4458,
      "step": 3500
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.9028297662734985,
      "learning_rate": 2.8039804116593743e-05,
      "loss": 0.4595,
      "step": 3510
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.8407122492790222,
      "learning_rate": 2.8028870640685218e-05,
      "loss": 0.4651,
      "step": 3520
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.8511534333229065,
      "learning_rate": 2.8017908901355664e-05,
      "loss": 0.4741,
      "step": 3530
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.9740129709243774,
      "learning_rate": 2.8006918922384294e-05,
      "loss": 0.4293,
      "step": 3540
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.5897610187530518,
      "learning_rate": 2.7995900727611565e-05,
      "loss": 0.4518,
      "step": 3550
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.0108542442321777,
      "learning_rate": 2.7984854340939165e-05,
      "loss": 0.4773,
      "step": 3560
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.0660512447357178,
      "learning_rate": 2.797377978632993e-05,
      "loss": 0.4869,
      "step": 3570
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.203108310699463,
      "learning_rate": 2.7962677087807795e-05,
      "loss": 0.4792,
      "step": 3580
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.5561940670013428,
      "learning_rate": 2.7951546269457756e-05,
      "loss": 0.4568,
      "step": 3590
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.5640798807144165,
      "learning_rate": 2.7940387355425798e-05,
      "loss": 0.4698,
      "step": 3600
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.8079834580421448,
      "learning_rate": 2.7929200369918865e-05,
      "loss": 0.5101,
      "step": 3610
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.9702656269073486,
      "learning_rate": 2.7917985337204797e-05,
      "loss": 0.4328,
      "step": 3620
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.1823782920837402,
      "learning_rate": 2.7906742281612265e-05,
      "loss": 0.4309,
      "step": 3630
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.3852368593215942,
      "learning_rate": 2.7895471227530737e-05,
      "loss": 0.4671,
      "step": 3640
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.941049337387085,
      "learning_rate": 2.7884172199410417e-05,
      "loss": 0.4968,
      "step": 3650
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.9504838585853577,
      "learning_rate": 2.7872845221762196e-05,
      "loss": 0.465,
      "step": 3660
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.5967661142349243,
      "learning_rate": 2.7861490319157586e-05,
      "loss": 0.4514,
      "step": 3670
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.843571662902832,
      "learning_rate": 2.785010751622869e-05,
      "loss": 0.4814,
      "step": 3680
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.1507587432861328,
      "learning_rate": 2.7838696837668128e-05,
      "loss": 0.5171,
      "step": 3690
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.8161338567733765,
      "learning_rate": 2.7827258308228986e-05,
      "loss": 0.4497,
      "step": 3700
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.8108837604522705,
      "learning_rate": 2.7815791952724774e-05,
      "loss": 0.4503,
      "step": 3710
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.9686793684959412,
      "learning_rate": 2.780429779602936e-05,
      "loss": 0.5158,
      "step": 3720
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.2799814939498901,
      "learning_rate": 2.779277586307692e-05,
      "loss": 0.4588,
      "step": 3730
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.351778268814087,
      "learning_rate": 2.77812261788619e-05,
      "loss": 0.443,
      "step": 3740
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.2796088457107544,
      "learning_rate": 2.776964876843892e-05,
      "loss": 0.4882,
      "step": 3750
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.4114775657653809,
      "learning_rate": 2.7758043656922764e-05,
      "loss": 0.4749,
      "step": 3760
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.8899524807929993,
      "learning_rate": 2.774641086948831e-05,
      "loss": 0.5141,
      "step": 3770
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0771539211273193,
      "learning_rate": 2.7734750431370462e-05,
      "loss": 0.4933,
      "step": 3780
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.4011026620864868,
      "learning_rate": 2.772306236786411e-05,
      "loss": 0.4931,
      "step": 3790
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.8376346230506897,
      "learning_rate": 2.771134670432408e-05,
      "loss": 0.4652,
      "step": 3800
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.5906424522399902,
      "learning_rate": 2.769960346616506e-05,
      "loss": 0.4559,
      "step": 3810
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.772112488746643,
      "learning_rate": 2.768783267886156e-05,
      "loss": 0.4544,
      "step": 3820
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9940418601036072,
      "learning_rate": 2.7676034367947843e-05,
      "loss": 0.4569,
      "step": 3830
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.3140424489974976,
      "learning_rate": 2.7664208559017903e-05,
      "loss": 0.4583,
      "step": 3840
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.950488805770874,
      "learning_rate": 2.765235527772536e-05,
      "loss": 0.4683,
      "step": 3850
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.4381009340286255,
      "learning_rate": 2.7640474549783437e-05,
      "loss": 0.4917,
      "step": 3860
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.093623399734497,
      "learning_rate": 2.7628566400964904e-05,
      "loss": 0.4738,
      "step": 3870
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.9251783490180969,
      "learning_rate": 2.7616630857102005e-05,
      "loss": 0.4979,
      "step": 3880
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.40205717086792,
      "learning_rate": 2.760466794408642e-05,
      "loss": 0.4726,
      "step": 3890
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.3863176107406616,
      "learning_rate": 2.7592677687869186e-05,
      "loss": 0.4597,
      "step": 3900
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.4129339456558228,
      "learning_rate": 2.7580660114460686e-05,
      "loss": 0.4871,
      "step": 3910
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.0059483051300049,
      "learning_rate": 2.756861524993053e-05,
      "loss": 0.5344,
      "step": 3920
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1126641035079956,
      "learning_rate": 2.7556543120407536e-05,
      "loss": 0.4434,
      "step": 3930
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.1822257041931152,
      "learning_rate": 2.7544443752079694e-05,
      "loss": 0.4544,
      "step": 3940
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.0572421550750732,
      "learning_rate": 2.753231717119405e-05,
      "loss": 0.4748,
      "step": 3950
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.2742339372634888,
      "learning_rate": 2.7520163404056695e-05,
      "loss": 0.4687,
      "step": 3960
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.8889950513839722,
      "learning_rate": 2.7507982477032695e-05,
      "loss": 0.4641,
      "step": 3970
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.8226084113121033,
      "learning_rate": 2.749577441654604e-05,
      "loss": 0.4865,
      "step": 3980
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.0655468702316284,
      "learning_rate": 2.748353924907957e-05,
      "loss": 0.4487,
      "step": 3990
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.2212311029434204,
      "learning_rate": 2.7471277001174936e-05,
      "loss": 0.4354,
      "step": 4000
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.6110998392105103,
      "learning_rate": 2.7458987699432527e-05,
      "loss": 0.4557,
      "step": 4010
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.268338680267334,
      "learning_rate": 2.744667137051143e-05,
      "loss": 0.4561,
      "step": 4020
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.1830418109893799,
      "learning_rate": 2.7434328041129337e-05,
      "loss": 0.4275,
      "step": 4030
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.9173282980918884,
      "learning_rate": 2.7421957738062553e-05,
      "loss": 0.4787,
      "step": 4040
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.6843807697296143,
      "learning_rate": 2.7409560488145863e-05,
      "loss": 0.4603,
      "step": 4050
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.9309388399124146,
      "learning_rate": 2.7397136318272516e-05,
      "loss": 0.4492,
      "step": 4060
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.5829594135284424,
      "learning_rate": 2.7384685255394164e-05,
      "loss": 0.478,
      "step": 4070
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.2651492357254028,
      "learning_rate": 2.7372207326520794e-05,
      "loss": 0.4324,
      "step": 4080
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.5639958381652832,
      "learning_rate": 2.7359702558720673e-05,
      "loss": 0.4558,
      "step": 4090
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.1714311838150024,
      "learning_rate": 2.7347170979120294e-05,
      "loss": 0.4553,
      "step": 4100
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.5104447603225708,
      "learning_rate": 2.7334612614904307e-05,
      "loss": 0.4768,
      "step": 4110
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.9362322092056274,
      "learning_rate": 2.732202749331546e-05,
      "loss": 0.4833,
      "step": 4120
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.9768896698951721,
      "learning_rate": 2.7309415641654563e-05,
      "loss": 0.4747,
      "step": 4130
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.1713634729385376,
      "learning_rate": 2.7296777087280396e-05,
      "loss": 0.4705,
      "step": 4140
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.905758798122406,
      "learning_rate": 2.728411185760967e-05,
      "loss": 0.4483,
      "step": 4150
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.8956748843193054,
      "learning_rate": 2.7271419980116965e-05,
      "loss": 0.4251,
      "step": 4160
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.5208483934402466,
      "learning_rate": 2.725870148233467e-05,
      "loss": 0.4694,
      "step": 4170
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.9940243363380432,
      "learning_rate": 2.7245956391852904e-05,
      "loss": 0.4893,
      "step": 4180
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.919756293296814,
      "learning_rate": 2.72331847363195e-05,
      "loss": 0.4778,
      "step": 4190
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.296770453453064,
      "learning_rate": 2.722038654343989e-05,
      "loss": 0.4315,
      "step": 4200
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.8315755128860474,
      "learning_rate": 2.72075618409771e-05,
      "loss": 0.4488,
      "step": 4210
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.9256955981254578,
      "learning_rate": 2.7194710656751647e-05,
      "loss": 0.4247,
      "step": 4220
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.13149094581604,
      "learning_rate": 2.71818330186415e-05,
      "loss": 0.4354,
      "step": 4230
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.585375428199768,
      "learning_rate": 2.7168928954582e-05,
      "loss": 0.491,
      "step": 4240
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.9781903028488159,
      "learning_rate": 2.7155998492565844e-05,
      "loss": 0.4671,
      "step": 4250
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.0176775455474854,
      "learning_rate": 2.7143041660642967e-05,
      "loss": 0.4849,
      "step": 4260
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.9536118507385254,
      "learning_rate": 2.7130058486920516e-05,
      "loss": 0.4643,
      "step": 4270
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.5803585052490234,
      "learning_rate": 2.711704899956279e-05,
      "loss": 0.4126,
      "step": 4280
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.9399005770683289,
      "learning_rate": 2.7104013226791156e-05,
      "loss": 0.467,
      "step": 4290
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.2522224187850952,
      "learning_rate": 2.7090951196884008e-05,
      "loss": 0.4949,
      "step": 4300
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.0256743431091309,
      "learning_rate": 2.707786293817669e-05,
      "loss": 0.4618,
      "step": 4310
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.305038332939148,
      "learning_rate": 2.7064748479061476e-05,
      "loss": 0.4081,
      "step": 4320
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.4442059993743896,
      "learning_rate": 2.705160784798743e-05,
      "loss": 0.4247,
      "step": 4330
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.3785779476165771,
      "learning_rate": 2.703844107346043e-05,
      "loss": 0.3871,
      "step": 4340
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.1437116861343384,
      "learning_rate": 2.702524818404304e-05,
      "loss": 0.4109,
      "step": 4350
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.1089221239089966,
      "learning_rate": 2.7012029208354493e-05,
      "loss": 0.419,
      "step": 4360
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.4200245141983032,
      "learning_rate": 2.69987841750706e-05,
      "loss": 0.4327,
      "step": 4370
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.71670401096344,
      "learning_rate": 2.69855131129237e-05,
      "loss": 0.4381,
      "step": 4380
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.3048374652862549,
      "learning_rate": 2.6972216050702606e-05,
      "loss": 0.4989,
      "step": 4390
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.0126266479492188,
      "learning_rate": 2.6958893017252514e-05,
      "loss": 0.4197,
      "step": 4400
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.7158067226409912,
      "learning_rate": 2.694554404147498e-05,
      "loss": 0.4159,
      "step": 4410
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.536108136177063,
      "learning_rate": 2.693216915232782e-05,
      "loss": 0.4067,
      "step": 4420
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.9760039448738098,
      "learning_rate": 2.691876837882507e-05,
      "loss": 0.4516,
      "step": 4430
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.0933799743652344,
      "learning_rate": 2.690534175003692e-05,
      "loss": 0.4593,
      "step": 4440
    },
    {
      "epoch": 2.09,
      "grad_norm": 1.3046612739562988,
      "learning_rate": 2.6891889295089646e-05,
      "loss": 0.4246,
      "step": 4450
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.061811685562134,
      "learning_rate": 2.687841104316554e-05,
      "loss": 0.4572,
      "step": 4460
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.1141096353530884,
      "learning_rate": 2.6864907023502867e-05,
      "loss": 0.4277,
      "step": 4470
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.640285611152649,
      "learning_rate": 2.6851377265395784e-05,
      "loss": 0.4265,
      "step": 4480
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.1374058723449707,
      "learning_rate": 2.6837821798194284e-05,
      "loss": 0.4251,
      "step": 4490
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.9797405004501343,
      "learning_rate": 2.682424065130413e-05,
      "loss": 0.4321,
      "step": 4500
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.3149226903915405,
      "learning_rate": 2.6810633854186792e-05,
      "loss": 0.4416,
      "step": 4510
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.18130362033844,
      "learning_rate": 2.6797001436359377e-05,
      "loss": 0.426,
      "step": 4520
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.7871407866477966,
      "learning_rate": 2.678334342739458e-05,
      "loss": 0.4276,
      "step": 4530
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.5152140855789185,
      "learning_rate": 2.6769659856920603e-05,
      "loss": 0.414,
      "step": 4540
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.1986569166183472,
      "learning_rate": 2.6755950754621106e-05,
      "loss": 0.4356,
      "step": 4550
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.5678962469100952,
      "learning_rate": 2.674221615023513e-05,
      "loss": 0.4276,
      "step": 4560
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.0556745529174805,
      "learning_rate": 2.6728456073557042e-05,
      "loss": 0.4398,
      "step": 4570
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.9854451417922974,
      "learning_rate": 2.6714670554436452e-05,
      "loss": 0.4293,
      "step": 4580
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.4171007871627808,
      "learning_rate": 2.6700859622778184e-05,
      "loss": 0.4383,
      "step": 4590
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.4903723001480103,
      "learning_rate": 2.668702330854217e-05,
      "loss": 0.4796,
      "step": 4600
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.7427738904953003,
      "learning_rate": 2.667316164174341e-05,
      "loss": 0.4124,
      "step": 4610
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.6383893489837646,
      "learning_rate": 2.665927465245191e-05,
      "loss": 0.4209,
      "step": 4620
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.3152025938034058,
      "learning_rate": 2.66453623707926e-05,
      "loss": 0.4142,
      "step": 4630
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.00175940990448,
      "learning_rate": 2.6631424826945276e-05,
      "loss": 0.4536,
      "step": 4640
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.1040726900100708,
      "learning_rate": 2.6617462051144527e-05,
      "loss": 0.4295,
      "step": 4650
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.1489323377609253,
      "learning_rate": 2.66034740736797e-05,
      "loss": 0.4383,
      "step": 4660
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.264906644821167,
      "learning_rate": 2.6589460924894788e-05,
      "loss": 0.4315,
      "step": 4670
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.4266295433044434,
      "learning_rate": 2.6575422635188408e-05,
      "loss": 0.4134,
      "step": 4680
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.6298081874847412,
      "learning_rate": 2.65613592350137e-05,
      "loss": 0.4642,
      "step": 4690
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.9376447796821594,
      "learning_rate": 2.6547270754878284e-05,
      "loss": 0.441,
      "step": 4700
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.1348618268966675,
      "learning_rate": 2.653315722534418e-05,
      "loss": 0.4605,
      "step": 4710
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.9820616245269775,
      "learning_rate": 2.651901867702775e-05,
      "loss": 0.4158,
      "step": 4720
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.0892231464385986,
      "learning_rate": 2.6504855140599634e-05,
      "loss": 0.4296,
      "step": 4730
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.2061107158660889,
      "learning_rate": 2.649066664678467e-05,
      "loss": 0.4554,
      "step": 4740
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.1761893033981323,
      "learning_rate": 2.647645322636184e-05,
      "loss": 0.4135,
      "step": 4750
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.8001900911331177,
      "learning_rate": 2.6462214910164207e-05,
      "loss": 0.4719,
      "step": 4760
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.0607244968414307,
      "learning_rate": 2.6447951729078826e-05,
      "loss": 0.4401,
      "step": 4770
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.0123711824417114,
      "learning_rate": 2.6433663714046694e-05,
      "loss": 0.4299,
      "step": 4780
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.5414743423461914,
      "learning_rate": 2.6419350896062687e-05,
      "loss": 0.4612,
      "step": 4790
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.983356237411499,
      "learning_rate": 2.6405013306175486e-05,
      "loss": 0.4078,
      "step": 4800
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.1020010709762573,
      "learning_rate": 2.6390650975487497e-05,
      "loss": 0.4541,
      "step": 4810
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.2298059463500977,
      "learning_rate": 2.6376263935154812e-05,
      "loss": 0.4227,
      "step": 4820
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.8479397296905518,
      "learning_rate": 2.6361852216387114e-05,
      "loss": 0.4779,
      "step": 4830
    },
    {
      "epoch": 2.27,
      "grad_norm": 1.5920190811157227,
      "learning_rate": 2.6347415850447634e-05,
      "loss": 0.4644,
      "step": 4840
    },
    {
      "epoch": 2.27,
      "grad_norm": 1.370934009552002,
      "learning_rate": 2.6332954868653047e-05,
      "loss": 0.4429,
      "step": 4850
    },
    {
      "epoch": 2.28,
      "grad_norm": 1.0554263591766357,
      "learning_rate": 2.6318469302373453e-05,
      "loss": 0.4398,
      "step": 4860
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.951431155204773,
      "learning_rate": 2.6303959183032262e-05,
      "loss": 0.4092,
      "step": 4870
    },
    {
      "epoch": 2.29,
      "grad_norm": 1.5784052610397339,
      "learning_rate": 2.6289424542106163e-05,
      "loss": 0.4445,
      "step": 4880
    },
    {
      "epoch": 2.29,
      "grad_norm": 1.8436590433120728,
      "learning_rate": 2.6274865411125028e-05,
      "loss": 0.4466,
      "step": 4890
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.6388685703277588,
      "learning_rate": 2.6260281821671857e-05,
      "loss": 0.4415,
      "step": 4900
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.458302617073059,
      "learning_rate": 2.6245673805382716e-05,
      "loss": 0.4271,
      "step": 4910
    },
    {
      "epoch": 2.31,
      "grad_norm": 1.6119425296783447,
      "learning_rate": 2.6231041393946647e-05,
      "loss": 0.4137,
      "step": 4920
    },
    {
      "epoch": 2.31,
      "grad_norm": 1.0250177383422852,
      "learning_rate": 2.6216384619105625e-05,
      "loss": 0.4357,
      "step": 4930
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.0235767364501953,
      "learning_rate": 2.6201703512654465e-05,
      "loss": 0.409,
      "step": 4940
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.4160914421081543,
      "learning_rate": 2.6186998106440772e-05,
      "loss": 0.4417,
      "step": 4950
    },
    {
      "epoch": 2.33,
      "grad_norm": 1.1250394582748413,
      "learning_rate": 2.617226843236486e-05,
      "loss": 0.4071,
      "step": 4960
    },
    {
      "epoch": 2.33,
      "grad_norm": 1.8459957838058472,
      "learning_rate": 2.6157514522379686e-05,
      "loss": 0.4627,
      "step": 4970
    },
    {
      "epoch": 2.33,
      "grad_norm": 1.3036408424377441,
      "learning_rate": 2.614273640849079e-05,
      "loss": 0.4246,
      "step": 4980
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.767042875289917,
      "learning_rate": 2.6127934122756217e-05,
      "loss": 0.4078,
      "step": 4990
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.1272004842758179,
      "learning_rate": 2.611310769728643e-05,
      "loss": 0.4262,
      "step": 5000
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.2992268800735474,
      "learning_rate": 2.6098257164244276e-05,
      "loss": 0.4415,
      "step": 5010
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.0109690427780151,
      "learning_rate": 2.60833825558449e-05,
      "loss": 0.4383,
      "step": 5020
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.7549852132797241,
      "learning_rate": 2.6068483904355654e-05,
      "loss": 0.397,
      "step": 5030
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.3684316873550415,
      "learning_rate": 2.605356124209607e-05,
      "loss": 0.4412,
      "step": 5040
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.1052019596099854,
      "learning_rate": 2.603861460143775e-05,
      "loss": 0.4579,
      "step": 5050
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.2079472541809082,
      "learning_rate": 2.6023644014804316e-05,
      "loss": 0.4238,
      "step": 5060
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.2886065244674683,
      "learning_rate": 2.6008649514671348e-05,
      "loss": 0.4175,
      "step": 5070
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.2375693321228027,
      "learning_rate": 2.5993631133566277e-05,
      "loss": 0.4032,
      "step": 5080
    },
    {
      "epoch": 2.39,
      "grad_norm": 1.1737343072891235,
      "learning_rate": 2.5978588904068357e-05,
      "loss": 0.4491,
      "step": 5090
    },
    {
      "epoch": 2.39,
      "grad_norm": 1.496962547302246,
      "learning_rate": 2.5963522858808575e-05,
      "loss": 0.4225,
      "step": 5100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.8589844703674316,
      "learning_rate": 2.594843303046958e-05,
      "loss": 0.4307,
      "step": 5110
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.1339386701583862,
      "learning_rate": 2.5933319451785602e-05,
      "loss": 0.4627,
      "step": 5120
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.4995168447494507,
      "learning_rate": 2.5918182155542415e-05,
      "loss": 0.4382,
      "step": 5130
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.5526684522628784,
      "learning_rate": 2.5903021174577217e-05,
      "loss": 0.4377,
      "step": 5140
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.8705402612686157,
      "learning_rate": 2.5887836541778605e-05,
      "loss": 0.4433,
      "step": 5150
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.9908652305603027,
      "learning_rate": 2.587262829008648e-05,
      "loss": 0.4457,
      "step": 5160
    },
    {
      "epoch": 2.42,
      "grad_norm": 1.251514196395874,
      "learning_rate": 2.5857396452491966e-05,
      "loss": 0.426,
      "step": 5170
    },
    {
      "epoch": 2.43,
      "grad_norm": 1.934004545211792,
      "learning_rate": 2.5842141062037374e-05,
      "loss": 0.4263,
      "step": 5180
    },
    {
      "epoch": 2.43,
      "grad_norm": 1.4540090560913086,
      "learning_rate": 2.5826862151816088e-05,
      "loss": 0.4284,
      "step": 5190
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.8727673292160034,
      "learning_rate": 2.5811559754972524e-05,
      "loss": 0.4505,
      "step": 5200
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.1378813982009888,
      "learning_rate": 2.5796233904702046e-05,
      "loss": 0.4483,
      "step": 5210
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.2467305660247803,
      "learning_rate": 2.5780884634250894e-05,
      "loss": 0.4005,
      "step": 5220
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.8919406533241272,
      "learning_rate": 2.5765511976916108e-05,
      "loss": 0.4244,
      "step": 5230
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.2093337774276733,
      "learning_rate": 2.5750115966045468e-05,
      "loss": 0.4161,
      "step": 5240
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.075281023979187,
      "learning_rate": 2.5734696635037414e-05,
      "loss": 0.4731,
      "step": 5250
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.9056360125541687,
      "learning_rate": 2.5719254017340974e-05,
      "loss": 0.4438,
      "step": 5260
    },
    {
      "epoch": 2.47,
      "grad_norm": 1.210811734199524,
      "learning_rate": 2.5703788146455693e-05,
      "loss": 0.4545,
      "step": 5270
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.0664479732513428,
      "learning_rate": 2.5688299055931547e-05,
      "loss": 0.4427,
      "step": 5280
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.1127115488052368,
      "learning_rate": 2.5672786779368904e-05,
      "loss": 0.4423,
      "step": 5290
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.9573156833648682,
      "learning_rate": 2.5657251350418406e-05,
      "loss": 0.4136,
      "step": 5300
    },
    {
      "epoch": 2.49,
      "grad_norm": 1.4358376264572144,
      "learning_rate": 2.5641692802780934e-05,
      "loss": 0.4097,
      "step": 5310
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.9030030965805054,
      "learning_rate": 2.5626111170207522e-05,
      "loss": 0.4305,
      "step": 5320
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.8793052434921265,
      "learning_rate": 2.5610506486499266e-05,
      "loss": 0.4217,
      "step": 5330
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.0009198188781738,
      "learning_rate": 2.5594878785507284e-05,
      "loss": 0.4508,
      "step": 5340
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.3590750694274902,
      "learning_rate": 2.5579228101132617e-05,
      "loss": 0.4428,
      "step": 5350
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.1724865436553955,
      "learning_rate": 2.556355446732616e-05,
      "loss": 0.4487,
      "step": 5360
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.8868981003761292,
      "learning_rate": 2.554785791808861e-05,
      "loss": 0.468,
      "step": 5370
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.7148743867874146,
      "learning_rate": 2.5532138487470344e-05,
      "loss": 0.4308,
      "step": 5380
    },
    {
      "epoch": 2.53,
      "grad_norm": 1.4288851022720337,
      "learning_rate": 2.5516396209571405e-05,
      "loss": 0.4124,
      "step": 5390
    },
    {
      "epoch": 2.53,
      "grad_norm": 1.2240303754806519,
      "learning_rate": 2.550063111854138e-05,
      "loss": 0.4098,
      "step": 5400
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.7096704244613647,
      "learning_rate": 2.5484843248579353e-05,
      "loss": 0.4557,
      "step": 5410
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.009147047996521,
      "learning_rate": 2.5469032633933817e-05,
      "loss": 0.4409,
      "step": 5420
    },
    {
      "epoch": 2.55,
      "grad_norm": 1.3513011932373047,
      "learning_rate": 2.5453199308902612e-05,
      "loss": 0.4098,
      "step": 5430
    },
    {
      "epoch": 2.55,
      "grad_norm": 1.5585428476333618,
      "learning_rate": 2.5437343307832832e-05,
      "loss": 0.4621,
      "step": 5440
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.489725947380066,
      "learning_rate": 2.542146466512077e-05,
      "loss": 0.4354,
      "step": 5450
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.766488790512085,
      "learning_rate": 2.5405563415211836e-05,
      "loss": 0.4037,
      "step": 5460
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.3253897428512573,
      "learning_rate": 2.538963959260048e-05,
      "loss": 0.4294,
      "step": 5470
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.9730870723724365,
      "learning_rate": 2.5373693231830117e-05,
      "loss": 0.4259,
      "step": 5480
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.5123579502105713,
      "learning_rate": 2.5357724367493052e-05,
      "loss": 0.4176,
      "step": 5490
    },
    {
      "epoch": 2.58,
      "grad_norm": 1.2938424348831177,
      "learning_rate": 2.5341733034230423e-05,
      "loss": 0.4254,
      "step": 5500
    },
    {
      "epoch": 2.58,
      "grad_norm": 1.1137312650680542,
      "learning_rate": 2.5325719266732084e-05,
      "loss": 0.4426,
      "step": 5510
    },
    {
      "epoch": 2.59,
      "grad_norm": 1.082529067993164,
      "learning_rate": 2.5309683099736567e-05,
      "loss": 0.4536,
      "step": 5520
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.7689487934112549,
      "learning_rate": 2.5293624568031008e-05,
      "loss": 0.4353,
      "step": 5530
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.1523401737213135,
      "learning_rate": 2.527754370645103e-05,
      "loss": 0.4209,
      "step": 5540
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.2508143186569214,
      "learning_rate": 2.5261440549880726e-05,
      "loss": 0.4579,
      "step": 5550
    },
    {
      "epoch": 2.61,
      "grad_norm": 1.2111269235610962,
      "learning_rate": 2.5245315133252538e-05,
      "loss": 0.4525,
      "step": 5560
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.8860145211219788,
      "learning_rate": 2.522916749154719e-05,
      "loss": 0.4489,
      "step": 5570
    },
    {
      "epoch": 2.62,
      "grad_norm": 1.3551092147827148,
      "learning_rate": 2.521299765979364e-05,
      "loss": 0.4445,
      "step": 5580
    },
    {
      "epoch": 2.62,
      "grad_norm": 1.938841700553894,
      "learning_rate": 2.5196805673068964e-05,
      "loss": 0.381,
      "step": 5590
    },
    {
      "epoch": 2.63,
      "grad_norm": 1.066371202468872,
      "learning_rate": 2.5180591566498298e-05,
      "loss": 0.4647,
      "step": 5600
    },
    {
      "epoch": 2.63,
      "grad_norm": 1.4087985754013062,
      "learning_rate": 2.516435537525478e-05,
      "loss": 0.439,
      "step": 5610
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.9979239106178284,
      "learning_rate": 2.5148097134559436e-05,
      "loss": 0.4294,
      "step": 5620
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.1988505125045776,
      "learning_rate": 2.513181687968114e-05,
      "loss": 0.4092,
      "step": 5630
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.0903410911560059,
      "learning_rate": 2.5115514645936506e-05,
      "loss": 0.4377,
      "step": 5640
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.9267657995224,
      "learning_rate": 2.5099190468689843e-05,
      "loss": 0.398,
      "step": 5650
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.0701206922531128,
      "learning_rate": 2.5082844383353048e-05,
      "loss": 0.4336,
      "step": 5660
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.3240785598754883,
      "learning_rate": 2.5066476425385552e-05,
      "loss": 0.3941,
      "step": 5670
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.0942836999893188,
      "learning_rate": 2.5050086630294225e-05,
      "loss": 0.4439,
      "step": 5680
    },
    {
      "epoch": 2.67,
      "grad_norm": 1.096063494682312,
      "learning_rate": 2.503367503363332e-05,
      "loss": 0.4328,
      "step": 5690
    },
    {
      "epoch": 2.67,
      "grad_norm": 1.0282142162322998,
      "learning_rate": 2.5017241671004373e-05,
      "loss": 0.399,
      "step": 5700
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.946344256401062,
      "learning_rate": 2.5000786578056142e-05,
      "loss": 0.4155,
      "step": 5710
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.1098644733428955,
      "learning_rate": 2.4984309790484525e-05,
      "loss": 0.4466,
      "step": 5720
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.8766494989395142,
      "learning_rate": 2.496781134403248e-05,
      "loss": 0.4461,
      "step": 5730
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.8873691558837891,
      "learning_rate": 2.4951291274489946e-05,
      "loss": 0.4169,
      "step": 5740
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.3056522607803345,
      "learning_rate": 2.4934749617693777e-05,
      "loss": 0.4194,
      "step": 5750
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.2833548784255981,
      "learning_rate": 2.4918186409527656e-05,
      "loss": 0.4063,
      "step": 5760
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.4844835996627808,
      "learning_rate": 2.4901601685922007e-05,
      "loss": 0.4594,
      "step": 5770
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.0446438789367676,
      "learning_rate": 2.4884995482853933e-05,
      "loss": 0.44,
      "step": 5780
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.2840982675552368,
      "learning_rate": 2.4868367836347142e-05,
      "loss": 0.397,
      "step": 5790
    },
    {
      "epoch": 2.72,
      "grad_norm": 1.251654863357544,
      "learning_rate": 2.4851718782471836e-05,
      "loss": 0.425,
      "step": 5800
    },
    {
      "epoch": 2.72,
      "grad_norm": 1.1239383220672607,
      "learning_rate": 2.4835048357344677e-05,
      "loss": 0.4366,
      "step": 5810
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.1538646221160889,
      "learning_rate": 2.481835659712868e-05,
      "loss": 0.4437,
      "step": 5820
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.7615028619766235,
      "learning_rate": 2.480164353803314e-05,
      "loss": 0.4549,
      "step": 5830
    },
    {
      "epoch": 2.74,
      "grad_norm": 1.2631865739822388,
      "learning_rate": 2.478490921631356e-05,
      "loss": 0.4227,
      "step": 5840
    },
    {
      "epoch": 2.74,
      "grad_norm": 1.5836018323898315,
      "learning_rate": 2.4768153668271563e-05,
      "loss": 0.4585,
      "step": 5850
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.9912697076797485,
      "learning_rate": 2.475137693025482e-05,
      "loss": 0.4505,
      "step": 5860
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.9759060740470886,
      "learning_rate": 2.473457903865697e-05,
      "loss": 0.4163,
      "step": 5870
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.5890073776245117,
      "learning_rate": 2.4717760029917546e-05,
      "loss": 0.4391,
      "step": 5880
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.9897321462631226,
      "learning_rate": 2.4700919940521872e-05,
      "loss": 0.4114,
      "step": 5890
    },
    {
      "epoch": 2.77,
      "grad_norm": 1.0855814218521118,
      "learning_rate": 2.4684058807001023e-05,
      "loss": 0.4368,
      "step": 5900
    },
    {
      "epoch": 2.77,
      "grad_norm": 1.5503089427947998,
      "learning_rate": 2.466717666593172e-05,
      "loss": 0.4402,
      "step": 5910
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.524308681488037,
      "learning_rate": 2.4650273553936237e-05,
      "loss": 0.4343,
      "step": 5920
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.7981009483337402,
      "learning_rate": 2.4633349507682367e-05,
      "loss": 0.4186,
      "step": 5930
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.2121065855026245,
      "learning_rate": 2.4616404563883302e-05,
      "loss": 0.4365,
      "step": 5940
    },
    {
      "epoch": 2.79,
      "grad_norm": 1.5405789613723755,
      "learning_rate": 2.4599438759297564e-05,
      "loss": 0.4344,
      "step": 5950
    },
    {
      "epoch": 2.79,
      "grad_norm": 1.3049598932266235,
      "learning_rate": 2.4582452130728933e-05,
      "loss": 0.3927,
      "step": 5960
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.8006672859191895,
      "learning_rate": 2.456544471502637e-05,
      "loss": 0.402,
      "step": 5970
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.0524626970291138,
      "learning_rate": 2.4548416549083908e-05,
      "loss": 0.4074,
      "step": 5980
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.9051045179367065,
      "learning_rate": 2.453136766984061e-05,
      "loss": 0.4044,
      "step": 5990
    },
    {
      "epoch": 2.81,
      "grad_norm": 1.268096923828125,
      "learning_rate": 2.4514298114280474e-05,
      "loss": 0.4248,
      "step": 6000
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.165075659751892,
      "learning_rate": 2.4497207919432335e-05,
      "loss": 0.4057,
      "step": 6010
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.9804874062538147,
      "learning_rate": 2.4480097122369818e-05,
      "loss": 0.4334,
      "step": 6020
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.3164597749710083,
      "learning_rate": 2.446296576021124e-05,
      "loss": 0.4116,
      "step": 6030
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.0511760711669922,
      "learning_rate": 2.444581387011951e-05,
      "loss": 0.4303,
      "step": 6040
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.20068359375,
      "learning_rate": 2.442864148930208e-05,
      "loss": 0.4508,
      "step": 6050
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.0285989046096802,
      "learning_rate": 2.441144865501087e-05,
      "loss": 0.4561,
      "step": 6060
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.364382028579712,
      "learning_rate": 2.439423540454214e-05,
      "loss": 0.4326,
      "step": 6070
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.0930802822113037,
      "learning_rate": 2.4377001775236453e-05,
      "loss": 0.4591,
      "step": 6080
    },
    {
      "epoch": 2.86,
      "grad_norm": 1.513089656829834,
      "learning_rate": 2.4359747804478576e-05,
      "loss": 0.4563,
      "step": 6090
    },
    {
      "epoch": 2.86,
      "grad_norm": 1.718767523765564,
      "learning_rate": 2.4342473529697406e-05,
      "loss": 0.4154,
      "step": 6100
    },
    {
      "epoch": 2.86,
      "grad_norm": 1.1550260782241821,
      "learning_rate": 2.432517898836589e-05,
      "loss": 0.4416,
      "step": 6110
    },
    {
      "epoch": 2.87,
      "grad_norm": 1.5652037858963013,
      "learning_rate": 2.4307864218000927e-05,
      "loss": 0.4516,
      "step": 6120
    },
    {
      "epoch": 2.87,
      "grad_norm": 1.2189844846725464,
      "learning_rate": 2.4290529256163305e-05,
      "loss": 0.3969,
      "step": 6130
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.8600881099700928,
      "learning_rate": 2.4273174140457618e-05,
      "loss": 0.4263,
      "step": 6140
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.3346283435821533,
      "learning_rate": 2.425579890853217e-05,
      "loss": 0.4536,
      "step": 6150
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.3880804777145386,
      "learning_rate": 2.4238403598078905e-05,
      "loss": 0.3843,
      "step": 6160
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.5537525415420532,
      "learning_rate": 2.4220988246833334e-05,
      "loss": 0.4375,
      "step": 6170
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.1012085676193237,
      "learning_rate": 2.4203552892574428e-05,
      "loss": 0.4508,
      "step": 6180
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.0162818431854248,
      "learning_rate": 2.4186097573124556e-05,
      "loss": 0.3993,
      "step": 6190
    },
    {
      "epoch": 2.91,
      "grad_norm": 1.2057181596755981,
      "learning_rate": 2.41686223263494e-05,
      "loss": 0.4839,
      "step": 6200
    },
    {
      "epoch": 2.91,
      "grad_norm": 1.341999888420105,
      "learning_rate": 2.4151127190157864e-05,
      "loss": 0.4112,
      "step": 6210
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.3456130027770996,
      "learning_rate": 2.413361220250201e-05,
      "loss": 0.4232,
      "step": 6220
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.233945369720459,
      "learning_rate": 2.411607740137695e-05,
      "loss": 0.4395,
      "step": 6230
    },
    {
      "epoch": 2.93,
      "grad_norm": 1.4185211658477783,
      "learning_rate": 2.4098522824820782e-05,
      "loss": 0.4437,
      "step": 6240
    },
    {
      "epoch": 2.93,
      "grad_norm": 1.2311252355575562,
      "learning_rate": 2.4080948510914505e-05,
      "loss": 0.3934,
      "step": 6250
    },
    {
      "epoch": 2.93,
      "grad_norm": 1.1874425411224365,
      "learning_rate": 2.4063354497781932e-05,
      "loss": 0.4467,
      "step": 6260
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.1947839260101318,
      "learning_rate": 2.404574082358961e-05,
      "loss": 0.4574,
      "step": 6270
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.2120932340621948,
      "learning_rate": 2.4028107526546736e-05,
      "loss": 0.4302,
      "step": 6280
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.6111561059951782,
      "learning_rate": 2.4010454644905076e-05,
      "loss": 0.424,
      "step": 6290
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.4231961965560913,
      "learning_rate": 2.3992782216958876e-05,
      "loss": 0.4494,
      "step": 6300
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.3714748620986938,
      "learning_rate": 2.3975090281044793e-05,
      "loss": 0.4021,
      "step": 6310
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.7109646797180176,
      "learning_rate": 2.3957378875541795e-05,
      "loss": 0.3906,
      "step": 6320
    },
    {
      "epoch": 2.97,
      "grad_norm": 1.2526252269744873,
      "learning_rate": 2.3939648038871082e-05,
      "loss": 0.4275,
      "step": 6330
    },
    {
      "epoch": 2.97,
      "grad_norm": 1.1453516483306885,
      "learning_rate": 2.392189780949602e-05,
      "loss": 0.4287,
      "step": 6340
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.4757120609283447,
      "learning_rate": 2.3904128225922027e-05,
      "loss": 0.424,
      "step": 6350
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.1383576393127441,
      "learning_rate": 2.3886339326696517e-05,
      "loss": 0.4327,
      "step": 6360
    },
    {
      "epoch": 2.99,
      "grad_norm": 1.1282737255096436,
      "learning_rate": 2.3868531150408798e-05,
      "loss": 0.423,
      "step": 6370
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.9936639070510864,
      "learning_rate": 2.3850703735690002e-05,
      "loss": 0.4109,
      "step": 6380
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.591102957725525,
      "learning_rate": 2.3832857121212992e-05,
      "loss": 0.4155,
      "step": 6390
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8459746241569519,
      "learning_rate": 2.3814991345692283e-05,
      "loss": 0.4613,
      "step": 6400
    },
    {
      "epoch": 3.01,
      "grad_norm": 1.5186268091201782,
      "learning_rate": 2.3797106447883947e-05,
      "loss": 0.4012,
      "step": 6410
    },
    {
      "epoch": 3.01,
      "grad_norm": 1.0979949235916138,
      "learning_rate": 2.377920246658555e-05,
      "loss": 0.3926,
      "step": 6420
    },
    {
      "epoch": 3.01,
      "grad_norm": 1.0863800048828125,
      "learning_rate": 2.376127944063605e-05,
      "loss": 0.4265,
      "step": 6430
    },
    {
      "epoch": 3.02,
      "grad_norm": 1.223052740097046,
      "learning_rate": 2.3743337408915717e-05,
      "loss": 0.3743,
      "step": 6440
    },
    {
      "epoch": 3.02,
      "grad_norm": 1.707360863685608,
      "learning_rate": 2.3725376410346052e-05,
      "loss": 0.3905,
      "step": 6450
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.7291398048400879,
      "learning_rate": 2.3707396483889697e-05,
      "loss": 0.4001,
      "step": 6460
    },
    {
      "epoch": 3.03,
      "grad_norm": 1.029990315437317,
      "learning_rate": 2.3689397668550365e-05,
      "loss": 0.3977,
      "step": 6470
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.7896524667739868,
      "learning_rate": 2.3671380003372726e-05,
      "loss": 0.3942,
      "step": 6480
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.0031380653381348,
      "learning_rate": 2.365334352744236e-05,
      "loss": 0.4321,
      "step": 6490
    },
    {
      "epoch": 3.05,
      "grad_norm": 1.624577522277832,
      "learning_rate": 2.3635288279885647e-05,
      "loss": 0.4048,
      "step": 6500
    },
    {
      "epoch": 3.05,
      "grad_norm": 1.0632269382476807,
      "learning_rate": 2.3617214299869673e-05,
      "loss": 0.3784,
      "step": 6510
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.3881925344467163,
      "learning_rate": 2.359912162660219e-05,
      "loss": 0.385,
      "step": 6520
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.9923982620239258,
      "learning_rate": 2.358101029933147e-05,
      "loss": 0.4288,
      "step": 6530
    },
    {
      "epoch": 3.07,
      "grad_norm": 1.5355782508850098,
      "learning_rate": 2.3562880357346273e-05,
      "loss": 0.3649,
      "step": 6540
    },
    {
      "epoch": 3.07,
      "grad_norm": 1.177649974822998,
      "learning_rate": 2.3544731839975726e-05,
      "loss": 0.4004,
      "step": 6550
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.9823176860809326,
      "learning_rate": 2.3526564786589263e-05,
      "loss": 0.4577,
      "step": 6560
    },
    {
      "epoch": 3.08,
      "grad_norm": 1.5967732667922974,
      "learning_rate": 2.3508379236596522e-05,
      "loss": 0.3859,
      "step": 6570
    },
    {
      "epoch": 3.08,
      "grad_norm": 1.2945692539215088,
      "learning_rate": 2.349017522944726e-05,
      "loss": 0.3933,
      "step": 6580
    },
    {
      "epoch": 3.09,
      "grad_norm": 1.0568474531173706,
      "learning_rate": 2.347195280463128e-05,
      "loss": 0.4063,
      "step": 6590
    },
    {
      "epoch": 3.09,
      "grad_norm": 1.4918124675750732,
      "learning_rate": 2.3453712001678343e-05,
      "loss": 0.4044,
      "step": 6600
    },
    {
      "epoch": 3.1,
      "grad_norm": 1.7463560104370117,
      "learning_rate": 2.3435452860158067e-05,
      "loss": 0.4214,
      "step": 6610
    },
    {
      "epoch": 3.1,
      "grad_norm": 1.1595178842544556,
      "learning_rate": 2.3417175419679856e-05,
      "loss": 0.3854,
      "step": 6620
    },
    {
      "epoch": 3.11,
      "grad_norm": 1.1285499334335327,
      "learning_rate": 2.3398879719892814e-05,
      "loss": 0.4241,
      "step": 6630
    },
    {
      "epoch": 3.11,
      "grad_norm": 1.3319388628005981,
      "learning_rate": 2.3380565800485646e-05,
      "loss": 0.4074,
      "step": 6640
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.315078854560852,
      "learning_rate": 2.3362233701186584e-05,
      "loss": 0.4254,
      "step": 6650
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.3795433044433594,
      "learning_rate": 2.3343883461763307e-05,
      "loss": 0.4019,
      "step": 6660
    },
    {
      "epoch": 3.13,
      "grad_norm": 1.0539709329605103,
      "learning_rate": 2.3325515122022834e-05,
      "loss": 0.403,
      "step": 6670
    },
    {
      "epoch": 3.13,
      "grad_norm": 1.1747087240219116,
      "learning_rate": 2.3307128721811444e-05,
      "loss": 0.4205,
      "step": 6680
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.438403606414795,
      "learning_rate": 2.3288724301014613e-05,
      "loss": 0.3994,
      "step": 6690
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.1135761737823486,
      "learning_rate": 2.3270301899556897e-05,
      "loss": 0.3968,
      "step": 6700
    },
    {
      "epoch": 3.15,
      "grad_norm": 1.509230136871338,
      "learning_rate": 2.3251861557401852e-05,
      "loss": 0.3695,
      "step": 6710
    },
    {
      "epoch": 3.15,
      "grad_norm": 1.411992073059082,
      "learning_rate": 2.3233403314551965e-05,
      "loss": 0.4095,
      "step": 6720
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.176233172416687,
      "learning_rate": 2.321492721104855e-05,
      "loss": 0.3638,
      "step": 6730
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.1729151010513306,
      "learning_rate": 2.319643328697166e-05,
      "loss": 0.3781,
      "step": 6740
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.7977508306503296,
      "learning_rate": 2.3177921582440015e-05,
      "loss": 0.3939,
      "step": 6750
    },
    {
      "epoch": 3.17,
      "grad_norm": 1.6342905759811401,
      "learning_rate": 2.3159392137610902e-05,
      "loss": 0.3859,
      "step": 6760
    },
    {
      "epoch": 3.17,
      "grad_norm": 1.2504040002822876,
      "learning_rate": 2.314084499268009e-05,
      "loss": 0.3913,
      "step": 6770
    },
    {
      "epoch": 3.18,
      "grad_norm": 1.5161076784133911,
      "learning_rate": 2.312228018788175e-05,
      "loss": 0.4182,
      "step": 6780
    },
    {
      "epoch": 3.18,
      "grad_norm": 1.1133768558502197,
      "learning_rate": 2.3103697763488352e-05,
      "loss": 0.4117,
      "step": 6790
    },
    {
      "epoch": 3.19,
      "grad_norm": 1.090694785118103,
      "learning_rate": 2.3085097759810602e-05,
      "loss": 0.3912,
      "step": 6800
    },
    {
      "epoch": 3.19,
      "grad_norm": 1.5430316925048828,
      "learning_rate": 2.3066480217197332e-05,
      "loss": 0.4066,
      "step": 6810
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.1199034452438354,
      "learning_rate": 2.3047845176035425e-05,
      "loss": 0.3785,
      "step": 6820
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.7917568683624268,
      "learning_rate": 2.3029192676749717e-05,
      "loss": 0.3809,
      "step": 6830
    },
    {
      "epoch": 3.21,
      "grad_norm": 1.6983171701431274,
      "learning_rate": 2.3010522759802922e-05,
      "loss": 0.3923,
      "step": 6840
    },
    {
      "epoch": 3.21,
      "grad_norm": 1.2089861631393433,
      "learning_rate": 2.2991835465695534e-05,
      "loss": 0.4074,
      "step": 6850
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.108988642692566,
      "learning_rate": 2.297313083496575e-05,
      "loss": 0.3918,
      "step": 6860
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.162425994873047,
      "learning_rate": 2.2954408908189367e-05,
      "loss": 0.4237,
      "step": 6870
    },
    {
      "epoch": 3.23,
      "grad_norm": 1.0712668895721436,
      "learning_rate": 2.2935669725979708e-05,
      "loss": 0.3987,
      "step": 6880
    },
    {
      "epoch": 3.23,
      "grad_norm": 1.2341210842132568,
      "learning_rate": 2.2916913328987515e-05,
      "loss": 0.4176,
      "step": 6890
    },
    {
      "epoch": 3.23,
      "grad_norm": 1.441519856452942,
      "learning_rate": 2.2898139757900897e-05,
      "loss": 0.398,
      "step": 6900
    },
    {
      "epoch": 3.24,
      "grad_norm": 1.3886278867721558,
      "learning_rate": 2.2879349053445204e-05,
      "loss": 0.3839,
      "step": 6910
    },
    {
      "epoch": 3.24,
      "grad_norm": 1.379485845565796,
      "learning_rate": 2.286054125638295e-05,
      "loss": 0.419,
      "step": 6920
    },
    {
      "epoch": 3.25,
      "grad_norm": 1.0199459791183472,
      "learning_rate": 2.284171640751374e-05,
      "loss": 0.4402,
      "step": 6930
    },
    {
      "epoch": 3.25,
      "grad_norm": 1.1872330904006958,
      "learning_rate": 2.2822874547674157e-05,
      "loss": 0.4177,
      "step": 6940
    },
    {
      "epoch": 3.26,
      "grad_norm": 1.195482611656189,
      "learning_rate": 2.2804015717737693e-05,
      "loss": 0.3864,
      "step": 6950
    },
    {
      "epoch": 3.26,
      "grad_norm": 1.2675551176071167,
      "learning_rate": 2.2785139958614654e-05,
      "loss": 0.4212,
      "step": 6960
    },
    {
      "epoch": 3.27,
      "grad_norm": 1.4745999574661255,
      "learning_rate": 2.2766247311252063e-05,
      "loss": 0.448,
      "step": 6970
    },
    {
      "epoch": 3.27,
      "grad_norm": 1.7728908061981201,
      "learning_rate": 2.274733781663358e-05,
      "loss": 0.3988,
      "step": 6980
    },
    {
      "epoch": 3.28,
      "grad_norm": 1.1915130615234375,
      "learning_rate": 2.2728411515779426e-05,
      "loss": 0.3774,
      "step": 6990
    },
    {
      "epoch": 3.28,
      "grad_norm": 1.5165650844573975,
      "learning_rate": 2.2709468449746264e-05,
      "loss": 0.4056,
      "step": 7000
    },
    {
      "epoch": 3.29,
      "grad_norm": 1.0240724086761475,
      "learning_rate": 2.269050865962713e-05,
      "loss": 0.3975,
      "step": 7010
    },
    {
      "epoch": 3.29,
      "grad_norm": 1.8609634637832642,
      "learning_rate": 2.2671532186551335e-05,
      "loss": 0.4054,
      "step": 7020
    },
    {
      "epoch": 3.3,
      "grad_norm": 1.1508244276046753,
      "learning_rate": 2.265253907168439e-05,
      "loss": 0.409,
      "step": 7030
    },
    {
      "epoch": 3.3,
      "grad_norm": 1.3514297008514404,
      "learning_rate": 2.2633529356227897e-05,
      "loss": 0.4411,
      "step": 7040
    },
    {
      "epoch": 3.31,
      "grad_norm": 1.7587779760360718,
      "learning_rate": 2.261450308141948e-05,
      "loss": 0.4136,
      "step": 7050
    },
    {
      "epoch": 3.31,
      "grad_norm": 1.063020944595337,
      "learning_rate": 2.259546028853267e-05,
      "loss": 0.4069,
      "step": 7060
    },
    {
      "epoch": 3.31,
      "grad_norm": 1.2778429985046387,
      "learning_rate": 2.257640101887685e-05,
      "loss": 0.4,
      "step": 7070
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.3062241077423096,
      "learning_rate": 2.2557325313797135e-05,
      "loss": 0.407,
      "step": 7080
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.3584825992584229,
      "learning_rate": 2.2538233214674284e-05,
      "loss": 0.4279,
      "step": 7090
    },
    {
      "epoch": 3.33,
      "grad_norm": 1.543480396270752,
      "learning_rate": 2.251912476292464e-05,
      "loss": 0.4163,
      "step": 7100
    },
    {
      "epoch": 3.33,
      "grad_norm": 2.2749643325805664,
      "learning_rate": 2.25e-05,
      "loss": 0.3973,
      "step": 7110
    },
    {
      "epoch": 3.34,
      "grad_norm": 1.0906314849853516,
      "learning_rate": 2.248085896738756e-05,
      "loss": 0.3973,
      "step": 7120
    },
    {
      "epoch": 3.34,
      "grad_norm": 1.4088633060455322,
      "learning_rate": 2.24617017066098e-05,
      "loss": 0.3843,
      "step": 7130
    },
    {
      "epoch": 3.35,
      "grad_norm": 1.3358713388442993,
      "learning_rate": 2.2442528259224412e-05,
      "loss": 0.4051,
      "step": 7140
    },
    {
      "epoch": 3.35,
      "grad_norm": 1.0918927192687988,
      "learning_rate": 2.2423338666824187e-05,
      "loss": 0.398,
      "step": 7150
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.5057291984558105,
      "learning_rate": 2.240413297103696e-05,
      "loss": 0.4025,
      "step": 7160
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.890936017036438,
      "learning_rate": 2.2384911213525476e-05,
      "loss": 0.4031,
      "step": 7170
    },
    {
      "epoch": 3.37,
      "grad_norm": 1.2384320497512817,
      "learning_rate": 2.2365673435987344e-05,
      "loss": 0.395,
      "step": 7180
    },
    {
      "epoch": 3.37,
      "grad_norm": 1.8127704858779907,
      "learning_rate": 2.2346419680154906e-05,
      "loss": 0.3692,
      "step": 7190
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.7073185443878174,
      "learning_rate": 2.2327149987795185e-05,
      "loss": 0.3938,
      "step": 7200
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.2786412239074707,
      "learning_rate": 2.2307864400709758e-05,
      "loss": 0.3716,
      "step": 7210
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.1930650472640991,
      "learning_rate": 2.2288562960734694e-05,
      "loss": 0.4185,
      "step": 7220
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.9481475353240967,
      "learning_rate": 2.226924570974044e-05,
      "loss": 0.4048,
      "step": 7230
    },
    {
      "epoch": 3.39,
      "grad_norm": 1.328179121017456,
      "learning_rate": 2.2249912689631754e-05,
      "loss": 0.3906,
      "step": 7240
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.1352941989898682,
      "learning_rate": 2.2230563942347592e-05,
      "loss": 0.4257,
      "step": 7250
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.6577613353729248,
      "learning_rate": 2.2211199509861036e-05,
      "loss": 0.4507,
      "step": 7260
    },
    {
      "epoch": 3.41,
      "grad_norm": 1.0800226926803589,
      "learning_rate": 2.2191819434179184e-05,
      "loss": 0.3988,
      "step": 7270
    },
    {
      "epoch": 3.41,
      "grad_norm": 1.5107243061065674,
      "learning_rate": 2.2172423757343072e-05,
      "loss": 0.3996,
      "step": 7280
    },
    {
      "epoch": 3.42,
      "grad_norm": 1.5439566373825073,
      "learning_rate": 2.2153012521427593e-05,
      "loss": 0.4127,
      "step": 7290
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.9597909450531006,
      "learning_rate": 2.2133585768541365e-05,
      "loss": 0.3816,
      "step": 7300
    },
    {
      "epoch": 3.43,
      "grad_norm": 1.2435896396636963,
      "learning_rate": 2.211414354082669e-05,
      "loss": 0.4026,
      "step": 7310
    },
    {
      "epoch": 3.43,
      "grad_norm": 1.0240792036056519,
      "learning_rate": 2.209468588045943e-05,
      "loss": 0.3842,
      "step": 7320
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.9736368060112,
      "learning_rate": 2.207521282964893e-05,
      "loss": 0.3999,
      "step": 7330
    },
    {
      "epoch": 3.44,
      "grad_norm": 1.2485549449920654,
      "learning_rate": 2.205572443063791e-05,
      "loss": 0.4242,
      "step": 7340
    },
    {
      "epoch": 3.45,
      "grad_norm": 1.4941335916519165,
      "learning_rate": 2.2036220725702395e-05,
      "loss": 0.3849,
      "step": 7350
    },
    {
      "epoch": 3.45,
      "grad_norm": 1.2978267669677734,
      "learning_rate": 2.201670175715161e-05,
      "loss": 0.4216,
      "step": 7360
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.8920642137527466,
      "learning_rate": 2.19971675673279e-05,
      "loss": 0.4273,
      "step": 7370
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.305574655532837,
      "learning_rate": 2.1977618198606607e-05,
      "loss": 0.388,
      "step": 7380
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.1104607582092285,
      "learning_rate": 2.195805369339602e-05,
      "loss": 0.3818,
      "step": 7390
    },
    {
      "epoch": 3.47,
      "grad_norm": 1.5566587448120117,
      "learning_rate": 2.193847409413727e-05,
      "loss": 0.3972,
      "step": 7400
    },
    {
      "epoch": 3.47,
      "grad_norm": 1.4787757396697998,
      "learning_rate": 2.19188794433042e-05,
      "loss": 0.4029,
      "step": 7410
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.3273087739944458,
      "learning_rate": 2.189926978340334e-05,
      "loss": 0.4084,
      "step": 7420
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.6850179433822632,
      "learning_rate": 2.1879645156973748e-05,
      "loss": 0.3796,
      "step": 7430
    },
    {
      "epoch": 3.49,
      "grad_norm": 1.074401617050171,
      "learning_rate": 2.186000560658697e-05,
      "loss": 0.4299,
      "step": 7440
    },
    {
      "epoch": 3.49,
      "grad_norm": 1.1681243181228638,
      "learning_rate": 2.1840351174846917e-05,
      "loss": 0.3911,
      "step": 7450
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.7881163358688354,
      "learning_rate": 2.1820681904389798e-05,
      "loss": 0.4328,
      "step": 7460
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.33110511302948,
      "learning_rate": 2.1800997837883977e-05,
      "loss": 0.3824,
      "step": 7470
    },
    {
      "epoch": 3.51,
      "grad_norm": 1.6649004220962524,
      "learning_rate": 2.1781299018029955e-05,
      "loss": 0.3739,
      "step": 7480
    },
    {
      "epoch": 3.51,
      "grad_norm": 1.1005432605743408,
      "learning_rate": 2.176158548756021e-05,
      "loss": 0.4256,
      "step": 7490
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.237522840499878,
      "learning_rate": 2.1741857289239137e-05,
      "loss": 0.3838,
      "step": 7500
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.0075600147247314,
      "learning_rate": 2.172211446586296e-05,
      "loss": 0.3792,
      "step": 7510
    },
    {
      "epoch": 3.53,
      "grad_norm": 1.0308550596237183,
      "learning_rate": 2.170235706025962e-05,
      "loss": 0.382,
      "step": 7520
    },
    {
      "epoch": 3.53,
      "grad_norm": 1.2117871046066284,
      "learning_rate": 2.168258511528869e-05,
      "loss": 0.3956,
      "step": 7530
    },
    {
      "epoch": 3.53,
      "grad_norm": 1.0779027938842773,
      "learning_rate": 2.166279867384129e-05,
      "loss": 0.4093,
      "step": 7540
    },
    {
      "epoch": 3.54,
      "grad_norm": 1.25896155834198,
      "learning_rate": 2.164299777883998e-05,
      "loss": 0.3873,
      "step": 7550
    },
    {
      "epoch": 3.54,
      "grad_norm": 1.0103634595870972,
      "learning_rate": 2.162318247323868e-05,
      "loss": 0.3659,
      "step": 7560
    },
    {
      "epoch": 3.55,
      "grad_norm": 1.9155018329620361,
      "learning_rate": 2.1603352800022567e-05,
      "loss": 0.3929,
      "step": 7570
    },
    {
      "epoch": 3.55,
      "grad_norm": 1.0176912546157837,
      "learning_rate": 2.1583508802207987e-05,
      "loss": 0.4379,
      "step": 7580
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.7474489212036133,
      "learning_rate": 2.1563650522842357e-05,
      "loss": 0.3948,
      "step": 7590
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.1201305389404297,
      "learning_rate": 2.154377800500408e-05,
      "loss": 0.3917,
      "step": 7600
    },
    {
      "epoch": 3.57,
      "grad_norm": 2.0224390029907227,
      "learning_rate": 2.152389129180245e-05,
      "loss": 0.4222,
      "step": 7610
    },
    {
      "epoch": 3.57,
      "grad_norm": 1.9025629758834839,
      "learning_rate": 2.1503990426377543e-05,
      "loss": 0.3947,
      "step": 7620
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.8242522478103638,
      "learning_rate": 2.148407545190014e-05,
      "loss": 0.4154,
      "step": 7630
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.357429027557373,
      "learning_rate": 2.146414641157163e-05,
      "loss": 0.3489,
      "step": 7640
    },
    {
      "epoch": 3.59,
      "grad_norm": 1.3480255603790283,
      "learning_rate": 2.144420334862392e-05,
      "loss": 0.4447,
      "step": 7650
    },
    {
      "epoch": 3.59,
      "grad_norm": 1.129936933517456,
      "learning_rate": 2.1424246306319324e-05,
      "loss": 0.3806,
      "step": 7660
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.1844545602798462,
      "learning_rate": 2.14042753279505e-05,
      "loss": 0.3818,
      "step": 7670
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.0708673000335693,
      "learning_rate": 2.138429045684031e-05,
      "loss": 0.3811,
      "step": 7680
    },
    {
      "epoch": 3.61,
      "grad_norm": 1.4546144008636475,
      "learning_rate": 2.136429173634178e-05,
      "loss": 0.3836,
      "step": 7690
    },
    {
      "epoch": 3.61,
      "grad_norm": 1.224501132965088,
      "learning_rate": 2.1344279209837963e-05,
      "loss": 0.3993,
      "step": 7700
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.9996079206466675,
      "learning_rate": 2.1324252920741877e-05,
      "loss": 0.3841,
      "step": 7710
    },
    {
      "epoch": 3.62,
      "grad_norm": 1.3368377685546875,
      "learning_rate": 2.130421291249637e-05,
      "loss": 0.407,
      "step": 7720
    },
    {
      "epoch": 3.62,
      "grad_norm": 1.2675801515579224,
      "learning_rate": 2.1284159228574077e-05,
      "loss": 0.4332,
      "step": 7730
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.0615251064300537,
      "learning_rate": 2.1264091912477285e-05,
      "loss": 0.3811,
      "step": 7740
    },
    {
      "epoch": 3.63,
      "grad_norm": 1.4248861074447632,
      "learning_rate": 2.1244011007737855e-05,
      "loss": 0.44,
      "step": 7750
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.0178085565567017,
      "learning_rate": 2.1223916557917125e-05,
      "loss": 0.3754,
      "step": 7760
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.9359239935874939,
      "learning_rate": 2.120380860660582e-05,
      "loss": 0.4255,
      "step": 7770
    },
    {
      "epoch": 3.65,
      "grad_norm": 1.1951837539672852,
      "learning_rate": 2.1183687197423962e-05,
      "loss": 0.4156,
      "step": 7780
    },
    {
      "epoch": 3.65,
      "grad_norm": 1.1021337509155273,
      "learning_rate": 2.1163552374020737e-05,
      "loss": 0.4324,
      "step": 7790
    },
    {
      "epoch": 3.66,
      "grad_norm": 1.3904850482940674,
      "learning_rate": 2.1143404180074467e-05,
      "loss": 0.4031,
      "step": 7800
    },
    {
      "epoch": 3.66,
      "grad_norm": 1.2523494958877563,
      "learning_rate": 2.1123242659292458e-05,
      "loss": 0.3999,
      "step": 7810
    },
    {
      "epoch": 3.67,
      "grad_norm": 1.4352020025253296,
      "learning_rate": 2.1103067855410927e-05,
      "loss": 0.4146,
      "step": 7820
    },
    {
      "epoch": 3.67,
      "grad_norm": 1.2756670713424683,
      "learning_rate": 2.108287981219491e-05,
      "loss": 0.4153,
      "step": 7830
    },
    {
      "epoch": 3.68,
      "grad_norm": 2.1368932723999023,
      "learning_rate": 2.1062678573438162e-05,
      "loss": 0.4261,
      "step": 7840
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.583065152168274,
      "learning_rate": 2.1042464182963062e-05,
      "loss": 0.3696,
      "step": 7850
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.2343215942382812,
      "learning_rate": 2.102223668462052e-05,
      "loss": 0.3819,
      "step": 7860
    },
    {
      "epoch": 3.69,
      "grad_norm": 1.2815920114517212,
      "learning_rate": 2.1001996122289886e-05,
      "loss": 0.3773,
      "step": 7870
    },
    {
      "epoch": 3.69,
      "grad_norm": 1.383484125137329,
      "learning_rate": 2.0981742539878832e-05,
      "loss": 0.3823,
      "step": 7880
    },
    {
      "epoch": 3.7,
      "grad_norm": 1.3128427267074585,
      "learning_rate": 2.09614759813233e-05,
      "loss": 0.4239,
      "step": 7890
    },
    {
      "epoch": 3.7,
      "grad_norm": 1.8357834815979004,
      "learning_rate": 2.0941196490587352e-05,
      "loss": 0.4276,
      "step": 7900
    },
    {
      "epoch": 3.71,
      "grad_norm": 1.5928959846496582,
      "learning_rate": 2.0920904111663133e-05,
      "loss": 0.4023,
      "step": 7910
    },
    {
      "epoch": 3.71,
      "grad_norm": 1.428240180015564,
      "learning_rate": 2.0900598888570727e-05,
      "loss": 0.4241,
      "step": 7920
    },
    {
      "epoch": 3.72,
      "grad_norm": 1.3974944353103638,
      "learning_rate": 2.0880280865358088e-05,
      "loss": 0.4079,
      "step": 7930
    },
    {
      "epoch": 3.72,
      "grad_norm": 1.3464157581329346,
      "learning_rate": 2.0859950086100926e-05,
      "loss": 0.3795,
      "step": 7940
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.9904042482376099,
      "learning_rate": 2.0839606594902646e-05,
      "loss": 0.4623,
      "step": 7950
    },
    {
      "epoch": 3.73,
      "grad_norm": 1.1182701587677002,
      "learning_rate": 2.0819250435894202e-05,
      "loss": 0.3847,
      "step": 7960
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.004128098487854,
      "learning_rate": 2.079888165323405e-05,
      "loss": 0.4258,
      "step": 7970
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.1868481636047363,
      "learning_rate": 2.0778500291108017e-05,
      "loss": 0.396,
      "step": 7980
    },
    {
      "epoch": 3.75,
      "grad_norm": 1.1728826761245728,
      "learning_rate": 2.0758106393729225e-05,
      "loss": 0.413,
      "step": 7990
    },
    {
      "epoch": 3.75,
      "grad_norm": 2.0213840007781982,
      "learning_rate": 2.0737700005337984e-05,
      "loss": 0.3765,
      "step": 8000
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.340093970298767,
      "learning_rate": 2.0717281170201706e-05,
      "loss": 0.3914,
      "step": 8010
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.2604906558990479,
      "learning_rate": 2.06968499326148e-05,
      "loss": 0.3899,
      "step": 8020
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.8875666856765747,
      "learning_rate": 2.0676406336898577e-05,
      "loss": 0.435,
      "step": 8030
    },
    {
      "epoch": 3.77,
      "grad_norm": 1.2517726421356201,
      "learning_rate": 2.0655950427401163e-05,
      "loss": 0.4012,
      "step": 8040
    },
    {
      "epoch": 3.77,
      "grad_norm": 1.3522816896438599,
      "learning_rate": 2.0635482248497396e-05,
      "loss": 0.433,
      "step": 8050
    },
    {
      "epoch": 3.78,
      "grad_norm": 1.5644359588623047,
      "learning_rate": 2.0615001844588716e-05,
      "loss": 0.409,
      "step": 8060
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.1389904022216797,
      "learning_rate": 2.05945092601031e-05,
      "loss": 0.423,
      "step": 8070
    },
    {
      "epoch": 3.79,
      "grad_norm": 1.3755507469177246,
      "learning_rate": 2.0574004539494946e-05,
      "loss": 0.4659,
      "step": 8080
    },
    {
      "epoch": 3.79,
      "grad_norm": 1.9242714643478394,
      "learning_rate": 2.0553487727244965e-05,
      "loss": 0.4198,
      "step": 8090
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.2080377340316772,
      "learning_rate": 2.0532958867860115e-05,
      "loss": 0.4368,
      "step": 8100
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.9872636795043945,
      "learning_rate": 2.0512418005873482e-05,
      "loss": 0.3692,
      "step": 8110
    },
    {
      "epoch": 3.81,
      "grad_norm": 1.822630763053894,
      "learning_rate": 2.0491865185844182e-05,
      "loss": 0.4057,
      "step": 8120
    },
    {
      "epoch": 3.81,
      "grad_norm": 1.0549782514572144,
      "learning_rate": 2.0471300452357273e-05,
      "loss": 0.381,
      "step": 8130
    },
    {
      "epoch": 3.82,
      "grad_norm": 1.3593446016311646,
      "learning_rate": 2.0450723850023675e-05,
      "loss": 0.4182,
      "step": 8140
    },
    {
      "epoch": 3.82,
      "grad_norm": 1.4145433902740479,
      "learning_rate": 2.0430135423480026e-05,
      "loss": 0.4016,
      "step": 8150
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.952480673789978,
      "learning_rate": 2.040953521738864e-05,
      "loss": 0.3759,
      "step": 8160
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.3586636781692505,
      "learning_rate": 2.038892327643736e-05,
      "loss": 0.3772,
      "step": 8170
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.3237379789352417,
      "learning_rate": 2.0368299645339512e-05,
      "loss": 0.4032,
      "step": 8180
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.4261562824249268,
      "learning_rate": 2.0347664368833765e-05,
      "loss": 0.3949,
      "step": 8190
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.4394419193267822,
      "learning_rate": 2.0327017491684052e-05,
      "loss": 0.3457,
      "step": 8200
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.4247260093688965,
      "learning_rate": 2.0306359058679468e-05,
      "loss": 0.4167,
      "step": 8210
    },
    {
      "epoch": 3.85,
      "grad_norm": 1.4551986455917358,
      "learning_rate": 2.0285689114634184e-05,
      "loss": 0.4168,
      "step": 8220
    },
    {
      "epoch": 3.86,
      "grad_norm": 1.2615617513656616,
      "learning_rate": 2.0265007704387343e-05,
      "loss": 0.4076,
      "step": 8230
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.9187427163124084,
      "learning_rate": 2.024431487280294e-05,
      "loss": 0.4069,
      "step": 8240
    },
    {
      "epoch": 3.87,
      "grad_norm": 1.2644920349121094,
      "learning_rate": 2.0223610664769788e-05,
      "loss": 0.4077,
      "step": 8250
    },
    {
      "epoch": 3.87,
      "grad_norm": 1.2283352613449097,
      "learning_rate": 2.020289512520133e-05,
      "loss": 0.4262,
      "step": 8260
    },
    {
      "epoch": 3.88,
      "grad_norm": 1.4683085680007935,
      "learning_rate": 2.0182168299035635e-05,
      "loss": 0.4231,
      "step": 8270
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.287146806716919,
      "learning_rate": 2.0161430231235216e-05,
      "loss": 0.4164,
      "step": 8280
    },
    {
      "epoch": 3.89,
      "grad_norm": 1.236685037612915,
      "learning_rate": 2.0140680966787008e-05,
      "loss": 0.4092,
      "step": 8290
    },
    {
      "epoch": 3.89,
      "grad_norm": 1.2019184827804565,
      "learning_rate": 2.0119920550702203e-05,
      "loss": 0.4048,
      "step": 8300
    },
    {
      "epoch": 3.9,
      "grad_norm": 1.4485009908676147,
      "learning_rate": 2.0099149028016214e-05,
      "loss": 0.4014,
      "step": 8310
    },
    {
      "epoch": 3.9,
      "grad_norm": 1.4008500576019287,
      "learning_rate": 2.007836644378852e-05,
      "loss": 0.4007,
      "step": 8320
    },
    {
      "epoch": 3.91,
      "grad_norm": 1.710365891456604,
      "learning_rate": 2.0057572843102615e-05,
      "loss": 0.4248,
      "step": 8330
    },
    {
      "epoch": 3.91,
      "grad_norm": 1.027437448501587,
      "learning_rate": 2.003676827106589e-05,
      "loss": 0.4327,
      "step": 8340
    },
    {
      "epoch": 3.91,
      "grad_norm": 1.1008431911468506,
      "learning_rate": 2.0015952772809522e-05,
      "loss": 0.4219,
      "step": 8350
    },
    {
      "epoch": 3.92,
      "grad_norm": 1.6792984008789062,
      "learning_rate": 1.99951263934884e-05,
      "loss": 0.4426,
      "step": 8360
    },
    {
      "epoch": 3.92,
      "grad_norm": 1.2034193277359009,
      "learning_rate": 1.997428917828102e-05,
      "loss": 0.4163,
      "step": 8370
    },
    {
      "epoch": 3.93,
      "grad_norm": 1.2403075695037842,
      "learning_rate": 1.9953441172389375e-05,
      "loss": 0.416,
      "step": 8380
    },
    {
      "epoch": 3.93,
      "grad_norm": 1.4425809383392334,
      "learning_rate": 1.9932582421038872e-05,
      "loss": 0.4122,
      "step": 8390
    },
    {
      "epoch": 3.94,
      "grad_norm": 1.3166425228118896,
      "learning_rate": 1.9911712969478235e-05,
      "loss": 0.4128,
      "step": 8400
    },
    {
      "epoch": 3.94,
      "grad_norm": 1.1703400611877441,
      "learning_rate": 1.9890832862979383e-05,
      "loss": 0.4007,
      "step": 8410
    },
    {
      "epoch": 3.95,
      "grad_norm": 1.9017689228057861,
      "learning_rate": 1.986994214683736e-05,
      "loss": 0.4043,
      "step": 8420
    },
    {
      "epoch": 3.95,
      "grad_norm": 1.3325614929199219,
      "learning_rate": 1.9849040866370227e-05,
      "loss": 0.4276,
      "step": 8430
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.0263925790786743,
      "learning_rate": 1.9828129066918954e-05,
      "loss": 0.4065,
      "step": 8440
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.6980295181274414,
      "learning_rate": 1.9807206793847337e-05,
      "loss": 0.3989,
      "step": 8450
    },
    {
      "epoch": 3.97,
      "grad_norm": 1.6949275732040405,
      "learning_rate": 1.978627409254189e-05,
      "loss": 0.4073,
      "step": 8460
    },
    {
      "epoch": 3.97,
      "grad_norm": 1.354638934135437,
      "learning_rate": 1.9765331008411742e-05,
      "loss": 0.3969,
      "step": 8470
    },
    {
      "epoch": 3.98,
      "grad_norm": 1.0766994953155518,
      "learning_rate": 1.974437758688856e-05,
      "loss": 0.3956,
      "step": 8480
    },
    {
      "epoch": 3.98,
      "grad_norm": 1.5093576908111572,
      "learning_rate": 1.9723413873426427e-05,
      "loss": 0.3809,
      "step": 8490
    },
    {
      "epoch": 3.98,
      "grad_norm": 1.2375223636627197,
      "learning_rate": 1.9702439913501743e-05,
      "loss": 0.3923,
      "step": 8500
    },
    {
      "epoch": 3.99,
      "grad_norm": 1.3385486602783203,
      "learning_rate": 1.9681455752613156e-05,
      "loss": 0.4123,
      "step": 8510
    },
    {
      "epoch": 3.99,
      "grad_norm": 1.2161595821380615,
      "learning_rate": 1.966046143628143e-05,
      "loss": 0.3748,
      "step": 8520
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.7272511720657349,
      "learning_rate": 1.9639457010049358e-05,
      "loss": 0.3882,
      "step": 8530
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.5214341878890991,
      "learning_rate": 1.9618442519481668e-05,
      "loss": 0.3909,
      "step": 8540
    },
    {
      "epoch": 4.01,
      "grad_norm": 1.0981956720352173,
      "learning_rate": 1.9597418010164923e-05,
      "loss": 0.366,
      "step": 8550
    },
    {
      "epoch": 4.01,
      "grad_norm": 1.315088152885437,
      "learning_rate": 1.9576383527707416e-05,
      "loss": 0.4145,
      "step": 8560
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.3641769886016846,
      "learning_rate": 1.9555339117739073e-05,
      "loss": 0.4136,
      "step": 8570
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.3433911800384521,
      "learning_rate": 1.9534284825911357e-05,
      "loss": 0.3791,
      "step": 8580
    },
    {
      "epoch": 4.03,
      "grad_norm": 1.0506044626235962,
      "learning_rate": 1.9513220697897177e-05,
      "loss": 0.3629,
      "step": 8590
    },
    {
      "epoch": 4.03,
      "grad_norm": 1.355149269104004,
      "learning_rate": 1.949214677939076e-05,
      "loss": 0.3538,
      "step": 8600
    },
    {
      "epoch": 4.04,
      "grad_norm": 1.5365365743637085,
      "learning_rate": 1.9471063116107596e-05,
      "loss": 0.4016,
      "step": 8610
    },
    {
      "epoch": 4.04,
      "grad_norm": 1.950120449066162,
      "learning_rate": 1.9449969753784283e-05,
      "loss": 0.372,
      "step": 8620
    },
    {
      "epoch": 4.05,
      "grad_norm": 1.3105560541152954,
      "learning_rate": 1.9428866738178493e-05,
      "loss": 0.325,
      "step": 8630
    },
    {
      "epoch": 4.05,
      "grad_norm": 1.5326350927352905,
      "learning_rate": 1.9407754115068814e-05,
      "loss": 0.3625,
      "step": 8640
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.9622383713722229,
      "learning_rate": 1.9386631930254686e-05,
      "loss": 0.3733,
      "step": 8650
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.4498436450958252,
      "learning_rate": 1.9365500229556296e-05,
      "loss": 0.3539,
      "step": 8660
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.7245897054672241,
      "learning_rate": 1.9344359058814456e-05,
      "loss": 0.3685,
      "step": 8670
    },
    {
      "epoch": 4.07,
      "grad_norm": 1.9291276931762695,
      "learning_rate": 1.932320846389054e-05,
      "loss": 0.3713,
      "step": 8680
    },
    {
      "epoch": 4.07,
      "grad_norm": 1.1760950088500977,
      "learning_rate": 1.9302048490666356e-05,
      "loss": 0.3754,
      "step": 8690
    },
    {
      "epoch": 4.08,
      "grad_norm": 1.41798996925354,
      "learning_rate": 1.9280879185044057e-05,
      "loss": 0.3759,
      "step": 8700
    },
    {
      "epoch": 4.08,
      "grad_norm": 1.3745241165161133,
      "learning_rate": 1.9259700592946043e-05,
      "loss": 0.3771,
      "step": 8710
    },
    {
      "epoch": 4.09,
      "grad_norm": 1.209822177886963,
      "learning_rate": 1.923851276031486e-05,
      "loss": 0.3731,
      "step": 8720
    },
    {
      "epoch": 4.09,
      "grad_norm": 1.231552243232727,
      "learning_rate": 1.9217315733113095e-05,
      "loss": 0.3694,
      "step": 8730
    },
    {
      "epoch": 4.1,
      "grad_norm": 1.1018046140670776,
      "learning_rate": 1.9196109557323283e-05,
      "loss": 0.3885,
      "step": 8740
    },
    {
      "epoch": 4.1,
      "grad_norm": 1.0878173112869263,
      "learning_rate": 1.917489427894781e-05,
      "loss": 0.3889,
      "step": 8750
    },
    {
      "epoch": 4.11,
      "grad_norm": 2.0818302631378174,
      "learning_rate": 1.9153669944008802e-05,
      "loss": 0.3983,
      "step": 8760
    },
    {
      "epoch": 4.11,
      "grad_norm": 1.326686978340149,
      "learning_rate": 1.9132436598548028e-05,
      "loss": 0.3669,
      "step": 8770
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.2502738237380981,
      "learning_rate": 1.911119428862681e-05,
      "loss": 0.4,
      "step": 8780
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.6183159351348877,
      "learning_rate": 1.908994306032592e-05,
      "loss": 0.3447,
      "step": 8790
    },
    {
      "epoch": 4.13,
      "grad_norm": 1.7129007577896118,
      "learning_rate": 1.9068682959745463e-05,
      "loss": 0.3907,
      "step": 8800
    },
    {
      "epoch": 4.13,
      "grad_norm": 2.131758213043213,
      "learning_rate": 1.904741403300481e-05,
      "loss": 0.3607,
      "step": 8810
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.9320842027664185,
      "learning_rate": 1.902613632624245e-05,
      "loss": 0.3503,
      "step": 8820
    },
    {
      "epoch": 4.14,
      "grad_norm": 1.4629877805709839,
      "learning_rate": 1.9004849885615954e-05,
      "loss": 0.3971,
      "step": 8830
    },
    {
      "epoch": 4.14,
      "grad_norm": 1.3736177682876587,
      "learning_rate": 1.898355475730181e-05,
      "loss": 0.3678,
      "step": 8840
    },
    {
      "epoch": 4.15,
      "grad_norm": 1.219594955444336,
      "learning_rate": 1.896225098749537e-05,
      "loss": 0.3515,
      "step": 8850
    },
    {
      "epoch": 4.15,
      "grad_norm": 1.7991209030151367,
      "learning_rate": 1.8940938622410717e-05,
      "loss": 0.3548,
      "step": 8860
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.4331655502319336,
      "learning_rate": 1.89196177082806e-05,
      "loss": 0.393,
      "step": 8870
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.4460670948028564,
      "learning_rate": 1.8898288291356287e-05,
      "loss": 0.3662,
      "step": 8880
    },
    {
      "epoch": 4.17,
      "grad_norm": 1.5269067287445068,
      "learning_rate": 1.887695041790752e-05,
      "loss": 0.354,
      "step": 8890
    },
    {
      "epoch": 4.17,
      "grad_norm": 1.380394697189331,
      "learning_rate": 1.8855604134222356e-05,
      "loss": 0.4271,
      "step": 8900
    },
    {
      "epoch": 4.18,
      "grad_norm": 1.1240992546081543,
      "learning_rate": 1.883424948660712e-05,
      "loss": 0.3494,
      "step": 8910
    },
    {
      "epoch": 4.18,
      "grad_norm": 1.1596579551696777,
      "learning_rate": 1.8812886521386275e-05,
      "loss": 0.3917,
      "step": 8920
    },
    {
      "epoch": 4.19,
      "grad_norm": 1.464470386505127,
      "learning_rate": 1.8791515284902312e-05,
      "loss": 0.3904,
      "step": 8930
    },
    {
      "epoch": 4.19,
      "grad_norm": 1.6233004331588745,
      "learning_rate": 1.877013582351569e-05,
      "loss": 0.3832,
      "step": 8940
    },
    {
      "epoch": 4.2,
      "grad_norm": 1.426207423210144,
      "learning_rate": 1.8748748183604688e-05,
      "loss": 0.3599,
      "step": 8950
    },
    {
      "epoch": 4.2,
      "grad_norm": 1.4137873649597168,
      "learning_rate": 1.8727352411565345e-05,
      "loss": 0.3769,
      "step": 8960
    },
    {
      "epoch": 4.21,
      "grad_norm": 1.4856529235839844,
      "learning_rate": 1.870594855381132e-05,
      "loss": 0.354,
      "step": 8970
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.8387706279754639,
      "learning_rate": 1.868453665677384e-05,
      "loss": 0.3863,
      "step": 8980
    },
    {
      "epoch": 4.21,
      "grad_norm": 1.660750150680542,
      "learning_rate": 1.866311676690154e-05,
      "loss": 0.3951,
      "step": 8990
    },
    {
      "epoch": 4.22,
      "grad_norm": 1.4679274559020996,
      "learning_rate": 1.8641688930660417e-05,
      "loss": 0.3691,
      "step": 9000
    },
    {
      "epoch": 4.22,
      "grad_norm": 1.3845847845077515,
      "learning_rate": 1.86202531945337e-05,
      "loss": 0.3831,
      "step": 9010
    },
    {
      "epoch": 4.23,
      "grad_norm": 1.5605926513671875,
      "learning_rate": 1.8598809605021746e-05,
      "loss": 0.3571,
      "step": 9020
    },
    {
      "epoch": 4.23,
      "grad_norm": 1.3675929307937622,
      "learning_rate": 1.857735820864196e-05,
      "loss": 0.3753,
      "step": 9030
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.414428472518921,
      "learning_rate": 1.855589905192869e-05,
      "loss": 0.3972,
      "step": 9040
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.7830721139907837,
      "learning_rate": 1.8534432181433086e-05,
      "loss": 0.3851,
      "step": 9050
    },
    {
      "epoch": 4.25,
      "grad_norm": 2.1168670654296875,
      "learning_rate": 1.8512957643723064e-05,
      "loss": 0.3757,
      "step": 9060
    },
    {
      "epoch": 4.25,
      "grad_norm": 1.2796016931533813,
      "learning_rate": 1.849147548538316e-05,
      "loss": 0.3919,
      "step": 9070
    },
    {
      "epoch": 4.26,
      "grad_norm": 1.280464768409729,
      "learning_rate": 1.846998575301444e-05,
      "loss": 0.3634,
      "step": 9080
    },
    {
      "epoch": 4.26,
      "grad_norm": 1.402626395225525,
      "learning_rate": 1.8448488493234402e-05,
      "loss": 0.4147,
      "step": 9090
    },
    {
      "epoch": 4.27,
      "grad_norm": 1.5137217044830322,
      "learning_rate": 1.8426983752676877e-05,
      "loss": 0.377,
      "step": 9100
    },
    {
      "epoch": 4.27,
      "grad_norm": 1.101765513420105,
      "learning_rate": 1.8405471577991914e-05,
      "loss": 0.3437,
      "step": 9110
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.7022652626037598,
      "learning_rate": 1.8383952015845697e-05,
      "loss": 0.424,
      "step": 9120
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.1924684047698975,
      "learning_rate": 1.8362425112920443e-05,
      "loss": 0.3558,
      "step": 9130
    },
    {
      "epoch": 4.29,
      "grad_norm": 1.6964741945266724,
      "learning_rate": 1.8340890915914268e-05,
      "loss": 0.3712,
      "step": 9140
    },
    {
      "epoch": 4.29,
      "grad_norm": 1.3849518299102783,
      "learning_rate": 1.831934947154114e-05,
      "loss": 0.35,
      "step": 9150
    },
    {
      "epoch": 4.29,
      "grad_norm": 1.3439782857894897,
      "learning_rate": 1.829780082653073e-05,
      "loss": 0.3454,
      "step": 9160
    },
    {
      "epoch": 4.3,
      "grad_norm": 2.0037989616394043,
      "learning_rate": 1.8276245027628337e-05,
      "loss": 0.3847,
      "step": 9170
    },
    {
      "epoch": 4.3,
      "grad_norm": 2.0093040466308594,
      "learning_rate": 1.825468212159477e-05,
      "loss": 0.3702,
      "step": 9180
    },
    {
      "epoch": 4.31,
      "grad_norm": 1.357911229133606,
      "learning_rate": 1.8233112155206275e-05,
      "loss": 0.3721,
      "step": 9190
    },
    {
      "epoch": 4.31,
      "grad_norm": 1.721880316734314,
      "learning_rate": 1.821153517525439e-05,
      "loss": 0.3664,
      "step": 9200
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.6943491697311401,
      "learning_rate": 1.8189951228545884e-05,
      "loss": 0.3946,
      "step": 9210
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.8508117198944092,
      "learning_rate": 1.816836036190263e-05,
      "loss": 0.3598,
      "step": 9220
    },
    {
      "epoch": 4.33,
      "grad_norm": 1.2994515895843506,
      "learning_rate": 1.8146762622161522e-05,
      "loss": 0.3803,
      "step": 9230
    },
    {
      "epoch": 4.33,
      "grad_norm": 1.0669236183166504,
      "learning_rate": 1.812515805617435e-05,
      "loss": 0.374,
      "step": 9240
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.3345820903778076,
      "learning_rate": 1.810354671080773e-05,
      "loss": 0.3728,
      "step": 9250
    },
    {
      "epoch": 4.34,
      "grad_norm": 1.2186955213546753,
      "learning_rate": 1.8081928632942965e-05,
      "loss": 0.4064,
      "step": 9260
    },
    {
      "epoch": 4.35,
      "grad_norm": 2.1650991439819336,
      "learning_rate": 1.806030386947597e-05,
      "loss": 0.3477,
      "step": 9270
    },
    {
      "epoch": 4.35,
      "grad_norm": 1.6300454139709473,
      "learning_rate": 1.8038672467317178e-05,
      "loss": 0.4012,
      "step": 9280
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.008471965789795,
      "learning_rate": 1.8017034473391397e-05,
      "loss": 0.3884,
      "step": 9290
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.6069937944412231,
      "learning_rate": 1.7995389934637757e-05,
      "loss": 0.3725,
      "step": 9300
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.2715412378311157,
      "learning_rate": 1.797373889800957e-05,
      "loss": 0.3405,
      "step": 9310
    },
    {
      "epoch": 4.37,
      "grad_norm": 1.774332046508789,
      "learning_rate": 1.7952081410474255e-05,
      "loss": 0.3726,
      "step": 9320
    },
    {
      "epoch": 4.37,
      "grad_norm": 1.0777627229690552,
      "learning_rate": 1.7930417519013215e-05,
      "loss": 0.3887,
      "step": 9330
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.9657349586486816,
      "learning_rate": 1.7908747270621753e-05,
      "loss": 0.3496,
      "step": 9340
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.0217759609222412,
      "learning_rate": 1.788707071230896e-05,
      "loss": 0.3961,
      "step": 9350
    },
    {
      "epoch": 4.39,
      "grad_norm": 1.166359543800354,
      "learning_rate": 1.7865387891097615e-05,
      "loss": 0.3598,
      "step": 9360
    },
    {
      "epoch": 4.39,
      "grad_norm": 1.9392215013504028,
      "learning_rate": 1.784369885402408e-05,
      "loss": 0.3785,
      "step": 9370
    },
    {
      "epoch": 4.4,
      "grad_norm": 1.8308161497116089,
      "learning_rate": 1.7822003648138208e-05,
      "loss": 0.4009,
      "step": 9380
    },
    {
      "epoch": 4.4,
      "grad_norm": 1.7567341327667236,
      "learning_rate": 1.780030232050322e-05,
      "loss": 0.3646,
      "step": 9390
    },
    {
      "epoch": 4.41,
      "grad_norm": 1.1666609048843384,
      "learning_rate": 1.7778594918195634e-05,
      "loss": 0.3672,
      "step": 9400
    },
    {
      "epoch": 4.41,
      "grad_norm": 1.487126111984253,
      "learning_rate": 1.7756881488305133e-05,
      "loss": 0.3616,
      "step": 9410
    },
    {
      "epoch": 4.42,
      "grad_norm": 1.2172702550888062,
      "learning_rate": 1.7735162077934484e-05,
      "loss": 0.3629,
      "step": 9420
    },
    {
      "epoch": 4.42,
      "grad_norm": 1.3772999048233032,
      "learning_rate": 1.771343673419942e-05,
      "loss": 0.3439,
      "step": 9430
    },
    {
      "epoch": 4.43,
      "grad_norm": 1.4205539226531982,
      "learning_rate": 1.7691705504228548e-05,
      "loss": 0.3701,
      "step": 9440
    },
    {
      "epoch": 4.43,
      "grad_norm": 1.8833186626434326,
      "learning_rate": 1.766996843516326e-05,
      "loss": 0.378,
      "step": 9450
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.3858819007873535,
      "learning_rate": 1.7648225574157573e-05,
      "loss": 0.322,
      "step": 9460
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.593843698501587,
      "learning_rate": 1.7626476968378117e-05,
      "loss": 0.4046,
      "step": 9470
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.3985199928283691,
      "learning_rate": 1.760472266500396e-05,
      "loss": 0.3893,
      "step": 9480
    },
    {
      "epoch": 4.45,
      "grad_norm": 1.7583168745040894,
      "learning_rate": 1.758296271122652e-05,
      "loss": 0.3706,
      "step": 9490
    },
    {
      "epoch": 4.45,
      "grad_norm": 1.964767336845398,
      "learning_rate": 1.7561197154249486e-05,
      "loss": 0.3673,
      "step": 9500
    },
    {
      "epoch": 4.46,
      "grad_norm": 1.3554705381393433,
      "learning_rate": 1.7539426041288717e-05,
      "loss": 0.3326,
      "step": 9510
    },
    {
      "epoch": 4.46,
      "grad_norm": 1.2214350700378418,
      "learning_rate": 1.7517649419572092e-05,
      "loss": 0.3938,
      "step": 9520
    },
    {
      "epoch": 4.47,
      "grad_norm": 1.170867681503296,
      "learning_rate": 1.749586733633946e-05,
      "loss": 0.3524,
      "step": 9530
    },
    {
      "epoch": 4.47,
      "grad_norm": 1.502933382987976,
      "learning_rate": 1.7474079838842513e-05,
      "loss": 0.3722,
      "step": 9540
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.3184928894042969,
      "learning_rate": 1.7452286974344687e-05,
      "loss": 0.4053,
      "step": 9550
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.4400990009307861,
      "learning_rate": 1.743048879012107e-05,
      "loss": 0.4136,
      "step": 9560
    },
    {
      "epoch": 4.49,
      "grad_norm": 1.9894874095916748,
      "learning_rate": 1.740868533345827e-05,
      "loss": 0.3991,
      "step": 9570
    },
    {
      "epoch": 4.49,
      "grad_norm": 1.4722200632095337,
      "learning_rate": 1.738687665165436e-05,
      "loss": 0.367,
      "step": 9580
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.863244891166687,
      "learning_rate": 1.7365062792018713e-05,
      "loss": 0.3728,
      "step": 9590
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.279341459274292,
      "learning_rate": 1.7343243801871977e-05,
      "loss": 0.3712,
      "step": 9600
    },
    {
      "epoch": 4.51,
      "grad_norm": 1.1696741580963135,
      "learning_rate": 1.7321419728545884e-05,
      "loss": 0.3926,
      "step": 9610
    },
    {
      "epoch": 4.51,
      "grad_norm": 1.881609320640564,
      "learning_rate": 1.729959061938323e-05,
      "loss": 0.3626,
      "step": 9620
    },
    {
      "epoch": 4.51,
      "grad_norm": 1.3582148551940918,
      "learning_rate": 1.727775652173772e-05,
      "loss": 0.3945,
      "step": 9630
    },
    {
      "epoch": 4.52,
      "grad_norm": 2.1846213340759277,
      "learning_rate": 1.725591748297387e-05,
      "loss": 0.3675,
      "step": 9640
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.5324076414108276,
      "learning_rate": 1.7234073550466934e-05,
      "loss": 0.3835,
      "step": 9650
    },
    {
      "epoch": 4.53,
      "grad_norm": 1.2830740213394165,
      "learning_rate": 1.7212224771602776e-05,
      "loss": 0.3721,
      "step": 9660
    },
    {
      "epoch": 4.53,
      "grad_norm": 1.7397009134292603,
      "learning_rate": 1.719037119377776e-05,
      "loss": 0.3975,
      "step": 9670
    },
    {
      "epoch": 4.54,
      "grad_norm": 1.2378263473510742,
      "learning_rate": 1.7168512864398684e-05,
      "loss": 0.4017,
      "step": 9680
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.0267019271850586,
      "learning_rate": 1.7146649830882635e-05,
      "loss": 0.3729,
      "step": 9690
    },
    {
      "epoch": 4.55,
      "grad_norm": 1.3951120376586914,
      "learning_rate": 1.7124782140656912e-05,
      "loss": 0.3781,
      "step": 9700
    },
    {
      "epoch": 4.55,
      "grad_norm": 1.6233704090118408,
      "learning_rate": 1.7102909841158906e-05,
      "loss": 0.3804,
      "step": 9710
    },
    {
      "epoch": 4.56,
      "grad_norm": 1.1870685815811157,
      "learning_rate": 1.7081032979836027e-05,
      "loss": 0.3984,
      "step": 9720
    },
    {
      "epoch": 4.56,
      "grad_norm": 1.6888400316238403,
      "learning_rate": 1.705915160414556e-05,
      "loss": 0.3255,
      "step": 9730
    },
    {
      "epoch": 4.57,
      "grad_norm": 1.8398011922836304,
      "learning_rate": 1.7037265761554588e-05,
      "loss": 0.3935,
      "step": 9740
    },
    {
      "epoch": 4.57,
      "grad_norm": 1.4257444143295288,
      "learning_rate": 1.7015375499539908e-05,
      "loss": 0.3839,
      "step": 9750
    },
    {
      "epoch": 4.58,
      "grad_norm": 1.3054895401000977,
      "learning_rate": 1.699348086558786e-05,
      "loss": 0.3948,
      "step": 9760
    },
    {
      "epoch": 4.58,
      "grad_norm": 1.3122972249984741,
      "learning_rate": 1.6971581907194306e-05,
      "loss": 0.3496,
      "step": 9770
    },
    {
      "epoch": 4.59,
      "grad_norm": 1.1853444576263428,
      "learning_rate": 1.694967867186447e-05,
      "loss": 0.3516,
      "step": 9780
    },
    {
      "epoch": 4.59,
      "grad_norm": 1.0797865390777588,
      "learning_rate": 1.6927771207112866e-05,
      "loss": 0.3654,
      "step": 9790
    },
    {
      "epoch": 4.59,
      "grad_norm": 1.482877254486084,
      "learning_rate": 1.690585956046316e-05,
      "loss": 0.3951,
      "step": 9800
    },
    {
      "epoch": 4.6,
      "grad_norm": 1.3320215940475464,
      "learning_rate": 1.688394377944812e-05,
      "loss": 0.398,
      "step": 9810
    },
    {
      "epoch": 4.6,
      "grad_norm": 1.665268063545227,
      "learning_rate": 1.686202391160946e-05,
      "loss": 0.3765,
      "step": 9820
    },
    {
      "epoch": 4.61,
      "grad_norm": 1.7943010330200195,
      "learning_rate": 1.684010000449778e-05,
      "loss": 0.3829,
      "step": 9830
    },
    {
      "epoch": 4.61,
      "grad_norm": 1.4524922370910645,
      "learning_rate": 1.681817210567241e-05,
      "loss": 0.3813,
      "step": 9840
    },
    {
      "epoch": 4.62,
      "grad_norm": 1.113123893737793,
      "learning_rate": 1.6796240262701373e-05,
      "loss": 0.3813,
      "step": 9850
    },
    {
      "epoch": 4.62,
      "grad_norm": 1.0799469947814941,
      "learning_rate": 1.677430452316123e-05,
      "loss": 0.3924,
      "step": 9860
    },
    {
      "epoch": 4.63,
      "grad_norm": 1.4070079326629639,
      "learning_rate": 1.6752364934637e-05,
      "loss": 0.3973,
      "step": 9870
    },
    {
      "epoch": 4.63,
      "grad_norm": 1.1471209526062012,
      "learning_rate": 1.673042154472205e-05,
      "loss": 0.3562,
      "step": 9880
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.218626022338867,
      "learning_rate": 1.670847440101799e-05,
      "loss": 0.3785,
      "step": 9890
    },
    {
      "epoch": 4.64,
      "grad_norm": 1.3066949844360352,
      "learning_rate": 1.6686523551134584e-05,
      "loss": 0.3501,
      "step": 9900
    },
    {
      "epoch": 4.65,
      "grad_norm": 1.742174506187439,
      "learning_rate": 1.6664569042689622e-05,
      "loss": 0.4183,
      "step": 9910
    },
    {
      "epoch": 4.65,
      "grad_norm": 1.3839703798294067,
      "learning_rate": 1.6642610923308843e-05,
      "loss": 0.4058,
      "step": 9920
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.1873595714569092,
      "learning_rate": 1.662064924062581e-05,
      "loss": 0.3648,
      "step": 9930
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.4414255619049072,
      "learning_rate": 1.6598684042281815e-05,
      "loss": 0.3504,
      "step": 9940
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.9563758969306946,
      "learning_rate": 1.657671537592579e-05,
      "loss": 0.3838,
      "step": 9950
    },
    {
      "epoch": 4.67,
      "grad_norm": 1.323286533355713,
      "learning_rate": 1.6554743289214172e-05,
      "loss": 0.3795,
      "step": 9960
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.7372878193855286,
      "learning_rate": 1.6532767829810838e-05,
      "loss": 0.4172,
      "step": 9970
    },
    {
      "epoch": 4.68,
      "grad_norm": 1.6358965635299683,
      "learning_rate": 1.6510789045386957e-05,
      "loss": 0.4276,
      "step": 9980
    },
    {
      "epoch": 4.68,
      "grad_norm": 1.3385536670684814,
      "learning_rate": 1.6488806983620927e-05,
      "loss": 0.409,
      "step": 9990
    },
    {
      "epoch": 4.69,
      "grad_norm": 0.9352612495422363,
      "learning_rate": 1.6466821692198252e-05,
      "loss": 0.3266,
      "step": 10000
    },
    {
      "epoch": 4.69,
      "grad_norm": 1.4733771085739136,
      "learning_rate": 1.6444833218811452e-05,
      "loss": 0.3483,
      "step": 10010
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.2579855918884277,
      "learning_rate": 1.6422841611159927e-05,
      "loss": 0.3522,
      "step": 10020
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.4760788679122925,
      "learning_rate": 1.6400846916949896e-05,
      "loss": 0.4122,
      "step": 10030
    },
    {
      "epoch": 4.71,
      "grad_norm": 1.621995449066162,
      "learning_rate": 1.637884918389427e-05,
      "loss": 0.3383,
      "step": 10040
    },
    {
      "epoch": 4.71,
      "grad_norm": 1.534529209136963,
      "learning_rate": 1.6356848459712536e-05,
      "loss": 0.3671,
      "step": 10050
    },
    {
      "epoch": 4.72,
      "grad_norm": 1.183638572692871,
      "learning_rate": 1.6334844792130693e-05,
      "loss": 0.3595,
      "step": 10060
    },
    {
      "epoch": 4.72,
      "grad_norm": 1.4494688510894775,
      "learning_rate": 1.6312838228881118e-05,
      "loss": 0.3914,
      "step": 10070
    },
    {
      "epoch": 4.73,
      "grad_norm": 2.1290698051452637,
      "learning_rate": 1.6290828817702456e-05,
      "loss": 0.3735,
      "step": 10080
    },
    {
      "epoch": 4.73,
      "grad_norm": 1.8192734718322754,
      "learning_rate": 1.6268816606339543e-05,
      "loss": 0.3679,
      "step": 10090
    },
    {
      "epoch": 4.74,
      "grad_norm": 1.3718100786209106,
      "learning_rate": 1.624680164254329e-05,
      "loss": 0.3893,
      "step": 10100
    },
    {
      "epoch": 4.74,
      "grad_norm": 1.8810944557189941,
      "learning_rate": 1.6224783974070574e-05,
      "loss": 0.3558,
      "step": 10110
    },
    {
      "epoch": 4.74,
      "grad_norm": 1.7633405923843384,
      "learning_rate": 1.6202763648684142e-05,
      "loss": 0.4361,
      "step": 10120
    },
    {
      "epoch": 4.75,
      "grad_norm": 1.544899821281433,
      "learning_rate": 1.61807407141525e-05,
      "loss": 0.3846,
      "step": 10130
    },
    {
      "epoch": 4.75,
      "grad_norm": 1.0885814428329468,
      "learning_rate": 1.615871521824982e-05,
      "loss": 0.364,
      "step": 10140
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.6203889846801758,
      "learning_rate": 1.613668720875582e-05,
      "loss": 0.3564,
      "step": 10150
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.8734980821609497,
      "learning_rate": 1.6114656733455695e-05,
      "loss": 0.3954,
      "step": 10160
    },
    {
      "epoch": 4.77,
      "grad_norm": 1.0498231649398804,
      "learning_rate": 1.6092623840139954e-05,
      "loss": 0.3983,
      "step": 10170
    },
    {
      "epoch": 4.77,
      "grad_norm": 1.2425227165222168,
      "learning_rate": 1.607058857660438e-05,
      "loss": 0.3888,
      "step": 10180
    },
    {
      "epoch": 4.78,
      "grad_norm": 1.9922237396240234,
      "learning_rate": 1.6048550990649885e-05,
      "loss": 0.3481,
      "step": 10190
    },
    {
      "epoch": 4.78,
      "grad_norm": 1.2329541444778442,
      "learning_rate": 1.6026511130082424e-05,
      "loss": 0.4036,
      "step": 10200
    },
    {
      "epoch": 4.79,
      "grad_norm": 1.3108521699905396,
      "learning_rate": 1.6004469042712877e-05,
      "loss": 0.363,
      "step": 10210
    },
    {
      "epoch": 4.79,
      "grad_norm": 1.111620306968689,
      "learning_rate": 1.5982424776356972e-05,
      "loss": 0.3773,
      "step": 10220
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.895275592803955,
      "learning_rate": 1.596037837883514e-05,
      "loss": 0.3611,
      "step": 10230
    },
    {
      "epoch": 4.8,
      "grad_norm": 2.423947334289551,
      "learning_rate": 1.5938329897972457e-05,
      "loss": 0.4068,
      "step": 10240
    },
    {
      "epoch": 4.81,
      "grad_norm": 1.0604225397109985,
      "learning_rate": 1.591627938159851e-05,
      "loss": 0.3748,
      "step": 10250
    },
    {
      "epoch": 4.81,
      "grad_norm": 1.342798113822937,
      "learning_rate": 1.5894226877547298e-05,
      "loss": 0.3781,
      "step": 10260
    },
    {
      "epoch": 4.81,
      "grad_norm": 1.3220611810684204,
      "learning_rate": 1.587217243365714e-05,
      "loss": 0.3925,
      "step": 10270
    },
    {
      "epoch": 4.82,
      "grad_norm": 1.8071902990341187,
      "learning_rate": 1.585011609777055e-05,
      "loss": 0.3499,
      "step": 10280
    },
    {
      "epoch": 4.82,
      "grad_norm": 1.225887656211853,
      "learning_rate": 1.582805791773416e-05,
      "loss": 0.3811,
      "step": 10290
    },
    {
      "epoch": 4.83,
      "grad_norm": 2.3881142139434814,
      "learning_rate": 1.58059979413986e-05,
      "loss": 0.3949,
      "step": 10300
    },
    {
      "epoch": 4.83,
      "grad_norm": 1.359307885169983,
      "learning_rate": 1.5783936216618388e-05,
      "loss": 0.3555,
      "step": 10310
    },
    {
      "epoch": 4.84,
      "grad_norm": 1.9637843370437622,
      "learning_rate": 1.576187279125184e-05,
      "loss": 0.3643,
      "step": 10320
    },
    {
      "epoch": 4.84,
      "grad_norm": 1.0214918851852417,
      "learning_rate": 1.5739807713160966e-05,
      "loss": 0.4245,
      "step": 10330
    },
    {
      "epoch": 4.85,
      "grad_norm": 2.4864468574523926,
      "learning_rate": 1.5717741030211354e-05,
      "loss": 0.3414,
      "step": 10340
    },
    {
      "epoch": 4.85,
      "grad_norm": 1.6416748762130737,
      "learning_rate": 1.5695672790272076e-05,
      "loss": 0.4166,
      "step": 10350
    },
    {
      "epoch": 4.86,
      "grad_norm": 1.279152750968933,
      "learning_rate": 1.5673603041215586e-05,
      "loss": 0.405,
      "step": 10360
    },
    {
      "epoch": 4.86,
      "grad_norm": 2.0334277153015137,
      "learning_rate": 1.5651531830917606e-05,
      "loss": 0.3596,
      "step": 10370
    },
    {
      "epoch": 4.87,
      "grad_norm": 1.4525741338729858,
      "learning_rate": 1.5629459207257024e-05,
      "loss": 0.3717,
      "step": 10380
    },
    {
      "epoch": 4.87,
      "grad_norm": 1.0955928564071655,
      "learning_rate": 1.560738521811581e-05,
      "loss": 0.3666,
      "step": 10390
    },
    {
      "epoch": 4.88,
      "grad_norm": 2.0679807662963867,
      "learning_rate": 1.558530991137887e-05,
      "loss": 0.3585,
      "step": 10400
    },
    {
      "epoch": 4.88,
      "grad_norm": 1.4747350215911865,
      "learning_rate": 1.5563233334934002e-05,
      "loss": 0.4099,
      "step": 10410
    },
    {
      "epoch": 4.89,
      "grad_norm": 1.5860391855239868,
      "learning_rate": 1.554115553667173e-05,
      "loss": 0.3714,
      "step": 10420
    },
    {
      "epoch": 4.89,
      "grad_norm": 1.134071707725525,
      "learning_rate": 1.551907656448524e-05,
      "loss": 0.367,
      "step": 10430
    },
    {
      "epoch": 4.89,
      "grad_norm": 1.2566536664962769,
      "learning_rate": 1.5496996466270265e-05,
      "loss": 0.3983,
      "step": 10440
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.9986615180969238,
      "learning_rate": 1.5474915289924972e-05,
      "loss": 0.3594,
      "step": 10450
    },
    {
      "epoch": 4.9,
      "grad_norm": 1.2073898315429688,
      "learning_rate": 1.545283308334988e-05,
      "loss": 0.3733,
      "step": 10460
    },
    {
      "epoch": 4.91,
      "grad_norm": 1.6990623474121094,
      "learning_rate": 1.5430749894447736e-05,
      "loss": 0.4064,
      "step": 10470
    },
    {
      "epoch": 4.91,
      "grad_norm": 1.4797078371047974,
      "learning_rate": 1.5408665771123425e-05,
      "loss": 0.3894,
      "step": 10480
    },
    {
      "epoch": 4.92,
      "grad_norm": 1.30536687374115,
      "learning_rate": 1.5386580761283836e-05,
      "loss": 0.3729,
      "step": 10490
    },
    {
      "epoch": 4.92,
      "grad_norm": 1.0410386323928833,
      "learning_rate": 1.536449491283781e-05,
      "loss": 0.3874,
      "step": 10500
    },
    {
      "epoch": 4.93,
      "grad_norm": 1.2065836191177368,
      "learning_rate": 1.5342408273695996e-05,
      "loss": 0.3448,
      "step": 10510
    },
    {
      "epoch": 4.93,
      "grad_norm": 1.6215640306472778,
      "learning_rate": 1.5320320891770755e-05,
      "loss": 0.3939,
      "step": 10520
    },
    {
      "epoch": 4.94,
      "grad_norm": 1.2884684801101685,
      "learning_rate": 1.5298232814976053e-05,
      "loss": 0.3843,
      "step": 10530
    },
    {
      "epoch": 4.94,
      "grad_norm": 1.2688748836517334,
      "learning_rate": 1.5276144091227384e-05,
      "loss": 0.4544,
      "step": 10540
    },
    {
      "epoch": 4.95,
      "grad_norm": 1.3649983406066895,
      "learning_rate": 1.5254054768441625e-05,
      "loss": 0.3631,
      "step": 10550
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.9851985573768616,
      "learning_rate": 1.5231964894536965e-05,
      "loss": 0.4036,
      "step": 10560
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.2515342235565186,
      "learning_rate": 1.5209874517432783e-05,
      "loss": 0.3665,
      "step": 10570
    },
    {
      "epoch": 4.96,
      "grad_norm": 2.332304000854492,
      "learning_rate": 1.518778368504955e-05,
      "loss": 0.3612,
      "step": 10580
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.6469167470932007,
      "learning_rate": 1.5165692445308728e-05,
      "loss": 0.3544,
      "step": 10590
    },
    {
      "epoch": 4.97,
      "grad_norm": 2.2876811027526855,
      "learning_rate": 1.514360084613266e-05,
      "loss": 0.3938,
      "step": 10600
    },
    {
      "epoch": 4.97,
      "grad_norm": 1.8361326456069946,
      "learning_rate": 1.5121508935444465e-05,
      "loss": 0.3588,
      "step": 10610
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.2661975622177124,
      "learning_rate": 1.5099416761167939e-05,
      "loss": 0.3829,
      "step": 10620
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.6083097457885742,
      "learning_rate": 1.5077324371227467e-05,
      "loss": 0.3778,
      "step": 10630
    },
    {
      "epoch": 4.99,
      "grad_norm": 1.6265578269958496,
      "learning_rate": 1.5055231813547869e-05,
      "loss": 0.3562,
      "step": 10640
    },
    {
      "epoch": 4.99,
      "grad_norm": 1.4666067361831665,
      "learning_rate": 1.503313913605436e-05,
      "loss": 0.3768,
      "step": 10650
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.7126891613006592,
      "learning_rate": 1.5011046386672399e-05,
      "loss": 0.3574,
      "step": 10660
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.0814265012741089,
      "learning_rate": 1.4988953613327604e-05,
      "loss": 0.412,
      "step": 10670
    },
    {
      "epoch": 5.01,
      "grad_norm": 1.5876706838607788,
      "learning_rate": 1.4966860863945638e-05,
      "loss": 0.3409,
      "step": 10680
    },
    {
      "epoch": 5.01,
      "grad_norm": 1.7222776412963867,
      "learning_rate": 1.4944768186452128e-05,
      "loss": 0.3262,
      "step": 10690
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.6721644401550293,
      "learning_rate": 1.4922675628772538e-05,
      "loss": 0.3798,
      "step": 10700
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.9102154970169067,
      "learning_rate": 1.4900583238832064e-05,
      "loss": 0.3307,
      "step": 10710
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.132504940032959,
      "learning_rate": 1.4878491064555539e-05,
      "loss": 0.3569,
      "step": 10720
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.9992465972900391,
      "learning_rate": 1.4856399153867344e-05,
      "loss": 0.35,
      "step": 10730
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.7281465530395508,
      "learning_rate": 1.4834307554691274e-05,
      "loss": 0.3573,
      "step": 10740
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.3104376792907715,
      "learning_rate": 1.4812216314950449e-05,
      "loss": 0.3399,
      "step": 10750
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.3606339693069458,
      "learning_rate": 1.479012548256722e-05,
      "loss": 0.3683,
      "step": 10760
    },
    {
      "epoch": 5.05,
      "grad_norm": 1.6568652391433716,
      "learning_rate": 1.476803510546304e-05,
      "loss": 0.3528,
      "step": 10770
    },
    {
      "epoch": 5.05,
      "grad_norm": 1.4966590404510498,
      "learning_rate": 1.4745945231558378e-05,
      "loss": 0.3744,
      "step": 10780
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.5069708824157715,
      "learning_rate": 1.4723855908772618e-05,
      "loss": 0.3239,
      "step": 10790
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.273727536201477,
      "learning_rate": 1.4701767185023948e-05,
      "loss": 0.3751,
      "step": 10800
    },
    {
      "epoch": 5.07,
      "grad_norm": 1.681527018547058,
      "learning_rate": 1.4679679108229247e-05,
      "loss": 0.4009,
      "step": 10810
    },
    {
      "epoch": 5.07,
      "grad_norm": 2.0464868545532227,
      "learning_rate": 1.4657591726304009e-05,
      "loss": 0.3138,
      "step": 10820
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.2004908323287964,
      "learning_rate": 1.463550508716219e-05,
      "loss": 0.3288,
      "step": 10830
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.4913909435272217,
      "learning_rate": 1.4613419238716167e-05,
      "loss": 0.3774,
      "step": 10840
    },
    {
      "epoch": 5.09,
      "grad_norm": 2.335245370864868,
      "learning_rate": 1.459133422887658e-05,
      "loss": 0.3557,
      "step": 10850
    },
    {
      "epoch": 5.09,
      "grad_norm": 1.5727862119674683,
      "learning_rate": 1.4569250105552263e-05,
      "loss": 0.3181,
      "step": 10860
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.7864466905593872,
      "learning_rate": 1.454716691665012e-05,
      "loss": 0.3427,
      "step": 10870
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.7722055912017822,
      "learning_rate": 1.4525084710075033e-05,
      "loss": 0.3736,
      "step": 10880
    },
    {
      "epoch": 5.11,
      "grad_norm": 1.2625855207443237,
      "learning_rate": 1.450300353372974e-05,
      "loss": 0.329,
      "step": 10890
    },
    {
      "epoch": 5.11,
      "grad_norm": 1.7300564050674438,
      "learning_rate": 1.4480923435514763e-05,
      "loss": 0.3199,
      "step": 10900
    },
    {
      "epoch": 5.11,
      "grad_norm": 2.108747959136963,
      "learning_rate": 1.4458844463328272e-05,
      "loss": 0.3655,
      "step": 10910
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.8381175994873047,
      "learning_rate": 1.4436766665065997e-05,
      "loss": 0.3616,
      "step": 10920
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.7932960987091064,
      "learning_rate": 1.4414690088621129e-05,
      "loss": 0.3713,
      "step": 10930
    },
    {
      "epoch": 5.13,
      "grad_norm": 1.615193247795105,
      "learning_rate": 1.4392614781884194e-05,
      "loss": 0.3264,
      "step": 10940
    },
    {
      "epoch": 5.13,
      "grad_norm": 1.6604840755462646,
      "learning_rate": 1.4370540792742979e-05,
      "loss": 0.3249,
      "step": 10950
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.1271770000457764,
      "learning_rate": 1.4348468169082397e-05,
      "loss": 0.3469,
      "step": 10960
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.8872523307800293,
      "learning_rate": 1.4326396958784414e-05,
      "loss": 0.3783,
      "step": 10970
    },
    {
      "epoch": 5.15,
      "grad_norm": 1.9692620038986206,
      "learning_rate": 1.4304327209727921e-05,
      "loss": 0.382,
      "step": 10980
    },
    {
      "epoch": 5.15,
      "grad_norm": 1.5689891576766968,
      "learning_rate": 1.4282258969788652e-05,
      "loss": 0.3663,
      "step": 10990
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.69688880443573,
      "learning_rate": 1.4260192286839038e-05,
      "loss": 0.3492,
      "step": 11000
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.3866389989852905,
      "learning_rate": 1.4238127208748165e-05,
      "loss": 0.3521,
      "step": 11010
    },
    {
      "epoch": 5.17,
      "grad_norm": 1.2644603252410889,
      "learning_rate": 1.4216063783381614e-05,
      "loss": 0.3427,
      "step": 11020
    },
    {
      "epoch": 5.17,
      "grad_norm": 1.3300840854644775,
      "learning_rate": 1.4194002058601404e-05,
      "loss": 0.3276,
      "step": 11030
    },
    {
      "epoch": 5.18,
      "grad_norm": 1.0498220920562744,
      "learning_rate": 1.417194208226584e-05,
      "loss": 0.3293,
      "step": 11040
    },
    {
      "epoch": 5.18,
      "grad_norm": 1.6168214082717896,
      "learning_rate": 1.4149883902229455e-05,
      "loss": 0.3768,
      "step": 11050
    },
    {
      "epoch": 5.19,
      "grad_norm": 1.3768948316574097,
      "learning_rate": 1.4127827566342864e-05,
      "loss": 0.3514,
      "step": 11060
    },
    {
      "epoch": 5.19,
      "grad_norm": 1.645207405090332,
      "learning_rate": 1.4105773122452703e-05,
      "loss": 0.3684,
      "step": 11070
    },
    {
      "epoch": 5.19,
      "grad_norm": 1.497140645980835,
      "learning_rate": 1.4083720618401492e-05,
      "loss": 0.3373,
      "step": 11080
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.994994878768921,
      "learning_rate": 1.4061670102027542e-05,
      "loss": 0.3445,
      "step": 11090
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.323543667793274,
      "learning_rate": 1.403962162116486e-05,
      "loss": 0.3518,
      "step": 11100
    },
    {
      "epoch": 5.21,
      "grad_norm": 2.7144510746002197,
      "learning_rate": 1.4017575223643037e-05,
      "loss": 0.3494,
      "step": 11110
    },
    {
      "epoch": 5.21,
      "grad_norm": 1.247528076171875,
      "learning_rate": 1.3995530957287129e-05,
      "loss": 0.378,
      "step": 11120
    },
    {
      "epoch": 5.22,
      "grad_norm": 1.2161149978637695,
      "learning_rate": 1.397348886991758e-05,
      "loss": 0.3437,
      "step": 11130
    },
    {
      "epoch": 5.22,
      "grad_norm": 1.8314012289047241,
      "learning_rate": 1.3951449009350116e-05,
      "loss": 0.3634,
      "step": 11140
    },
    {
      "epoch": 5.23,
      "grad_norm": 1.2980343103408813,
      "learning_rate": 1.392941142339562e-05,
      "loss": 0.3616,
      "step": 11150
    },
    {
      "epoch": 5.23,
      "grad_norm": 2.0276939868927,
      "learning_rate": 1.3907376159860046e-05,
      "loss": 0.3669,
      "step": 11160
    },
    {
      "epoch": 5.24,
      "grad_norm": 1.7491308450698853,
      "learning_rate": 1.3885343266544313e-05,
      "loss": 0.3826,
      "step": 11170
    },
    {
      "epoch": 5.24,
      "grad_norm": 1.3640378713607788,
      "learning_rate": 1.3863312791244182e-05,
      "loss": 0.3562,
      "step": 11180
    },
    {
      "epoch": 5.25,
      "grad_norm": 1.8530540466308594,
      "learning_rate": 1.3841284781750184e-05,
      "loss": 0.3255,
      "step": 11190
    },
    {
      "epoch": 5.25,
      "grad_norm": 1.9384208917617798,
      "learning_rate": 1.3819259285847503e-05,
      "loss": 0.3068,
      "step": 11200
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.688899040222168,
      "learning_rate": 1.3797236351315862e-05,
      "loss": 0.3282,
      "step": 11210
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.842028260231018,
      "learning_rate": 1.3775216025929424e-05,
      "loss": 0.366,
      "step": 11220
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.3604649305343628,
      "learning_rate": 1.3753198357456713e-05,
      "loss": 0.3304,
      "step": 11230
    },
    {
      "epoch": 5.27,
      "grad_norm": 1.8417778015136719,
      "learning_rate": 1.373118339366046e-05,
      "loss": 0.3451,
      "step": 11240
    },
    {
      "epoch": 5.27,
      "grad_norm": 1.4065113067626953,
      "learning_rate": 1.370917118229755e-05,
      "loss": 0.3818,
      "step": 11250
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.2982780933380127,
      "learning_rate": 1.3687161771118887e-05,
      "loss": 0.3717,
      "step": 11260
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.3959838151931763,
      "learning_rate": 1.3665155207869308e-05,
      "loss": 0.3875,
      "step": 11270
    },
    {
      "epoch": 5.29,
      "grad_norm": 1.9261902570724487,
      "learning_rate": 1.3643151540287461e-05,
      "loss": 0.3315,
      "step": 11280
    },
    {
      "epoch": 5.29,
      "grad_norm": 1.546658992767334,
      "learning_rate": 1.3621150816105739e-05,
      "loss": 0.3696,
      "step": 11290
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.620543360710144,
      "learning_rate": 1.3599153083050107e-05,
      "loss": 0.3548,
      "step": 11300
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.2416638135910034,
      "learning_rate": 1.3577158388840076e-05,
      "loss": 0.347,
      "step": 11310
    },
    {
      "epoch": 5.31,
      "grad_norm": 1.229349970817566,
      "learning_rate": 1.3555166781188549e-05,
      "loss": 0.3753,
      "step": 11320
    },
    {
      "epoch": 5.31,
      "grad_norm": 1.0592079162597656,
      "learning_rate": 1.3533178307801745e-05,
      "loss": 0.3497,
      "step": 11330
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.3179768323898315,
      "learning_rate": 1.3511193016379079e-05,
      "loss": 0.3429,
      "step": 11340
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.6756287813186646,
      "learning_rate": 1.3489210954613052e-05,
      "loss": 0.3598,
      "step": 11350
    },
    {
      "epoch": 5.33,
      "grad_norm": 1.319293737411499,
      "learning_rate": 1.3467232170189166e-05,
      "loss": 0.3521,
      "step": 11360
    },
    {
      "epoch": 5.33,
      "grad_norm": 0.9876905679702759,
      "learning_rate": 1.3445256710785827e-05,
      "loss": 0.3778,
      "step": 11370
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.5062085390090942,
      "learning_rate": 1.3423284624074211e-05,
      "loss": 0.3567,
      "step": 11380
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.2553244829177856,
      "learning_rate": 1.3401315957718182e-05,
      "loss": 0.4203,
      "step": 11390
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.461759328842163,
      "learning_rate": 1.3379350759374195e-05,
      "loss": 0.3435,
      "step": 11400
    },
    {
      "epoch": 5.35,
      "grad_norm": 1.1895637512207031,
      "learning_rate": 1.3357389076691161e-05,
      "loss": 0.3888,
      "step": 11410
    },
    {
      "epoch": 5.35,
      "grad_norm": 1.2905254364013672,
      "learning_rate": 1.3335430957310382e-05,
      "loss": 0.3556,
      "step": 11420
    },
    {
      "epoch": 5.36,
      "grad_norm": 2.5757155418395996,
      "learning_rate": 1.3313476448865418e-05,
      "loss": 0.369,
      "step": 11430
    },
    {
      "epoch": 5.36,
      "grad_norm": 1.778450846672058,
      "learning_rate": 1.3291525598982011e-05,
      "loss": 0.4313,
      "step": 11440
    },
    {
      "epoch": 5.37,
      "grad_norm": 1.553194284439087,
      "learning_rate": 1.3269578455277953e-05,
      "loss": 0.3564,
      "step": 11450
    },
    {
      "epoch": 5.37,
      "grad_norm": 2.3317711353302,
      "learning_rate": 1.3247635065363007e-05,
      "loss": 0.3744,
      "step": 11460
    },
    {
      "epoch": 5.38,
      "grad_norm": 2.2074947357177734,
      "learning_rate": 1.3225695476838774e-05,
      "loss": 0.3833,
      "step": 11470
    },
    {
      "epoch": 5.38,
      "grad_norm": 1.2038980722427368,
      "learning_rate": 1.3203759737298631e-05,
      "loss": 0.3612,
      "step": 11480
    },
    {
      "epoch": 5.39,
      "grad_norm": 1.9950642585754395,
      "learning_rate": 1.3181827894327595e-05,
      "loss": 0.3448,
      "step": 11490
    },
    {
      "epoch": 5.39,
      "grad_norm": 2.0370194911956787,
      "learning_rate": 1.3159899995502224e-05,
      "loss": 0.3339,
      "step": 11500
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.7439682483673096,
      "learning_rate": 1.3137976088390537e-05,
      "loss": 0.3442,
      "step": 11510
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.660637378692627,
      "learning_rate": 1.3116056220551881e-05,
      "loss": 0.3713,
      "step": 11520
    },
    {
      "epoch": 5.41,
      "grad_norm": 2.587240695953369,
      "learning_rate": 1.3094140439536843e-05,
      "loss": 0.3025,
      "step": 11530
    },
    {
      "epoch": 5.41,
      "grad_norm": 1.2337242364883423,
      "learning_rate": 1.3072228792887138e-05,
      "loss": 0.3281,
      "step": 11540
    },
    {
      "epoch": 5.41,
      "grad_norm": 1.353310465812683,
      "learning_rate": 1.305032132813553e-05,
      "loss": 0.3567,
      "step": 11550
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.6960409879684448,
      "learning_rate": 1.3028418092805693e-05,
      "loss": 0.3547,
      "step": 11560
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.6072362661361694,
      "learning_rate": 1.3006519134412138e-05,
      "loss": 0.3419,
      "step": 11570
    },
    {
      "epoch": 5.43,
      "grad_norm": 1.397662878036499,
      "learning_rate": 1.29846245004601e-05,
      "loss": 0.3494,
      "step": 11580
    },
    {
      "epoch": 5.43,
      "grad_norm": 1.6263619661331177,
      "learning_rate": 1.2962734238445411e-05,
      "loss": 0.3453,
      "step": 11590
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.3391238451004028,
      "learning_rate": 1.2940848395854444e-05,
      "loss": 0.3591,
      "step": 11600
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.894499659538269,
      "learning_rate": 1.2918967020163978e-05,
      "loss": 0.3681,
      "step": 11610
    },
    {
      "epoch": 5.45,
      "grad_norm": 1.3817747831344604,
      "learning_rate": 1.2897090158841095e-05,
      "loss": 0.3537,
      "step": 11620
    },
    {
      "epoch": 5.45,
      "grad_norm": 1.1003586053848267,
      "learning_rate": 1.287521785934309e-05,
      "loss": 0.3877,
      "step": 11630
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.2889580726623535,
      "learning_rate": 1.2853350169117368e-05,
      "loss": 0.376,
      "step": 11640
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.9022055864334106,
      "learning_rate": 1.2831487135601317e-05,
      "loss": 0.3422,
      "step": 11650
    },
    {
      "epoch": 5.47,
      "grad_norm": 1.5423356294631958,
      "learning_rate": 1.280962880622224e-05,
      "loss": 0.3943,
      "step": 11660
    },
    {
      "epoch": 5.47,
      "grad_norm": 1.7635012865066528,
      "learning_rate": 1.2787775228397226e-05,
      "loss": 0.319,
      "step": 11670
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.199873447418213,
      "learning_rate": 1.2765926449533066e-05,
      "loss": 0.3596,
      "step": 11680
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.6130023002624512,
      "learning_rate": 1.2744082517026127e-05,
      "loss": 0.2998,
      "step": 11690
    },
    {
      "epoch": 5.49,
      "grad_norm": 1.5348105430603027,
      "learning_rate": 1.2722243478262287e-05,
      "loss": 0.407,
      "step": 11700
    },
    {
      "epoch": 5.49,
      "grad_norm": 1.8830032348632812,
      "learning_rate": 1.2700409380616771e-05,
      "loss": 0.3612,
      "step": 11710
    },
    {
      "epoch": 5.49,
      "grad_norm": 1.3788855075836182,
      "learning_rate": 1.2678580271454117e-05,
      "loss": 0.3462,
      "step": 11720
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.3762668371200562,
      "learning_rate": 1.2656756198128027e-05,
      "loss": 0.4098,
      "step": 11730
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.6677985191345215,
      "learning_rate": 1.2634937207981284e-05,
      "loss": 0.3274,
      "step": 11740
    },
    {
      "epoch": 5.51,
      "grad_norm": 0.8985734581947327,
      "learning_rate": 1.2613123348345648e-05,
      "loss": 0.3693,
      "step": 11750
    },
    {
      "epoch": 5.51,
      "grad_norm": 1.3337101936340332,
      "learning_rate": 1.2591314666541731e-05,
      "loss": 0.3695,
      "step": 11760
    },
    {
      "epoch": 5.52,
      "grad_norm": 2.061391592025757,
      "learning_rate": 1.2569511209878934e-05,
      "loss": 0.362,
      "step": 11770
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.6414411067962646,
      "learning_rate": 1.2547713025655312e-05,
      "loss": 0.354,
      "step": 11780
    },
    {
      "epoch": 5.53,
      "grad_norm": 1.3193484544754028,
      "learning_rate": 1.2525920161157491e-05,
      "loss": 0.3308,
      "step": 11790
    },
    {
      "epoch": 5.53,
      "grad_norm": 1.4781758785247803,
      "learning_rate": 1.2504132663660542e-05,
      "loss": 0.3418,
      "step": 11800
    },
    {
      "epoch": 5.54,
      "grad_norm": 1.643297791481018,
      "learning_rate": 1.2482350580427912e-05,
      "loss": 0.3495,
      "step": 11810
    },
    {
      "epoch": 5.54,
      "grad_norm": 1.3966330289840698,
      "learning_rate": 1.2460573958711287e-05,
      "loss": 0.3721,
      "step": 11820
    },
    {
      "epoch": 5.55,
      "grad_norm": 1.3119921684265137,
      "learning_rate": 1.2438802845750513e-05,
      "loss": 0.3633,
      "step": 11830
    },
    {
      "epoch": 5.55,
      "grad_norm": 1.3332055807113647,
      "learning_rate": 1.2417037288773484e-05,
      "loss": 0.3533,
      "step": 11840
    },
    {
      "epoch": 5.56,
      "grad_norm": 1.3975166082382202,
      "learning_rate": 1.2395277334996045e-05,
      "loss": 0.3315,
      "step": 11850
    },
    {
      "epoch": 5.56,
      "grad_norm": 2.054786443710327,
      "learning_rate": 1.2373523031621882e-05,
      "loss": 0.3408,
      "step": 11860
    },
    {
      "epoch": 5.56,
      "grad_norm": 1.4366356134414673,
      "learning_rate": 1.2351774425842431e-05,
      "loss": 0.3511,
      "step": 11870
    },
    {
      "epoch": 5.57,
      "grad_norm": 1.566415786743164,
      "learning_rate": 1.2330031564836749e-05,
      "loss": 0.3592,
      "step": 11880
    },
    {
      "epoch": 5.57,
      "grad_norm": 1.991323709487915,
      "learning_rate": 1.2308294495771453e-05,
      "loss": 0.3495,
      "step": 11890
    },
    {
      "epoch": 5.58,
      "grad_norm": 1.7218416929244995,
      "learning_rate": 1.2286563265800583e-05,
      "loss": 0.332,
      "step": 11900
    },
    {
      "epoch": 5.58,
      "grad_norm": 1.8606390953063965,
      "learning_rate": 1.226483792206552e-05,
      "loss": 0.341,
      "step": 11910
    },
    {
      "epoch": 5.59,
      "grad_norm": 1.2512938976287842,
      "learning_rate": 1.224311851169487e-05,
      "loss": 0.3717,
      "step": 11920
    },
    {
      "epoch": 5.59,
      "grad_norm": 1.4289716482162476,
      "learning_rate": 1.2221405081804374e-05,
      "loss": 0.3656,
      "step": 11930
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.1645054817199707,
      "learning_rate": 1.2199697679496782e-05,
      "loss": 0.3776,
      "step": 11940
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.8863285779953003,
      "learning_rate": 1.2177996351861796e-05,
      "loss": 0.3353,
      "step": 11950
    },
    {
      "epoch": 5.61,
      "grad_norm": 1.8842116594314575,
      "learning_rate": 1.215630114597592e-05,
      "loss": 0.3692,
      "step": 11960
    },
    {
      "epoch": 5.61,
      "grad_norm": 1.9293420314788818,
      "learning_rate": 1.2134612108902382e-05,
      "loss": 0.3796,
      "step": 11970
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.0521411895751953,
      "learning_rate": 1.2112929287691037e-05,
      "loss": 0.3102,
      "step": 11980
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.3480546474456787,
      "learning_rate": 1.2091252729378249e-05,
      "loss": 0.3301,
      "step": 11990
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.8363972902297974,
      "learning_rate": 1.2069582480986791e-05,
      "loss": 0.3343,
      "step": 12000
    },
    {
      "epoch": 5.63,
      "grad_norm": 1.8527833223342896,
      "learning_rate": 1.2047918589525749e-05,
      "loss": 0.3457,
      "step": 12010
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.9073087573051453,
      "learning_rate": 1.2026261101990433e-05,
      "loss": 0.3977,
      "step": 12020
    },
    {
      "epoch": 5.64,
      "grad_norm": 1.6155396699905396,
      "learning_rate": 1.2004610065362245e-05,
      "loss": 0.334,
      "step": 12030
    },
    {
      "epoch": 5.64,
      "grad_norm": 2.0423736572265625,
      "learning_rate": 1.1982965526608602e-05,
      "loss": 0.3502,
      "step": 12040
    },
    {
      "epoch": 5.65,
      "grad_norm": 1.4631519317626953,
      "learning_rate": 1.1961327532682828e-05,
      "loss": 0.415,
      "step": 12050
    },
    {
      "epoch": 5.65,
      "grad_norm": 1.431785225868225,
      "learning_rate": 1.1939696130524033e-05,
      "loss": 0.3438,
      "step": 12060
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.6506390571594238,
      "learning_rate": 1.191807136705704e-05,
      "loss": 0.3551,
      "step": 12070
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.2478646039962769,
      "learning_rate": 1.1896453289192275e-05,
      "loss": 0.3645,
      "step": 12080
    },
    {
      "epoch": 5.67,
      "grad_norm": 1.331677794456482,
      "learning_rate": 1.187484194382565e-05,
      "loss": 0.3272,
      "step": 12090
    },
    {
      "epoch": 5.67,
      "grad_norm": 1.4978355169296265,
      "learning_rate": 1.1853237377838479e-05,
      "loss": 0.3575,
      "step": 12100
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.1957725286483765,
      "learning_rate": 1.1831639638097372e-05,
      "loss": 0.3737,
      "step": 12110
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.5055814981460571,
      "learning_rate": 1.181004877145412e-05,
      "loss": 0.3711,
      "step": 12120
    },
    {
      "epoch": 5.69,
      "grad_norm": 2.354196310043335,
      "learning_rate": 1.1788464824745614e-05,
      "loss": 0.3732,
      "step": 12130
    },
    {
      "epoch": 5.69,
      "grad_norm": 2.3942203521728516,
      "learning_rate": 1.1766887844793728e-05,
      "loss": 0.329,
      "step": 12140
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.339962363243103,
      "learning_rate": 1.1745317878405229e-05,
      "loss": 0.3394,
      "step": 12150
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.1774765253067017,
      "learning_rate": 1.172375497237167e-05,
      "loss": 0.3518,
      "step": 12160
    },
    {
      "epoch": 5.71,
      "grad_norm": 1.3246662616729736,
      "learning_rate": 1.1702199173469276e-05,
      "loss": 0.3539,
      "step": 12170
    },
    {
      "epoch": 5.71,
      "grad_norm": 1.7875056266784668,
      "learning_rate": 1.1680650528458861e-05,
      "loss": 0.3842,
      "step": 12180
    },
    {
      "epoch": 5.71,
      "grad_norm": 1.5148972272872925,
      "learning_rate": 1.1659109084085733e-05,
      "loss": 0.3322,
      "step": 12190
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.9425609111785889,
      "learning_rate": 1.1637574887079558e-05,
      "loss": 0.3687,
      "step": 12200
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.4873706102371216,
      "learning_rate": 1.16160479841543e-05,
      "loss": 0.3602,
      "step": 12210
    },
    {
      "epoch": 5.73,
      "grad_norm": 1.3800303936004639,
      "learning_rate": 1.159452842200809e-05,
      "loss": 0.3625,
      "step": 12220
    },
    {
      "epoch": 5.73,
      "grad_norm": 1.3067013025283813,
      "learning_rate": 1.1573016247323129e-05,
      "loss": 0.3421,
      "step": 12230
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.6295547485351562,
      "learning_rate": 1.1551511506765599e-05,
      "loss": 0.3077,
      "step": 12240
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.5021315813064575,
      "learning_rate": 1.1530014246985561e-05,
      "loss": 0.3334,
      "step": 12250
    },
    {
      "epoch": 5.75,
      "grad_norm": 1.3501535654067993,
      "learning_rate": 1.1508524514616841e-05,
      "loss": 0.39,
      "step": 12260
    },
    {
      "epoch": 5.75,
      "grad_norm": 1.7573031187057495,
      "learning_rate": 1.1487042356276935e-05,
      "loss": 0.3662,
      "step": 12270
    },
    {
      "epoch": 5.76,
      "grad_norm": 1.332872748374939,
      "learning_rate": 1.1465567818566917e-05,
      "loss": 0.3576,
      "step": 12280
    },
    {
      "epoch": 5.76,
      "grad_norm": 1.246690034866333,
      "learning_rate": 1.1444100948071316e-05,
      "loss": 0.3687,
      "step": 12290
    },
    {
      "epoch": 5.77,
      "grad_norm": 1.884072184562683,
      "learning_rate": 1.142264179135804e-05,
      "loss": 0.3767,
      "step": 12300
    },
    {
      "epoch": 5.77,
      "grad_norm": 1.9276474714279175,
      "learning_rate": 1.1401190394978254e-05,
      "loss": 0.3391,
      "step": 12310
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.6291909217834473,
      "learning_rate": 1.1379746805466303e-05,
      "loss": 0.3245,
      "step": 12320
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.3138890266418457,
      "learning_rate": 1.1358311069339582e-05,
      "loss": 0.3695,
      "step": 12330
    },
    {
      "epoch": 5.79,
      "grad_norm": 1.2627809047698975,
      "learning_rate": 1.1336883233098466e-05,
      "loss": 0.332,
      "step": 12340
    },
    {
      "epoch": 5.79,
      "grad_norm": 1.8130717277526855,
      "learning_rate": 1.1315463343226164e-05,
      "loss": 0.332,
      "step": 12350
    },
    {
      "epoch": 5.79,
      "grad_norm": 1.210847020149231,
      "learning_rate": 1.129405144618868e-05,
      "loss": 0.3753,
      "step": 12360
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.3282628059387207,
      "learning_rate": 1.1272647588434655e-05,
      "loss": 0.386,
      "step": 12370
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.3346394300460815,
      "learning_rate": 1.1251251816395311e-05,
      "loss": 0.3534,
      "step": 12380
    },
    {
      "epoch": 5.81,
      "grad_norm": 1.4723515510559082,
      "learning_rate": 1.1229864176484311e-05,
      "loss": 0.3892,
      "step": 12390
    },
    {
      "epoch": 5.81,
      "grad_norm": 1.870959997177124,
      "learning_rate": 1.1208484715097692e-05,
      "loss": 0.3774,
      "step": 12400
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.3040440082550049,
      "learning_rate": 1.118711347861373e-05,
      "loss": 0.3539,
      "step": 12410
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.2208516597747803,
      "learning_rate": 1.116575051339288e-05,
      "loss": 0.3604,
      "step": 12420
    },
    {
      "epoch": 5.83,
      "grad_norm": 2.2959213256835938,
      "learning_rate": 1.1144395865777647e-05,
      "loss": 0.3953,
      "step": 12430
    },
    {
      "epoch": 5.83,
      "grad_norm": 1.1341530084609985,
      "learning_rate": 1.1123049582092482e-05,
      "loss": 0.326,
      "step": 12440
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.2751805782318115,
      "learning_rate": 1.1101711708643712e-05,
      "loss": 0.342,
      "step": 12450
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.9829657077789307,
      "learning_rate": 1.1080382291719405e-05,
      "loss": 0.3577,
      "step": 12460
    },
    {
      "epoch": 5.85,
      "grad_norm": 1.673206090927124,
      "learning_rate": 1.1059061377589286e-05,
      "loss": 0.3896,
      "step": 12470
    },
    {
      "epoch": 5.85,
      "grad_norm": 1.512556791305542,
      "learning_rate": 1.1037749012504634e-05,
      "loss": 0.3323,
      "step": 12480
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.3981462717056274,
      "learning_rate": 1.1016445242698192e-05,
      "loss": 0.4365,
      "step": 12490
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.061031699180603,
      "learning_rate": 1.0995150114384045e-05,
      "loss": 0.3885,
      "step": 12500
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.114223599433899,
      "learning_rate": 1.0973863673757549e-05,
      "loss": 0.3923,
      "step": 12510
    },
    {
      "epoch": 5.87,
      "grad_norm": 1.3529483079910278,
      "learning_rate": 1.09525859669952e-05,
      "loss": 0.3872,
      "step": 12520
    },
    {
      "epoch": 5.87,
      "grad_norm": 1.561216950416565,
      "learning_rate": 1.0931317040254541e-05,
      "loss": 0.3863,
      "step": 12530
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.7181340456008911,
      "learning_rate": 1.0910056939674083e-05,
      "loss": 0.3329,
      "step": 12540
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.3233064413070679,
      "learning_rate": 1.0888805711373189e-05,
      "loss": 0.3551,
      "step": 12550
    },
    {
      "epoch": 5.89,
      "grad_norm": 1.7904798984527588,
      "learning_rate": 1.0867563401451975e-05,
      "loss": 0.3467,
      "step": 12560
    },
    {
      "epoch": 5.89,
      "grad_norm": 2.0727145671844482,
      "learning_rate": 1.0846330055991204e-05,
      "loss": 0.3583,
      "step": 12570
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.9902242422103882,
      "learning_rate": 1.0825105721052191e-05,
      "loss": 0.3482,
      "step": 12580
    },
    {
      "epoch": 5.9,
      "grad_norm": 2.6114275455474854,
      "learning_rate": 1.0803890442676717e-05,
      "loss": 0.3493,
      "step": 12590
    },
    {
      "epoch": 5.91,
      "grad_norm": 1.6409128904342651,
      "learning_rate": 1.0782684266886907e-05,
      "loss": 0.3789,
      "step": 12600
    },
    {
      "epoch": 5.91,
      "grad_norm": 2.488149404525757,
      "learning_rate": 1.0761487239685141e-05,
      "loss": 0.3533,
      "step": 12610
    },
    {
      "epoch": 5.92,
      "grad_norm": 1.6671768426895142,
      "learning_rate": 1.0740299407053958e-05,
      "loss": 0.3861,
      "step": 12620
    },
    {
      "epoch": 5.92,
      "grad_norm": 1.100512146949768,
      "learning_rate": 1.0719120814955949e-05,
      "loss": 0.3544,
      "step": 12630
    },
    {
      "epoch": 5.93,
      "grad_norm": 1.3748526573181152,
      "learning_rate": 1.069795150933365e-05,
      "loss": 0.3897,
      "step": 12640
    },
    {
      "epoch": 5.93,
      "grad_norm": 2.1077046394348145,
      "learning_rate": 1.0676791536109464e-05,
      "loss": 0.3769,
      "step": 12650
    },
    {
      "epoch": 5.94,
      "grad_norm": 1.3028711080551147,
      "learning_rate": 1.0655640941185545e-05,
      "loss": 0.3332,
      "step": 12660
    },
    {
      "epoch": 5.94,
      "grad_norm": 1.9550095796585083,
      "learning_rate": 1.0634499770443705e-05,
      "loss": 0.3788,
      "step": 12670
    },
    {
      "epoch": 5.94,
      "grad_norm": 1.3466970920562744,
      "learning_rate": 1.0613368069745311e-05,
      "loss": 0.3578,
      "step": 12680
    },
    {
      "epoch": 5.95,
      "grad_norm": 1.7544103860855103,
      "learning_rate": 1.0592245884931188e-05,
      "loss": 0.3707,
      "step": 12690
    },
    {
      "epoch": 5.95,
      "grad_norm": 1.5007655620574951,
      "learning_rate": 1.0571133261821512e-05,
      "loss": 0.3374,
      "step": 12700
    },
    {
      "epoch": 5.96,
      "grad_norm": 2.6335949897766113,
      "learning_rate": 1.0550030246215716e-05,
      "loss": 0.3048,
      "step": 12710
    },
    {
      "epoch": 5.96,
      "grad_norm": 1.4035680294036865,
      "learning_rate": 1.052893688389241e-05,
      "loss": 0.371,
      "step": 12720
    },
    {
      "epoch": 5.97,
      "grad_norm": 1.4614942073822021,
      "learning_rate": 1.0507853220609241e-05,
      "loss": 0.3805,
      "step": 12730
    },
    {
      "epoch": 5.97,
      "grad_norm": 1.547668695449829,
      "learning_rate": 1.0486779302102824e-05,
      "loss": 0.3307,
      "step": 12740
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.3080310821533203,
      "learning_rate": 1.0465715174088643e-05,
      "loss": 0.3738,
      "step": 12750
    },
    {
      "epoch": 5.98,
      "grad_norm": 1.4008126258850098,
      "learning_rate": 1.0444660882260931e-05,
      "loss": 0.3636,
      "step": 12760
    },
    {
      "epoch": 5.99,
      "grad_norm": 1.732690453529358,
      "learning_rate": 1.0423616472292588e-05,
      "loss": 0.3675,
      "step": 12770
    },
    {
      "epoch": 5.99,
      "grad_norm": 2.0084102153778076,
      "learning_rate": 1.0402581989835078e-05,
      "loss": 0.3385,
      "step": 12780
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.7503618001937866,
      "learning_rate": 1.0381557480518333e-05,
      "loss": 0.3716,
      "step": 12790
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.6998735666275024,
      "learning_rate": 1.0360542989950641e-05,
      "loss": 0.3215,
      "step": 12800
    },
    {
      "epoch": 6.01,
      "grad_norm": 1.7794344425201416,
      "learning_rate": 1.0339538563718575e-05,
      "loss": 0.341,
      "step": 12810
    },
    {
      "epoch": 6.01,
      "grad_norm": 2.0242815017700195,
      "learning_rate": 1.0318544247386846e-05,
      "loss": 0.3666,
      "step": 12820
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.2957305908203125,
      "learning_rate": 1.029756008649826e-05,
      "loss": 0.3407,
      "step": 12830
    },
    {
      "epoch": 6.02,
      "grad_norm": 2.1767032146453857,
      "learning_rate": 1.0276586126573578e-05,
      "loss": 0.3022,
      "step": 12840
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.609413981437683,
      "learning_rate": 1.025562241311144e-05,
      "loss": 0.3359,
      "step": 12850
    },
    {
      "epoch": 6.03,
      "grad_norm": 2.2377736568450928,
      "learning_rate": 1.0234668991588259e-05,
      "loss": 0.3341,
      "step": 12860
    },
    {
      "epoch": 6.03,
      "grad_norm": 2.0872182846069336,
      "learning_rate": 1.0213725907458118e-05,
      "loss": 0.3249,
      "step": 12870
    },
    {
      "epoch": 6.04,
      "grad_norm": 2.6512041091918945,
      "learning_rate": 1.0192793206152665e-05,
      "loss": 0.3399,
      "step": 12880
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.2495758533477783,
      "learning_rate": 1.017187093308105e-05,
      "loss": 0.3551,
      "step": 12890
    },
    {
      "epoch": 6.05,
      "grad_norm": 1.6194331645965576,
      "learning_rate": 1.0150959133629777e-05,
      "loss": 0.3163,
      "step": 12900
    },
    {
      "epoch": 6.05,
      "grad_norm": 1.9670335054397583,
      "learning_rate": 1.013005785316264e-05,
      "loss": 0.3267,
      "step": 12910
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.5732839107513428,
      "learning_rate": 1.010916713702062e-05,
      "loss": 0.3357,
      "step": 12920
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.641914963722229,
      "learning_rate": 1.008828703052177e-05,
      "loss": 0.3443,
      "step": 12930
    },
    {
      "epoch": 6.07,
      "grad_norm": 1.6571279764175415,
      "learning_rate": 1.006741757896113e-05,
      "loss": 0.3589,
      "step": 12940
    },
    {
      "epoch": 6.07,
      "grad_norm": 1.4930299520492554,
      "learning_rate": 1.0046558827610627e-05,
      "loss": 0.3661,
      "step": 12950
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.2456563711166382,
      "learning_rate": 1.0025710821718983e-05,
      "loss": 0.368,
      "step": 12960
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.6156957149505615,
      "learning_rate": 1.0004873606511602e-05,
      "loss": 0.3288,
      "step": 12970
    },
    {
      "epoch": 6.09,
      "grad_norm": 1.5178842544555664,
      "learning_rate": 9.984047227190484e-06,
      "loss": 0.3498,
      "step": 12980
    },
    {
      "epoch": 6.09,
      "grad_norm": 2.042545795440674,
      "learning_rate": 9.963231728934113e-06,
      "loss": 0.3914,
      "step": 12990
    },
    {
      "epoch": 6.09,
      "grad_norm": 1.59160578250885,
      "learning_rate": 9.942427156897385e-06,
      "loss": 0.31,
      "step": 13000
    },
    {
      "epoch": 6.1,
      "grad_norm": 1.4690252542495728,
      "learning_rate": 9.921633556211483e-06,
      "loss": 0.3332,
      "step": 13010
    },
    {
      "epoch": 6.1,
      "grad_norm": 1.6763888597488403,
      "learning_rate": 9.900850971983789e-06,
      "loss": 0.3308,
      "step": 13020
    },
    {
      "epoch": 6.11,
      "grad_norm": 1.394288420677185,
      "learning_rate": 9.880079449297796e-06,
      "loss": 0.3389,
      "step": 13030
    },
    {
      "epoch": 6.11,
      "grad_norm": 2.0294065475463867,
      "learning_rate": 9.859319033213e-06,
      "loss": 0.3446,
      "step": 13040
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.5440720319747925,
      "learning_rate": 9.838569768764788e-06,
      "loss": 0.3465,
      "step": 13050
    },
    {
      "epoch": 6.12,
      "grad_norm": 2.3082516193389893,
      "learning_rate": 9.81783170096437e-06,
      "loss": 0.2962,
      "step": 13060
    },
    {
      "epoch": 6.13,
      "grad_norm": 1.2276519536972046,
      "learning_rate": 9.79710487479867e-06,
      "loss": 0.3523,
      "step": 13070
    },
    {
      "epoch": 6.13,
      "grad_norm": 1.296891689300537,
      "learning_rate": 9.776389335230214e-06,
      "loss": 0.3109,
      "step": 13080
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.2771700620651245,
      "learning_rate": 9.755685127197057e-06,
      "loss": 0.347,
      "step": 13090
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.058525323867798,
      "learning_rate": 9.734992295612666e-06,
      "loss": 0.3305,
      "step": 13100
    },
    {
      "epoch": 6.15,
      "grad_norm": 1.8837194442749023,
      "learning_rate": 9.71431088536582e-06,
      "loss": 0.3254,
      "step": 13110
    },
    {
      "epoch": 6.15,
      "grad_norm": 1.3092851638793945,
      "learning_rate": 9.693640941320534e-06,
      "loss": 0.3367,
      "step": 13120
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.240888237953186,
      "learning_rate": 9.672982508315953e-06,
      "loss": 0.3347,
      "step": 13130
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.4194726943969727,
      "learning_rate": 9.652335631166236e-06,
      "loss": 0.3442,
      "step": 13140
    },
    {
      "epoch": 6.17,
      "grad_norm": 2.0321855545043945,
      "learning_rate": 9.631700354660484e-06,
      "loss": 0.3476,
      "step": 13150
    },
    {
      "epoch": 6.17,
      "grad_norm": 1.7465771436691284,
      "learning_rate": 9.611076723562641e-06,
      "loss": 0.3308,
      "step": 13160
    },
    {
      "epoch": 6.17,
      "grad_norm": 1.5311665534973145,
      "learning_rate": 9.590464782611367e-06,
      "loss": 0.3319,
      "step": 13170
    },
    {
      "epoch": 6.18,
      "grad_norm": 1.6036791801452637,
      "learning_rate": 9.569864576519978e-06,
      "loss": 0.3489,
      "step": 13180
    },
    {
      "epoch": 6.18,
      "grad_norm": 1.7152099609375,
      "learning_rate": 9.549276149976327e-06,
      "loss": 0.3684,
      "step": 13190
    },
    {
      "epoch": 6.19,
      "grad_norm": 1.5154964923858643,
      "learning_rate": 9.528699547642726e-06,
      "loss": 0.3256,
      "step": 13200
    },
    {
      "epoch": 6.19,
      "grad_norm": 1.0734288692474365,
      "learning_rate": 9.508134814155818e-06,
      "loss": 0.343,
      "step": 13210
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.4276403188705444,
      "learning_rate": 9.487581994126522e-06,
      "loss": 0.3371,
      "step": 13220
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.7170544862747192,
      "learning_rate": 9.467041132139884e-06,
      "loss": 0.3303,
      "step": 13230
    },
    {
      "epoch": 6.21,
      "grad_norm": 1.6458064317703247,
      "learning_rate": 9.446512272755034e-06,
      "loss": 0.3587,
      "step": 13240
    },
    {
      "epoch": 6.21,
      "grad_norm": 1.4529178142547607,
      "learning_rate": 9.425995460505055e-06,
      "loss": 0.3403,
      "step": 13250
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.5608091354370117,
      "learning_rate": 9.405490739896899e-06,
      "loss": 0.3437,
      "step": 13260
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.2864398956298828,
      "learning_rate": 9.384998155411288e-06,
      "loss": 0.3518,
      "step": 13270
    },
    {
      "epoch": 6.23,
      "grad_norm": 1.8627132177352905,
      "learning_rate": 9.364517751502613e-06,
      "loss": 0.3404,
      "step": 13280
    },
    {
      "epoch": 6.23,
      "grad_norm": 0.9947376251220703,
      "learning_rate": 9.34404957259884e-06,
      "loss": 0.3386,
      "step": 13290
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.8299646377563477,
      "learning_rate": 9.323593663101424e-06,
      "loss": 0.3382,
      "step": 13300
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.5260741710662842,
      "learning_rate": 9.303150067385204e-06,
      "loss": 0.329,
      "step": 13310
    },
    {
      "epoch": 6.24,
      "grad_norm": 2.435288906097412,
      "learning_rate": 9.282718829798293e-06,
      "loss": 0.3267,
      "step": 13320
    },
    {
      "epoch": 6.25,
      "grad_norm": 2.0043435096740723,
      "learning_rate": 9.262299994662015e-06,
      "loss": 0.3256,
      "step": 13330
    },
    {
      "epoch": 6.25,
      "grad_norm": 1.5096946954727173,
      "learning_rate": 9.241893606270779e-06,
      "loss": 0.2972,
      "step": 13340
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.7799363136291504,
      "learning_rate": 9.221499708891986e-06,
      "loss": 0.3397,
      "step": 13350
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.2123980522155762,
      "learning_rate": 9.201118346765951e-06,
      "loss": 0.3199,
      "step": 13360
    },
    {
      "epoch": 6.27,
      "grad_norm": 2.1745574474334717,
      "learning_rate": 9.180749564105798e-06,
      "loss": 0.3152,
      "step": 13370
    },
    {
      "epoch": 6.27,
      "grad_norm": 1.6401114463806152,
      "learning_rate": 9.160393405097356e-06,
      "loss": 0.3655,
      "step": 13380
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.7458819150924683,
      "learning_rate": 9.14004991389908e-06,
      "loss": 0.3335,
      "step": 13390
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.8303347826004028,
      "learning_rate": 9.119719134641918e-06,
      "loss": 0.3397,
      "step": 13400
    },
    {
      "epoch": 6.29,
      "grad_norm": 2.0443429946899414,
      "learning_rate": 9.099401111429279e-06,
      "loss": 0.3352,
      "step": 13410
    },
    {
      "epoch": 6.29,
      "grad_norm": 2.188951015472412,
      "learning_rate": 9.079095888336866e-06,
      "loss": 0.3475,
      "step": 13420
    },
    {
      "epoch": 6.3,
      "grad_norm": 1.6061033010482788,
      "learning_rate": 9.058803509412647e-06,
      "loss": 0.3967,
      "step": 13430
    },
    {
      "epoch": 6.3,
      "grad_norm": 1.7868716716766357,
      "learning_rate": 9.038524018676704e-06,
      "loss": 0.3161,
      "step": 13440
    },
    {
      "epoch": 6.31,
      "grad_norm": 2.4638922214508057,
      "learning_rate": 9.018257460121172e-06,
      "loss": 0.3324,
      "step": 13450
    },
    {
      "epoch": 6.31,
      "grad_norm": 1.7768478393554688,
      "learning_rate": 8.998003877710118e-06,
      "loss": 0.3427,
      "step": 13460
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.6524169445037842,
      "learning_rate": 8.977763315379482e-06,
      "loss": 0.3505,
      "step": 13470
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.23452889919281,
      "learning_rate": 8.957535817036942e-06,
      "loss": 0.3509,
      "step": 13480
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.3252661228179932,
      "learning_rate": 8.937321426561839e-06,
      "loss": 0.3261,
      "step": 13490
    },
    {
      "epoch": 6.33,
      "grad_norm": 1.5250600576400757,
      "learning_rate": 8.917120187805091e-06,
      "loss": 0.3528,
      "step": 13500
    },
    {
      "epoch": 6.33,
      "grad_norm": 1.9571261405944824,
      "learning_rate": 8.89693214458908e-06,
      "loss": 0.3578,
      "step": 13510
    },
    {
      "epoch": 6.34,
      "grad_norm": 1.8622925281524658,
      "learning_rate": 8.876757340707548e-06,
      "loss": 0.3455,
      "step": 13520
    },
    {
      "epoch": 6.34,
      "grad_norm": 1.5471532344818115,
      "learning_rate": 8.856595819925535e-06,
      "loss": 0.3619,
      "step": 13530
    },
    {
      "epoch": 6.35,
      "grad_norm": 2.4801993370056152,
      "learning_rate": 8.836447625979267e-06,
      "loss": 0.3172,
      "step": 13540
    },
    {
      "epoch": 6.35,
      "grad_norm": 1.6595557928085327,
      "learning_rate": 8.816312802576044e-06,
      "loss": 0.2836,
      "step": 13550
    },
    {
      "epoch": 6.36,
      "grad_norm": 1.74362313747406,
      "learning_rate": 8.796191393394177e-06,
      "loss": 0.3652,
      "step": 13560
    },
    {
      "epoch": 6.36,
      "grad_norm": 1.6764627695083618,
      "learning_rate": 8.77608344208288e-06,
      "loss": 0.333,
      "step": 13570
    },
    {
      "epoch": 6.37,
      "grad_norm": 1.7500730752944946,
      "learning_rate": 8.755988992262151e-06,
      "loss": 0.319,
      "step": 13580
    },
    {
      "epoch": 6.37,
      "grad_norm": 1.5514949560165405,
      "learning_rate": 8.735908087522721e-06,
      "loss": 0.3311,
      "step": 13590
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.3082808256149292,
      "learning_rate": 8.71584077142592e-06,
      "loss": 0.3624,
      "step": 13600
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.4028171300888062,
      "learning_rate": 8.695787087503628e-06,
      "loss": 0.2997,
      "step": 13610
    },
    {
      "epoch": 6.39,
      "grad_norm": 1.5276817083358765,
      "learning_rate": 8.675747079258124e-06,
      "loss": 0.2914,
      "step": 13620
    },
    {
      "epoch": 6.39,
      "grad_norm": 2.10931134223938,
      "learning_rate": 8.65572079016204e-06,
      "loss": 0.3188,
      "step": 13630
    },
    {
      "epoch": 6.39,
      "grad_norm": 2.538313150405884,
      "learning_rate": 8.63570826365822e-06,
      "loss": 0.3339,
      "step": 13640
    },
    {
      "epoch": 6.4,
      "grad_norm": 2.4532134532928467,
      "learning_rate": 8.615709543159692e-06,
      "loss": 0.3365,
      "step": 13650
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.2600570917129517,
      "learning_rate": 8.595724672049503e-06,
      "loss": 0.3639,
      "step": 13660
    },
    {
      "epoch": 6.41,
      "grad_norm": 1.3869622945785522,
      "learning_rate": 8.575753693680675e-06,
      "loss": 0.3196,
      "step": 13670
    },
    {
      "epoch": 6.41,
      "grad_norm": 2.2033090591430664,
      "learning_rate": 8.555796651376081e-06,
      "loss": 0.3392,
      "step": 13680
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.9874298572540283,
      "learning_rate": 8.535853588428371e-06,
      "loss": 0.3051,
      "step": 13690
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.8457671403884888,
      "learning_rate": 8.515924548099863e-06,
      "loss": 0.3616,
      "step": 13700
    },
    {
      "epoch": 6.43,
      "grad_norm": 1.7580230236053467,
      "learning_rate": 8.496009573622461e-06,
      "loss": 0.3446,
      "step": 13710
    },
    {
      "epoch": 6.43,
      "grad_norm": 1.2645221948623657,
      "learning_rate": 8.476108708197553e-06,
      "loss": 0.3801,
      "step": 13720
    },
    {
      "epoch": 6.44,
      "grad_norm": 1.5280139446258545,
      "learning_rate": 8.456221994995921e-06,
      "loss": 0.3508,
      "step": 13730
    },
    {
      "epoch": 6.44,
      "grad_norm": 1.7866309881210327,
      "learning_rate": 8.43634947715764e-06,
      "loss": 0.3309,
      "step": 13740
    },
    {
      "epoch": 6.45,
      "grad_norm": 2.008077383041382,
      "learning_rate": 8.41649119779202e-06,
      "loss": 0.3061,
      "step": 13750
    },
    {
      "epoch": 6.45,
      "grad_norm": 2.5503125190734863,
      "learning_rate": 8.396647199977439e-06,
      "loss": 0.3,
      "step": 13760
    },
    {
      "epoch": 6.46,
      "grad_norm": 1.519532322883606,
      "learning_rate": 8.376817526761327e-06,
      "loss": 0.3302,
      "step": 13770
    },
    {
      "epoch": 6.46,
      "grad_norm": 1.7645490169525146,
      "learning_rate": 8.357002221160022e-06,
      "loss": 0.3027,
      "step": 13780
    },
    {
      "epoch": 6.47,
      "grad_norm": 1.658251166343689,
      "learning_rate": 8.337201326158711e-06,
      "loss": 0.3502,
      "step": 13790
    },
    {
      "epoch": 6.47,
      "grad_norm": 1.4063422679901123,
      "learning_rate": 8.317414884711312e-06,
      "loss": 0.3109,
      "step": 13800
    },
    {
      "epoch": 6.47,
      "grad_norm": 1.4087562561035156,
      "learning_rate": 8.297642939740388e-06,
      "loss": 0.3477,
      "step": 13810
    },
    {
      "epoch": 6.48,
      "grad_norm": 1.2891839742660522,
      "learning_rate": 8.27788553413704e-06,
      "loss": 0.3201,
      "step": 13820
    },
    {
      "epoch": 6.48,
      "grad_norm": 1.2971285581588745,
      "learning_rate": 8.258142710760863e-06,
      "loss": 0.3276,
      "step": 13830
    },
    {
      "epoch": 6.49,
      "grad_norm": 1.7296885251998901,
      "learning_rate": 8.238414512439794e-06,
      "loss": 0.3476,
      "step": 13840
    },
    {
      "epoch": 6.49,
      "grad_norm": 1.4796708822250366,
      "learning_rate": 8.218700981970047e-06,
      "loss": 0.3476,
      "step": 13850
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.8196603059768677,
      "learning_rate": 8.199002162116022e-06,
      "loss": 0.3227,
      "step": 13860
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.9952174425125122,
      "learning_rate": 8.179318095610208e-06,
      "loss": 0.3464,
      "step": 13870
    },
    {
      "epoch": 6.51,
      "grad_norm": 1.7242988348007202,
      "learning_rate": 8.159648825153084e-06,
      "loss": 0.356,
      "step": 13880
    },
    {
      "epoch": 6.51,
      "grad_norm": 1.479493260383606,
      "learning_rate": 8.139994393413035e-06,
      "loss": 0.3532,
      "step": 13890
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.156294584274292,
      "learning_rate": 8.12035484302626e-06,
      "loss": 0.3325,
      "step": 13900
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.660897135734558,
      "learning_rate": 8.100730216596664e-06,
      "loss": 0.3551,
      "step": 13910
    },
    {
      "epoch": 6.53,
      "grad_norm": 1.3712444305419922,
      "learning_rate": 8.081120556695804e-06,
      "loss": 0.3598,
      "step": 13920
    },
    {
      "epoch": 6.53,
      "grad_norm": 1.4839651584625244,
      "learning_rate": 8.061525905862737e-06,
      "loss": 0.3174,
      "step": 13930
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.2746838331222534,
      "learning_rate": 8.041946306603981e-06,
      "loss": 0.3464,
      "step": 13940
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.737837314605713,
      "learning_rate": 8.022381801393393e-06,
      "loss": 0.3598,
      "step": 13950
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.0239472389221191,
      "learning_rate": 8.002832432672102e-06,
      "loss": 0.3502,
      "step": 13960
    },
    {
      "epoch": 6.55,
      "grad_norm": 1.5691581964492798,
      "learning_rate": 7.983298242848388e-06,
      "loss": 0.3458,
      "step": 13970
    },
    {
      "epoch": 6.55,
      "grad_norm": 1.4911593198776245,
      "learning_rate": 7.963779274297614e-06,
      "loss": 0.3558,
      "step": 13980
    },
    {
      "epoch": 6.56,
      "grad_norm": 2.156067132949829,
      "learning_rate": 7.944275569362094e-06,
      "loss": 0.3643,
      "step": 13990
    },
    {
      "epoch": 6.56,
      "grad_norm": 1.244913935661316,
      "learning_rate": 7.924787170351074e-06,
      "loss": 0.3348,
      "step": 14000
    },
    {
      "epoch": 6.57,
      "grad_norm": 1.4670265913009644,
      "learning_rate": 7.905314119540571e-06,
      "loss": 0.396,
      "step": 14010
    },
    {
      "epoch": 6.57,
      "grad_norm": 1.6128653287887573,
      "learning_rate": 7.885856459173313e-06,
      "loss": 0.3407,
      "step": 14020
    },
    {
      "epoch": 6.58,
      "grad_norm": 2.038252592086792,
      "learning_rate": 7.866414231458637e-06,
      "loss": 0.3709,
      "step": 14030
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.302539587020874,
      "learning_rate": 7.846987478572411e-06,
      "loss": 0.3476,
      "step": 14040
    },
    {
      "epoch": 6.59,
      "grad_norm": 1.8008618354797363,
      "learning_rate": 7.827576242656929e-06,
      "loss": 0.3368,
      "step": 14050
    },
    {
      "epoch": 6.59,
      "grad_norm": 1.5972110033035278,
      "learning_rate": 7.808180565820822e-06,
      "loss": 0.3384,
      "step": 14060
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.401404619216919,
      "learning_rate": 7.78880049013897e-06,
      "loss": 0.3416,
      "step": 14070
    },
    {
      "epoch": 6.6,
      "grad_norm": 1.589644193649292,
      "learning_rate": 7.769436057652407e-06,
      "loss": 0.3173,
      "step": 14080
    },
    {
      "epoch": 6.61,
      "grad_norm": 1.5865589380264282,
      "learning_rate": 7.750087310368247e-06,
      "loss": 0.3887,
      "step": 14090
    },
    {
      "epoch": 6.61,
      "grad_norm": 1.094987154006958,
      "learning_rate": 7.730754290259568e-06,
      "loss": 0.3287,
      "step": 14100
    },
    {
      "epoch": 6.62,
      "grad_norm": 2.19389271736145,
      "learning_rate": 7.711437039265315e-06,
      "loss": 0.3492,
      "step": 14110
    },
    {
      "epoch": 6.62,
      "grad_norm": 2.2664318084716797,
      "learning_rate": 7.692135599290241e-06,
      "loss": 0.3429,
      "step": 14120
    },
    {
      "epoch": 6.62,
      "grad_norm": 1.4206154346466064,
      "learning_rate": 7.672850012204815e-06,
      "loss": 0.3304,
      "step": 14130
    },
    {
      "epoch": 6.63,
      "grad_norm": 1.356520414352417,
      "learning_rate": 7.653580319845093e-06,
      "loss": 0.3191,
      "step": 14140
    },
    {
      "epoch": 6.63,
      "grad_norm": 1.6688034534454346,
      "learning_rate": 7.63432656401266e-06,
      "loss": 0.3491,
      "step": 14150
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.5613266229629517,
      "learning_rate": 7.615088786474526e-06,
      "loss": 0.3269,
      "step": 14160
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.5527597665786743,
      "learning_rate": 7.595867028963045e-06,
      "loss": 0.3576,
      "step": 14170
    },
    {
      "epoch": 6.65,
      "grad_norm": 1.525062918663025,
      "learning_rate": 7.576661333175814e-06,
      "loss": 0.3216,
      "step": 14180
    },
    {
      "epoch": 6.65,
      "grad_norm": 1.9893914461135864,
      "learning_rate": 7.557471740775593e-06,
      "loss": 0.3038,
      "step": 14190
    },
    {
      "epoch": 6.66,
      "grad_norm": 1.7685279846191406,
      "learning_rate": 7.538298293390201e-06,
      "loss": 0.3571,
      "step": 14200
    },
    {
      "epoch": 6.66,
      "grad_norm": 2.0026323795318604,
      "learning_rate": 7.5191410326124365e-06,
      "loss": 0.321,
      "step": 14210
    },
    {
      "epoch": 6.67,
      "grad_norm": 1.6976896524429321,
      "learning_rate": 7.500000000000004e-06,
      "loss": 0.338,
      "step": 14220
    },
    {
      "epoch": 6.67,
      "grad_norm": 1.301844835281372,
      "learning_rate": 7.480875237075366e-06,
      "loss": 0.3267,
      "step": 14230
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.4784259796142578,
      "learning_rate": 7.4617667853257184e-06,
      "loss": 0.3742,
      "step": 14240
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.6466126441955566,
      "learning_rate": 7.442674686202866e-06,
      "loss": 0.3426,
      "step": 14250
    },
    {
      "epoch": 6.69,
      "grad_norm": 1.3033790588378906,
      "learning_rate": 7.423598981123147e-06,
      "loss": 0.363,
      "step": 14260
    },
    {
      "epoch": 6.69,
      "grad_norm": 1.9836968183517456,
      "learning_rate": 7.404539711467333e-06,
      "loss": 0.3581,
      "step": 14270
    },
    {
      "epoch": 6.69,
      "grad_norm": 1.504085659980774,
      "learning_rate": 7.385496918580528e-06,
      "loss": 0.3614,
      "step": 14280
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.6127026081085205,
      "learning_rate": 7.3664706437721044e-06,
      "loss": 0.3168,
      "step": 14290
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.8629775047302246,
      "learning_rate": 7.347460928315614e-06,
      "loss": 0.3787,
      "step": 14300
    },
    {
      "epoch": 6.71,
      "grad_norm": 1.3986457586288452,
      "learning_rate": 7.3284678134486685e-06,
      "loss": 0.3331,
      "step": 14310
    },
    {
      "epoch": 6.71,
      "grad_norm": 1.911255955696106,
      "learning_rate": 7.3094913403728745e-06,
      "loss": 0.3808,
      "step": 14320
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.1757112741470337,
      "learning_rate": 7.290531550253738e-06,
      "loss": 0.3336,
      "step": 14330
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.41266930103302,
      "learning_rate": 7.271588484220576e-06,
      "loss": 0.3413,
      "step": 14340
    },
    {
      "epoch": 6.73,
      "grad_norm": 1.4058548212051392,
      "learning_rate": 7.252662183366421e-06,
      "loss": 0.3483,
      "step": 14350
    },
    {
      "epoch": 6.73,
      "grad_norm": 1.3093268871307373,
      "learning_rate": 7.233752688747944e-06,
      "loss": 0.3804,
      "step": 14360
    },
    {
      "epoch": 6.74,
      "grad_norm": 1.9105072021484375,
      "learning_rate": 7.214860041385354e-06,
      "loss": 0.3356,
      "step": 14370
    },
    {
      "epoch": 6.74,
      "grad_norm": 1.504866123199463,
      "learning_rate": 7.195984282262307e-06,
      "loss": 0.3236,
      "step": 14380
    },
    {
      "epoch": 6.75,
      "grad_norm": 1.2034071683883667,
      "learning_rate": 7.177125452325848e-06,
      "loss": 0.3404,
      "step": 14390
    },
    {
      "epoch": 6.75,
      "grad_norm": 1.9054874181747437,
      "learning_rate": 7.158283592486266e-06,
      "loss": 0.3505,
      "step": 14400
    },
    {
      "epoch": 6.76,
      "grad_norm": 1.4568067789077759,
      "learning_rate": 7.139458743617055e-06,
      "loss": 0.3103,
      "step": 14410
    },
    {
      "epoch": 6.76,
      "grad_norm": 1.9026843309402466,
      "learning_rate": 7.1206509465547956e-06,
      "loss": 0.3528,
      "step": 14420
    },
    {
      "epoch": 6.77,
      "grad_norm": 1.4189683198928833,
      "learning_rate": 7.101860242099102e-06,
      "loss": 0.3397,
      "step": 14430
    },
    {
      "epoch": 6.77,
      "grad_norm": 1.9425710439682007,
      "learning_rate": 7.083086671012485e-06,
      "loss": 0.3434,
      "step": 14440
    },
    {
      "epoch": 6.77,
      "grad_norm": 1.3763848543167114,
      "learning_rate": 7.064330274020302e-06,
      "loss": 0.365,
      "step": 14450
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.4115164279937744,
      "learning_rate": 7.045591091810635e-06,
      "loss": 0.3242,
      "step": 14460
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.568859338760376,
      "learning_rate": 7.026869165034251e-06,
      "loss": 0.3927,
      "step": 14470
    },
    {
      "epoch": 6.79,
      "grad_norm": 1.6347508430480957,
      "learning_rate": 7.008164534304467e-06,
      "loss": 0.3197,
      "step": 14480
    },
    {
      "epoch": 6.79,
      "grad_norm": 1.8911103010177612,
      "learning_rate": 6.989477240197081e-06,
      "loss": 0.3652,
      "step": 14490
    },
    {
      "epoch": 6.8,
      "grad_norm": 2.20314884185791,
      "learning_rate": 6.970807323250285e-06,
      "loss": 0.3199,
      "step": 14500
    },
    {
      "epoch": 6.8,
      "grad_norm": 1.5661767721176147,
      "learning_rate": 6.952154823964578e-06,
      "loss": 0.3343,
      "step": 14510
    },
    {
      "epoch": 6.81,
      "grad_norm": 0.9059175252914429,
      "learning_rate": 6.9335197828026685e-06,
      "loss": 0.3588,
      "step": 14520
    },
    {
      "epoch": 6.81,
      "grad_norm": 1.4019153118133545,
      "learning_rate": 6.914902240189399e-06,
      "loss": 0.3499,
      "step": 14530
    },
    {
      "epoch": 6.82,
      "grad_norm": 1.4184437990188599,
      "learning_rate": 6.8963022365116515e-06,
      "loss": 0.3544,
      "step": 14540
    },
    {
      "epoch": 6.82,
      "grad_norm": 1.6390677690505981,
      "learning_rate": 6.877719812118251e-06,
      "loss": 0.3365,
      "step": 14550
    },
    {
      "epoch": 6.83,
      "grad_norm": 1.8700182437896729,
      "learning_rate": 6.8591550073199085e-06,
      "loss": 0.3354,
      "step": 14560
    },
    {
      "epoch": 6.83,
      "grad_norm": 2.077009677886963,
      "learning_rate": 6.840607862389103e-06,
      "loss": 0.4168,
      "step": 14570
    },
    {
      "epoch": 6.84,
      "grad_norm": 1.3552738428115845,
      "learning_rate": 6.822078417559991e-06,
      "loss": 0.3484,
      "step": 14580
    },
    {
      "epoch": 6.84,
      "grad_norm": 1.4560221433639526,
      "learning_rate": 6.80356671302834e-06,
      "loss": 0.3521,
      "step": 14590
    },
    {
      "epoch": 6.84,
      "grad_norm": 1.83431077003479,
      "learning_rate": 6.785072788951452e-06,
      "loss": 0.3479,
      "step": 14600
    },
    {
      "epoch": 6.85,
      "grad_norm": 1.5872042179107666,
      "learning_rate": 6.766596685448036e-06,
      "loss": 0.3217,
      "step": 14610
    },
    {
      "epoch": 6.85,
      "grad_norm": 1.5367944240570068,
      "learning_rate": 6.7481384425981485e-06,
      "loss": 0.2972,
      "step": 14620
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.1752046346664429,
      "learning_rate": 6.729698100443106e-06,
      "loss": 0.3408,
      "step": 14630
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.9372475147247314,
      "learning_rate": 6.711275698985388e-06,
      "loss": 0.3292,
      "step": 14640
    },
    {
      "epoch": 6.87,
      "grad_norm": 2.4838736057281494,
      "learning_rate": 6.692871278188557e-06,
      "loss": 0.3362,
      "step": 14650
    },
    {
      "epoch": 6.87,
      "grad_norm": 2.0927510261535645,
      "learning_rate": 6.674484877977172e-06,
      "loss": 0.3764,
      "step": 14660
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.6986868381500244,
      "learning_rate": 6.656116538236696e-06,
      "loss": 0.3512,
      "step": 14670
    },
    {
      "epoch": 6.88,
      "grad_norm": 2.1090242862701416,
      "learning_rate": 6.637766298813419e-06,
      "loss": 0.3494,
      "step": 14680
    },
    {
      "epoch": 6.89,
      "grad_norm": 1.4869682788848877,
      "learning_rate": 6.6194341995143605e-06,
      "loss": 0.3678,
      "step": 14690
    },
    {
      "epoch": 6.89,
      "grad_norm": 1.490045428276062,
      "learning_rate": 6.601120280107192e-06,
      "loss": 0.3189,
      "step": 14700
    },
    {
      "epoch": 6.9,
      "grad_norm": 1.326806902885437,
      "learning_rate": 6.582824580320148e-06,
      "loss": 0.328,
      "step": 14710
    },
    {
      "epoch": 6.9,
      "grad_norm": 1.4669650793075562,
      "learning_rate": 6.564547139841933e-06,
      "loss": 0.3376,
      "step": 14720
    },
    {
      "epoch": 6.91,
      "grad_norm": 1.5277105569839478,
      "learning_rate": 6.546287998321656e-06,
      "loss": 0.3746,
      "step": 14730
    },
    {
      "epoch": 6.91,
      "grad_norm": 2.2548036575317383,
      "learning_rate": 6.528047195368724e-06,
      "loss": 0.3325,
      "step": 14740
    },
    {
      "epoch": 6.92,
      "grad_norm": 1.9037275314331055,
      "learning_rate": 6.509824770552747e-06,
      "loss": 0.3058,
      "step": 14750
    },
    {
      "epoch": 6.92,
      "grad_norm": 1.526411533355713,
      "learning_rate": 6.491620763403481e-06,
      "loss": 0.335,
      "step": 14760
    },
    {
      "epoch": 6.92,
      "grad_norm": 2.0385448932647705,
      "learning_rate": 6.473435213410737e-06,
      "loss": 0.3526,
      "step": 14770
    },
    {
      "epoch": 6.93,
      "grad_norm": 1.768992304801941,
      "learning_rate": 6.455268160024273e-06,
      "loss": 0.3223,
      "step": 14780
    },
    {
      "epoch": 6.93,
      "grad_norm": 1.240147352218628,
      "learning_rate": 6.4371196426537295e-06,
      "loss": 0.3134,
      "step": 14790
    },
    {
      "epoch": 6.94,
      "grad_norm": 1.2286005020141602,
      "learning_rate": 6.418989700668532e-06,
      "loss": 0.3478,
      "step": 14800
    },
    {
      "epoch": 6.94,
      "grad_norm": 2.9850518703460693,
      "learning_rate": 6.4008783733978135e-06,
      "loss": 0.3089,
      "step": 14810
    },
    {
      "epoch": 6.95,
      "grad_norm": 1.3354328870773315,
      "learning_rate": 6.3827857001303265e-06,
      "loss": 0.3181,
      "step": 14820
    },
    {
      "epoch": 6.95,
      "grad_norm": 1.7095859050750732,
      "learning_rate": 6.3647117201143575e-06,
      "loss": 0.3295,
      "step": 14830
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.241811752319336,
      "learning_rate": 6.346656472557642e-06,
      "loss": 0.3301,
      "step": 14840
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.1600139141082764,
      "learning_rate": 6.328619996627272e-06,
      "loss": 0.3217,
      "step": 14850
    },
    {
      "epoch": 6.97,
      "grad_norm": 1.4198331832885742,
      "learning_rate": 6.310602331449642e-06,
      "loss": 0.3738,
      "step": 14860
    },
    {
      "epoch": 6.97,
      "grad_norm": 2.096437692642212,
      "learning_rate": 6.292603516110307e-06,
      "loss": 0.3248,
      "step": 14870
    },
    {
      "epoch": 6.98,
      "grad_norm": 1.6146777868270874,
      "learning_rate": 6.274623589653954e-06,
      "loss": 0.3147,
      "step": 14880
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.5940816402435303,
      "learning_rate": 6.256662591084283e-06,
      "loss": 0.3524,
      "step": 14890
    },
    {
      "epoch": 6.99,
      "grad_norm": 2.334256172180176,
      "learning_rate": 6.238720559363949e-06,
      "loss": 0.3714,
      "step": 14900
    },
    {
      "epoch": 6.99,
      "grad_norm": 1.7144103050231934,
      "learning_rate": 6.220797533414447e-06,
      "loss": 0.3337,
      "step": 14910
    },
    {
      "epoch": 6.99,
      "grad_norm": 2.317338466644287,
      "learning_rate": 6.202893552116058e-06,
      "loss": 0.3344,
      "step": 14920
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.922712802886963,
      "learning_rate": 6.185008654307717e-06,
      "loss": 0.3408,
      "step": 14930
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.404770016670227,
      "learning_rate": 6.167142878787007e-06,
      "loss": 0.329,
      "step": 14940
    },
    {
      "epoch": 7.01,
      "grad_norm": 1.1122390031814575,
      "learning_rate": 6.1492962643099985e-06,
      "loss": 0.344,
      "step": 14950
    },
    {
      "epoch": 7.01,
      "grad_norm": 1.6734850406646729,
      "learning_rate": 6.131468849591203e-06,
      "loss": 0.3352,
      "step": 14960
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.6797608137130737,
      "learning_rate": 6.113660673303486e-06,
      "loss": 0.318,
      "step": 14970
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.736659288406372,
      "learning_rate": 6.095871774077976e-06,
      "loss": 0.3288,
      "step": 14980
    },
    {
      "epoch": 7.03,
      "grad_norm": 1.9042940139770508,
      "learning_rate": 6.078102190503984e-06,
      "loss": 0.3247,
      "step": 14990
    },
    {
      "epoch": 7.03,
      "grad_norm": 1.9518334865570068,
      "learning_rate": 6.06035196112892e-06,
      "loss": 0.3353,
      "step": 15000
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.2880966663360596,
      "learning_rate": 6.0426211244582105e-06,
      "loss": 0.3305,
      "step": 15010
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.809415578842163,
      "learning_rate": 6.024909718955206e-06,
      "loss": 0.3421,
      "step": 15020
    },
    {
      "epoch": 7.05,
      "grad_norm": 1.1956253051757812,
      "learning_rate": 6.007217783041122e-06,
      "loss": 0.3494,
      "step": 15030
    },
    {
      "epoch": 7.05,
      "grad_norm": 1.106843113899231,
      "learning_rate": 5.98954535509493e-06,
      "loss": 0.3034,
      "step": 15040
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.7319928407669067,
      "learning_rate": 5.971892473453269e-06,
      "loss": 0.3027,
      "step": 15050
    },
    {
      "epoch": 7.06,
      "grad_norm": 2.15865159034729,
      "learning_rate": 5.95425917641039e-06,
      "loss": 0.2756,
      "step": 15060
    },
    {
      "epoch": 7.07,
      "grad_norm": 1.1139332056045532,
      "learning_rate": 5.936645502218068e-06,
      "loss": 0.3251,
      "step": 15070
    },
    {
      "epoch": 7.07,
      "grad_norm": 1.6517771482467651,
      "learning_rate": 5.919051489085495e-06,
      "loss": 0.3022,
      "step": 15080
    },
    {
      "epoch": 7.07,
      "grad_norm": 1.8384894132614136,
      "learning_rate": 5.901477175179223e-06,
      "loss": 0.3095,
      "step": 15090
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.6891863346099854,
      "learning_rate": 5.883922598623051e-06,
      "loss": 0.3503,
      "step": 15100
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.7598308324813843,
      "learning_rate": 5.866387797497991e-06,
      "loss": 0.297,
      "step": 15110
    },
    {
      "epoch": 7.09,
      "grad_norm": 1.5838392972946167,
      "learning_rate": 5.8488728098421345e-06,
      "loss": 0.3705,
      "step": 15120
    },
    {
      "epoch": 7.09,
      "grad_norm": 1.5171431303024292,
      "learning_rate": 5.831377673650602e-06,
      "loss": 0.3259,
      "step": 15130
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.8200017213821411,
      "learning_rate": 5.813902426875448e-06,
      "loss": 0.3034,
      "step": 15140
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.4963905811309814,
      "learning_rate": 5.796447107425576e-06,
      "loss": 0.3182,
      "step": 15150
    },
    {
      "epoch": 7.11,
      "grad_norm": 0.8427501320838928,
      "learning_rate": 5.77901175316667e-06,
      "loss": 0.3503,
      "step": 15160
    },
    {
      "epoch": 7.11,
      "grad_norm": 1.5525544881820679,
      "learning_rate": 5.7615964019210975e-06,
      "loss": 0.3451,
      "step": 15170
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.5791634321212769,
      "learning_rate": 5.744201091467835e-06,
      "loss": 0.3312,
      "step": 15180
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.24153733253479,
      "learning_rate": 5.726825859542381e-06,
      "loss": 0.3223,
      "step": 15190
    },
    {
      "epoch": 7.13,
      "grad_norm": 1.752175211906433,
      "learning_rate": 5.709470743836692e-06,
      "loss": 0.2958,
      "step": 15200
    },
    {
      "epoch": 7.13,
      "grad_norm": 1.6946338415145874,
      "learning_rate": 5.692135781999079e-06,
      "loss": 0.3275,
      "step": 15210
    },
    {
      "epoch": 7.14,
      "grad_norm": 0.9952741861343384,
      "learning_rate": 5.674821011634116e-06,
      "loss": 0.3721,
      "step": 15220
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.3988704681396484,
      "learning_rate": 5.657526470302593e-06,
      "loss": 0.3623,
      "step": 15230
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.7312496900558472,
      "learning_rate": 5.640252195521428e-06,
      "loss": 0.316,
      "step": 15240
    },
    {
      "epoch": 7.15,
      "grad_norm": 1.702132225036621,
      "learning_rate": 5.6229982247635525e-06,
      "loss": 0.349,
      "step": 15250
    },
    {
      "epoch": 7.15,
      "grad_norm": 1.1557559967041016,
      "learning_rate": 5.605764595457865e-06,
      "loss": 0.3176,
      "step": 15260
    },
    {
      "epoch": 7.16,
      "grad_norm": 1.6112501621246338,
      "learning_rate": 5.588551344989133e-06,
      "loss": 0.2946,
      "step": 15270
    },
    {
      "epoch": 7.16,
      "grad_norm": 1.203015685081482,
      "learning_rate": 5.571358510697918e-06,
      "loss": 0.3128,
      "step": 15280
    },
    {
      "epoch": 7.17,
      "grad_norm": 1.6530296802520752,
      "learning_rate": 5.554186129880495e-06,
      "loss": 0.3612,
      "step": 15290
    },
    {
      "epoch": 7.17,
      "grad_norm": 1.3458809852600098,
      "learning_rate": 5.5370342397887654e-06,
      "loss": 0.2727,
      "step": 15300
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.690014362335205,
      "learning_rate": 5.519902877630182e-06,
      "loss": 0.3783,
      "step": 15310
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.9937162399291992,
      "learning_rate": 5.502792080567664e-06,
      "loss": 0.315,
      "step": 15320
    },
    {
      "epoch": 7.19,
      "grad_norm": 1.6820858716964722,
      "learning_rate": 5.485701885719534e-06,
      "loss": 0.3549,
      "step": 15330
    },
    {
      "epoch": 7.19,
      "grad_norm": 1.4655637741088867,
      "learning_rate": 5.4686323301593945e-06,
      "loss": 0.334,
      "step": 15340
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.5802412033081055,
      "learning_rate": 5.451583450916099e-06,
      "loss": 0.3662,
      "step": 15350
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.5069353580474854,
      "learning_rate": 5.434555284973632e-06,
      "loss": 0.3872,
      "step": 15360
    },
    {
      "epoch": 7.21,
      "grad_norm": 1.9588297605514526,
      "learning_rate": 5.417547869271063e-06,
      "loss": 0.3284,
      "step": 15370
    },
    {
      "epoch": 7.21,
      "grad_norm": 1.9467614889144897,
      "learning_rate": 5.400561240702434e-06,
      "loss": 0.365,
      "step": 15380
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.3240915536880493,
      "learning_rate": 5.383595436116703e-06,
      "loss": 0.299,
      "step": 15390
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.4676741361618042,
      "learning_rate": 5.366650492317632e-06,
      "loss": 0.3308,
      "step": 15400
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.7514221668243408,
      "learning_rate": 5.349726446063764e-06,
      "loss": 0.3402,
      "step": 15410
    },
    {
      "epoch": 7.23,
      "grad_norm": 1.6105213165283203,
      "learning_rate": 5.332823334068285e-06,
      "loss": 0.3199,
      "step": 15420
    },
    {
      "epoch": 7.23,
      "grad_norm": 1.5992282629013062,
      "learning_rate": 5.3159411929989785e-06,
      "loss": 0.3586,
      "step": 15430
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.341784119606018,
      "learning_rate": 5.299080059478131e-06,
      "loss": 0.3108,
      "step": 15440
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.373844027519226,
      "learning_rate": 5.2822399700824595e-06,
      "loss": 0.2759,
      "step": 15450
    },
    {
      "epoch": 7.25,
      "grad_norm": 1.2582896947860718,
      "learning_rate": 5.265420961343034e-06,
      "loss": 0.3547,
      "step": 15460
    },
    {
      "epoch": 7.25,
      "grad_norm": 2.3997435569763184,
      "learning_rate": 5.248623069745185e-06,
      "loss": 0.3268,
      "step": 15470
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.592766523361206,
      "learning_rate": 5.2318463317284425e-06,
      "loss": 0.3515,
      "step": 15480
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.3218605518341064,
      "learning_rate": 5.21509078368644e-06,
      "loss": 0.3645,
      "step": 15490
    },
    {
      "epoch": 7.27,
      "grad_norm": 2.0103249549865723,
      "learning_rate": 5.198356461966865e-06,
      "loss": 0.3562,
      "step": 15500
    },
    {
      "epoch": 7.27,
      "grad_norm": 1.9197672605514526,
      "learning_rate": 5.181643402871325e-06,
      "loss": 0.3356,
      "step": 15510
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.3104418516159058,
      "learning_rate": 5.164951642655328e-06,
      "loss": 0.3888,
      "step": 15520
    },
    {
      "epoch": 7.28,
      "grad_norm": 2.3498902320861816,
      "learning_rate": 5.148281217528165e-06,
      "loss": 0.2807,
      "step": 15530
    },
    {
      "epoch": 7.29,
      "grad_norm": 1.9948126077651978,
      "learning_rate": 5.13163216365286e-06,
      "loss": 0.3491,
      "step": 15540
    },
    {
      "epoch": 7.29,
      "grad_norm": 2.263185739517212,
      "learning_rate": 5.115004517146065e-06,
      "loss": 0.3214,
      "step": 15550
    },
    {
      "epoch": 7.29,
      "grad_norm": 2.1079964637756348,
      "learning_rate": 5.098398314077999e-06,
      "loss": 0.3008,
      "step": 15560
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.2919286489486694,
      "learning_rate": 5.081813590472344e-06,
      "loss": 0.2812,
      "step": 15570
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.558290958404541,
      "learning_rate": 5.065250382306222e-06,
      "loss": 0.3229,
      "step": 15580
    },
    {
      "epoch": 7.31,
      "grad_norm": 1.1556740999221802,
      "learning_rate": 5.048708725510056e-06,
      "loss": 0.3693,
      "step": 15590
    },
    {
      "epoch": 7.31,
      "grad_norm": 2.1964945793151855,
      "learning_rate": 5.032188655967525e-06,
      "loss": 0.2874,
      "step": 15600
    },
    {
      "epoch": 7.32,
      "grad_norm": 2.0441975593566895,
      "learning_rate": 5.0156902095154785e-06,
      "loss": 0.3477,
      "step": 15610
    },
    {
      "epoch": 7.32,
      "grad_norm": 2.19002628326416,
      "learning_rate": 4.999213421943862e-06,
      "loss": 0.2961,
      "step": 15620
    },
    {
      "epoch": 7.33,
      "grad_norm": 1.8292787075042725,
      "learning_rate": 4.982758328995631e-06,
      "loss": 0.3288,
      "step": 15630
    },
    {
      "epoch": 7.33,
      "grad_norm": 2.0491228103637695,
      "learning_rate": 4.9663249663666835e-06,
      "loss": 0.3236,
      "step": 15640
    },
    {
      "epoch": 7.34,
      "grad_norm": 2.4216084480285645,
      "learning_rate": 4.949913369705776e-06,
      "loss": 0.3101,
      "step": 15650
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.6864904165267944,
      "learning_rate": 4.933523574614447e-06,
      "loss": 0.3181,
      "step": 15660
    },
    {
      "epoch": 7.35,
      "grad_norm": 1.1058820486068726,
      "learning_rate": 4.9171556166469486e-06,
      "loss": 0.3133,
      "step": 15670
    },
    {
      "epoch": 7.35,
      "grad_norm": 1.5828438997268677,
      "learning_rate": 4.9008095313101594e-06,
      "loss": 0.2881,
      "step": 15680
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.6591299772262573,
      "learning_rate": 4.8844853540634966e-06,
      "loss": 0.2956,
      "step": 15690
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.28361976146698,
      "learning_rate": 4.8681831203188605e-06,
      "loss": 0.2942,
      "step": 15700
    },
    {
      "epoch": 7.37,
      "grad_norm": 2.297170877456665,
      "learning_rate": 4.851902865440563e-06,
      "loss": 0.2895,
      "step": 15710
    },
    {
      "epoch": 7.37,
      "grad_norm": 1.8420928716659546,
      "learning_rate": 4.835644624745222e-06,
      "loss": 0.3305,
      "step": 15720
    },
    {
      "epoch": 7.37,
      "grad_norm": 1.7667043209075928,
      "learning_rate": 4.819408433501702e-06,
      "loss": 0.2744,
      "step": 15730
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.245227336883545,
      "learning_rate": 4.803194326931039e-06,
      "loss": 0.3974,
      "step": 15740
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.5274815559387207,
      "learning_rate": 4.7870023402063615e-06,
      "loss": 0.3058,
      "step": 15750
    },
    {
      "epoch": 7.39,
      "grad_norm": 1.808444619178772,
      "learning_rate": 4.770832508452809e-06,
      "loss": 0.3384,
      "step": 15760
    },
    {
      "epoch": 7.39,
      "grad_norm": 1.4053453207015991,
      "learning_rate": 4.754684866747466e-06,
      "loss": 0.323,
      "step": 15770
    },
    {
      "epoch": 7.4,
      "grad_norm": 2.319338083267212,
      "learning_rate": 4.738559450119275e-06,
      "loss": 0.3525,
      "step": 15780
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.6363098621368408,
      "learning_rate": 4.722456293548968e-06,
      "loss": 0.3861,
      "step": 15790
    },
    {
      "epoch": 7.41,
      "grad_norm": 1.4785581827163696,
      "learning_rate": 4.706375431968998e-06,
      "loss": 0.3325,
      "step": 15800
    },
    {
      "epoch": 7.41,
      "grad_norm": 1.3880085945129395,
      "learning_rate": 4.690316900263435e-06,
      "loss": 0.2982,
      "step": 15810
    },
    {
      "epoch": 7.42,
      "grad_norm": 1.8886548280715942,
      "learning_rate": 4.6742807332679205e-06,
      "loss": 0.3115,
      "step": 15820
    },
    {
      "epoch": 7.42,
      "grad_norm": 1.5765163898468018,
      "learning_rate": 4.658266965769576e-06,
      "loss": 0.3425,
      "step": 15830
    },
    {
      "epoch": 7.43,
      "grad_norm": 1.3175127506256104,
      "learning_rate": 4.642275632506942e-06,
      "loss": 0.3698,
      "step": 15840
    },
    {
      "epoch": 7.43,
      "grad_norm": 2.0065441131591797,
      "learning_rate": 4.626306768169882e-06,
      "loss": 0.316,
      "step": 15850
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.5156954526901245,
      "learning_rate": 4.610360407399525e-06,
      "loss": 0.2907,
      "step": 15860
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.5000196695327759,
      "learning_rate": 4.594436584788165e-06,
      "loss": 0.3379,
      "step": 15870
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.5331426858901978,
      "learning_rate": 4.578535334879233e-06,
      "loss": 0.3296,
      "step": 15880
    },
    {
      "epoch": 7.45,
      "grad_norm": 1.4910492897033691,
      "learning_rate": 4.562656692167172e-06,
      "loss": 0.3254,
      "step": 15890
    },
    {
      "epoch": 7.45,
      "grad_norm": 2.243706226348877,
      "learning_rate": 4.546800691097392e-06,
      "loss": 0.2838,
      "step": 15900
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.678127408027649,
      "learning_rate": 4.530967366066184e-06,
      "loss": 0.3599,
      "step": 15910
    },
    {
      "epoch": 7.46,
      "grad_norm": 2.109747886657715,
      "learning_rate": 4.5151567514206475e-06,
      "loss": 0.3439,
      "step": 15920
    },
    {
      "epoch": 7.47,
      "grad_norm": 2.6112427711486816,
      "learning_rate": 4.4993688814586215e-06,
      "loss": 0.317,
      "step": 15930
    },
    {
      "epoch": 7.47,
      "grad_norm": 1.2831987142562866,
      "learning_rate": 4.483603790428596e-06,
      "loss": 0.3348,
      "step": 15940
    },
    {
      "epoch": 7.48,
      "grad_norm": 1.6951905488967896,
      "learning_rate": 4.467861512529657e-06,
      "loss": 0.3343,
      "step": 15950
    },
    {
      "epoch": 7.48,
      "grad_norm": 1.6618471145629883,
      "learning_rate": 4.452142081911389e-06,
      "loss": 0.371,
      "step": 15960
    },
    {
      "epoch": 7.49,
      "grad_norm": 2.011218786239624,
      "learning_rate": 4.436445532673838e-06,
      "loss": 0.308,
      "step": 15970
    },
    {
      "epoch": 7.49,
      "grad_norm": 2.091780185699463,
      "learning_rate": 4.420771898867388e-06,
      "loss": 0.3478,
      "step": 15980
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.7361385822296143,
      "learning_rate": 4.4051212144927195e-06,
      "loss": 0.3289,
      "step": 15990
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.4523420333862305,
      "learning_rate": 4.389493513500733e-06,
      "loss": 0.3327,
      "step": 16000
    },
    {
      "epoch": 7.51,
      "grad_norm": 1.5753782987594604,
      "learning_rate": 4.37388882979248e-06,
      "loss": 0.3195,
      "step": 16010
    },
    {
      "epoch": 7.51,
      "grad_norm": 2.320683002471924,
      "learning_rate": 4.358307197219064e-06,
      "loss": 0.3178,
      "step": 16020
    },
    {
      "epoch": 7.52,
      "grad_norm": 2.088200807571411,
      "learning_rate": 4.3427486495816e-06,
      "loss": 0.2776,
      "step": 16030
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.545135259628296,
      "learning_rate": 4.327213220631098e-06,
      "loss": 0.3265,
      "step": 16040
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.840996265411377,
      "learning_rate": 4.311700944068451e-06,
      "loss": 0.299,
      "step": 16050
    },
    {
      "epoch": 7.53,
      "grad_norm": 1.884430170059204,
      "learning_rate": 4.296211853544309e-06,
      "loss": 0.2993,
      "step": 16060
    },
    {
      "epoch": 7.53,
      "grad_norm": 1.8887977600097656,
      "learning_rate": 4.280745982659025e-06,
      "loss": 0.3493,
      "step": 16070
    },
    {
      "epoch": 7.54,
      "grad_norm": 1.4991577863693237,
      "learning_rate": 4.265303364962587e-06,
      "loss": 0.3738,
      "step": 16080
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.712185859680176,
      "learning_rate": 4.2498840339545356e-06,
      "loss": 0.3124,
      "step": 16090
    },
    {
      "epoch": 7.55,
      "grad_norm": 1.329656720161438,
      "learning_rate": 4.234488023083898e-06,
      "loss": 0.3282,
      "step": 16100
    },
    {
      "epoch": 7.55,
      "grad_norm": 2.0047993659973145,
      "learning_rate": 4.219115365749112e-06,
      "loss": 0.3037,
      "step": 16110
    },
    {
      "epoch": 7.56,
      "grad_norm": 1.332309603691101,
      "learning_rate": 4.203766095297958e-06,
      "loss": 0.3204,
      "step": 16120
    },
    {
      "epoch": 7.56,
      "grad_norm": 2.5457065105438232,
      "learning_rate": 4.188440245027473e-06,
      "loss": 0.3046,
      "step": 16130
    },
    {
      "epoch": 7.57,
      "grad_norm": 1.7243729829788208,
      "learning_rate": 4.173137848183911e-06,
      "loss": 0.3068,
      "step": 16140
    },
    {
      "epoch": 7.57,
      "grad_norm": 1.5241330862045288,
      "learning_rate": 4.157858937962631e-06,
      "loss": 0.302,
      "step": 16150
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.7246021032333374,
      "learning_rate": 4.142603547508036e-06,
      "loss": 0.3165,
      "step": 16160
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.233159065246582,
      "learning_rate": 4.127371709913523e-06,
      "loss": 0.3665,
      "step": 16170
    },
    {
      "epoch": 7.59,
      "grad_norm": 1.7036696672439575,
      "learning_rate": 4.112163458221395e-06,
      "loss": 0.3507,
      "step": 16180
    },
    {
      "epoch": 7.59,
      "grad_norm": 1.3274853229522705,
      "learning_rate": 4.096978825422785e-06,
      "loss": 0.3198,
      "step": 16190
    },
    {
      "epoch": 7.59,
      "grad_norm": 1.5267993211746216,
      "learning_rate": 4.081817844457589e-06,
      "loss": 0.3139,
      "step": 16200
    },
    {
      "epoch": 7.6,
      "grad_norm": 2.1747703552246094,
      "learning_rate": 4.066680548214397e-06,
      "loss": 0.2889,
      "step": 16210
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.575568675994873,
      "learning_rate": 4.051566969530423e-06,
      "loss": 0.3104,
      "step": 16220
    },
    {
      "epoch": 7.61,
      "grad_norm": 1.5457046031951904,
      "learning_rate": 4.036477141191426e-06,
      "loss": 0.3342,
      "step": 16230
    },
    {
      "epoch": 7.61,
      "grad_norm": 1.7282098531723022,
      "learning_rate": 4.021411095931645e-06,
      "loss": 0.365,
      "step": 16240
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.9486362934112549,
      "learning_rate": 4.006368866433728e-06,
      "loss": 0.3322,
      "step": 16250
    },
    {
      "epoch": 7.62,
      "grad_norm": 2.1144895553588867,
      "learning_rate": 3.991350485328653e-06,
      "loss": 0.3449,
      "step": 16260
    },
    {
      "epoch": 7.63,
      "grad_norm": 1.3364732265472412,
      "learning_rate": 3.9763559851956846e-06,
      "loss": 0.3135,
      "step": 16270
    },
    {
      "epoch": 7.63,
      "grad_norm": 1.256588339805603,
      "learning_rate": 3.961385398562254e-06,
      "loss": 0.3186,
      "step": 16280
    },
    {
      "epoch": 7.64,
      "grad_norm": 1.51736319065094,
      "learning_rate": 3.946438757903934e-06,
      "loss": 0.3828,
      "step": 16290
    },
    {
      "epoch": 7.64,
      "grad_norm": 2.066528081893921,
      "learning_rate": 3.931516095644344e-06,
      "loss": 0.3143,
      "step": 16300
    },
    {
      "epoch": 7.65,
      "grad_norm": 1.1655539274215698,
      "learning_rate": 3.916617444155101e-06,
      "loss": 0.3269,
      "step": 16310
    },
    {
      "epoch": 7.65,
      "grad_norm": 1.8237545490264893,
      "learning_rate": 3.901742835755725e-06,
      "loss": 0.3594,
      "step": 16320
    },
    {
      "epoch": 7.66,
      "grad_norm": 1.238259196281433,
      "learning_rate": 3.886892302713575e-06,
      "loss": 0.3299,
      "step": 16330
    },
    {
      "epoch": 7.66,
      "grad_norm": 1.302106261253357,
      "learning_rate": 3.872065877243783e-06,
      "loss": 0.3252,
      "step": 16340
    },
    {
      "epoch": 7.67,
      "grad_norm": 1.5368534326553345,
      "learning_rate": 3.857263591509207e-06,
      "loss": 0.3426,
      "step": 16350
    },
    {
      "epoch": 7.67,
      "grad_norm": 1.6053187847137451,
      "learning_rate": 3.8424854776203125e-06,
      "loss": 0.3258,
      "step": 16360
    },
    {
      "epoch": 7.67,
      "grad_norm": 1.8420498371124268,
      "learning_rate": 3.827731567635142e-06,
      "loss": 0.3324,
      "step": 16370
    },
    {
      "epoch": 7.68,
      "grad_norm": 1.9107487201690674,
      "learning_rate": 3.8130018935592308e-06,
      "loss": 0.3329,
      "step": 16380
    },
    {
      "epoch": 7.68,
      "grad_norm": 1.3826324939727783,
      "learning_rate": 3.798296487345538e-06,
      "loss": 0.3459,
      "step": 16390
    },
    {
      "epoch": 7.69,
      "grad_norm": 1.6678677797317505,
      "learning_rate": 3.783615380894377e-06,
      "loss": 0.3184,
      "step": 16400
    },
    {
      "epoch": 7.69,
      "grad_norm": 1.2337926626205444,
      "learning_rate": 3.7689586060533527e-06,
      "loss": 0.3228,
      "step": 16410
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.6464251279830933,
      "learning_rate": 3.754326194617285e-06,
      "loss": 0.2898,
      "step": 16420
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.740859031677246,
      "learning_rate": 3.7397181783281385e-06,
      "loss": 0.3324,
      "step": 16430
    },
    {
      "epoch": 7.71,
      "grad_norm": 2.4617626667022705,
      "learning_rate": 3.7251345888749743e-06,
      "loss": 0.3083,
      "step": 16440
    },
    {
      "epoch": 7.71,
      "grad_norm": 1.506691575050354,
      "learning_rate": 3.7105754578938395e-06,
      "loss": 0.2627,
      "step": 16450
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.9527742862701416,
      "learning_rate": 3.69604081696774e-06,
      "loss": 0.3016,
      "step": 16460
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.3262816667556763,
      "learning_rate": 3.6815306976265466e-06,
      "loss": 0.3405,
      "step": 16470
    },
    {
      "epoch": 7.73,
      "grad_norm": 1.6864577531814575,
      "learning_rate": 3.667045131346952e-06,
      "loss": 0.3163,
      "step": 16480
    },
    {
      "epoch": 7.73,
      "grad_norm": 1.6104532480239868,
      "learning_rate": 3.652584149552369e-06,
      "loss": 0.3438,
      "step": 16490
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.305696964263916,
      "learning_rate": 3.638147783612888e-06,
      "loss": 0.3229,
      "step": 16500
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.9346752166748047,
      "learning_rate": 3.623736064845189e-06,
      "loss": 0.3488,
      "step": 16510
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.5581023693084717,
      "learning_rate": 3.6093490245125056e-06,
      "loss": 0.3026,
      "step": 16520
    },
    {
      "epoch": 7.75,
      "grad_norm": 1.3685014247894287,
      "learning_rate": 3.594986693824519e-06,
      "loss": 0.3279,
      "step": 16530
    },
    {
      "epoch": 7.75,
      "grad_norm": 1.0109155178070068,
      "learning_rate": 3.580649103937314e-06,
      "loss": 0.3269,
      "step": 16540
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.7673070430755615,
      "learning_rate": 3.566336285953308e-06,
      "loss": 0.3176,
      "step": 16550
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.677860975265503,
      "learning_rate": 3.552048270921177e-06,
      "loss": 0.299,
      "step": 16560
    },
    {
      "epoch": 7.77,
      "grad_norm": 1.6441409587860107,
      "learning_rate": 3.537785089835794e-06,
      "loss": 0.3319,
      "step": 16570
    },
    {
      "epoch": 7.77,
      "grad_norm": 1.6309763193130493,
      "learning_rate": 3.5235467736381576e-06,
      "loss": 0.3046,
      "step": 16580
    },
    {
      "epoch": 7.78,
      "grad_norm": 2.536569356918335,
      "learning_rate": 3.5093333532153316e-06,
      "loss": 0.3143,
      "step": 16590
    },
    {
      "epoch": 7.78,
      "grad_norm": 1.7746330499649048,
      "learning_rate": 3.495144859400365e-06,
      "loss": 0.3397,
      "step": 16600
    },
    {
      "epoch": 7.79,
      "grad_norm": 1.4839527606964111,
      "learning_rate": 3.4809813229722486e-06,
      "loss": 0.3238,
      "step": 16610
    },
    {
      "epoch": 7.79,
      "grad_norm": 2.109309673309326,
      "learning_rate": 3.4668427746558258e-06,
      "loss": 0.326,
      "step": 16620
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.5278531312942505,
      "learning_rate": 3.4527292451217217e-06,
      "loss": 0.3498,
      "step": 16630
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.8158262968063354,
      "learning_rate": 3.4386407649863e-06,
      "loss": 0.2908,
      "step": 16640
    },
    {
      "epoch": 7.81,
      "grad_norm": 1.4521348476409912,
      "learning_rate": 3.424577364811593e-06,
      "loss": 0.3581,
      "step": 16650
    },
    {
      "epoch": 7.81,
      "grad_norm": 1.5936602354049683,
      "learning_rate": 3.4105390751052123e-06,
      "loss": 0.3454,
      "step": 16660
    },
    {
      "epoch": 7.82,
      "grad_norm": 1.6272989511489868,
      "learning_rate": 3.3965259263203032e-06,
      "loss": 0.3197,
      "step": 16670
    },
    {
      "epoch": 7.82,
      "grad_norm": 1.5921270847320557,
      "learning_rate": 3.382537948855475e-06,
      "loss": 0.3169,
      "step": 16680
    },
    {
      "epoch": 7.82,
      "grad_norm": 1.7788339853286743,
      "learning_rate": 3.36857517305473e-06,
      "loss": 0.3218,
      "step": 16690
    },
    {
      "epoch": 7.83,
      "grad_norm": 1.4211223125457764,
      "learning_rate": 3.354637629207403e-06,
      "loss": 0.3488,
      "step": 16700
    },
    {
      "epoch": 7.83,
      "grad_norm": 2.1988534927368164,
      "learning_rate": 3.3407253475480902e-06,
      "loss": 0.2943,
      "step": 16710
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.4430389404296875,
      "learning_rate": 3.3268383582565897e-06,
      "loss": 0.2985,
      "step": 16720
    },
    {
      "epoch": 7.84,
      "grad_norm": 2.346165895462036,
      "learning_rate": 3.3129766914578337e-06,
      "loss": 0.3524,
      "step": 16730
    },
    {
      "epoch": 7.85,
      "grad_norm": 1.6181985139846802,
      "learning_rate": 3.29914037722182e-06,
      "loss": 0.3244,
      "step": 16740
    },
    {
      "epoch": 7.85,
      "grad_norm": 1.5089515447616577,
      "learning_rate": 3.285329445563549e-06,
      "loss": 0.278,
      "step": 16750
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.4070364236831665,
      "learning_rate": 3.2715439264429625e-06,
      "loss": 0.3038,
      "step": 16760
    },
    {
      "epoch": 7.86,
      "grad_norm": 2.1958935260772705,
      "learning_rate": 3.257783849764872e-06,
      "loss": 0.3433,
      "step": 16770
    },
    {
      "epoch": 7.87,
      "grad_norm": 1.743177890777588,
      "learning_rate": 3.2440492453788922e-06,
      "loss": 0.3052,
      "step": 16780
    },
    {
      "epoch": 7.87,
      "grad_norm": 1.1703625917434692,
      "learning_rate": 3.2303401430794e-06,
      "loss": 0.3436,
      "step": 16790
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.4432146549224854,
      "learning_rate": 3.2166565726054266e-06,
      "loss": 0.3214,
      "step": 16800
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.7252204418182373,
      "learning_rate": 3.202998563640629e-06,
      "loss": 0.3277,
      "step": 16810
    },
    {
      "epoch": 7.89,
      "grad_norm": 2.203158378601074,
      "learning_rate": 3.1893661458132107e-06,
      "loss": 0.3157,
      "step": 16820
    },
    {
      "epoch": 7.89,
      "grad_norm": 1.498030185699463,
      "learning_rate": 3.175759348695869e-06,
      "loss": 0.3051,
      "step": 16830
    },
    {
      "epoch": 7.89,
      "grad_norm": 1.4277218580245972,
      "learning_rate": 3.162178201805715e-06,
      "loss": 0.3298,
      "step": 16840
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.4184883832931519,
      "learning_rate": 3.1486227346042148e-06,
      "loss": 0.3166,
      "step": 16850
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.5478678941726685,
      "learning_rate": 3.1350929764971344e-06,
      "loss": 0.3237,
      "step": 16860
    },
    {
      "epoch": 7.91,
      "grad_norm": 1.4958261251449585,
      "learning_rate": 3.1215889568344614e-06,
      "loss": 0.3219,
      "step": 16870
    },
    {
      "epoch": 7.91,
      "grad_norm": 2.375513792037964,
      "learning_rate": 3.1081107049103578e-06,
      "loss": 0.3343,
      "step": 16880
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.8753769397735596,
      "learning_rate": 3.094658249963081e-06,
      "loss": 0.3201,
      "step": 16890
    },
    {
      "epoch": 7.92,
      "grad_norm": 2.103062152862549,
      "learning_rate": 3.081231621174932e-06,
      "loss": 0.3114,
      "step": 16900
    },
    {
      "epoch": 7.93,
      "grad_norm": 2.2600388526916504,
      "learning_rate": 3.067830847672184e-06,
      "loss": 0.318,
      "step": 16910
    },
    {
      "epoch": 7.93,
      "grad_norm": 2.0109872817993164,
      "learning_rate": 3.054455958525023e-06,
      "loss": 0.3667,
      "step": 16920
    },
    {
      "epoch": 7.94,
      "grad_norm": 1.2404766082763672,
      "learning_rate": 3.0411069827474876e-06,
      "loss": 0.3266,
      "step": 16930
    },
    {
      "epoch": 7.94,
      "grad_norm": 2.4038987159729004,
      "learning_rate": 3.027783949297398e-06,
      "loss": 0.3536,
      "step": 16940
    },
    {
      "epoch": 7.95,
      "grad_norm": 1.66965651512146,
      "learning_rate": 3.0144868870762974e-06,
      "loss": 0.3359,
      "step": 16950
    },
    {
      "epoch": 7.95,
      "grad_norm": 1.4006129503250122,
      "learning_rate": 3.001215824929401e-06,
      "loss": 0.2877,
      "step": 16960
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.7209553718566895,
      "learning_rate": 2.9879707916455124e-06,
      "loss": 0.358,
      "step": 16970
    },
    {
      "epoch": 7.96,
      "grad_norm": 2.2363057136535645,
      "learning_rate": 2.9747518159569635e-06,
      "loss": 0.3164,
      "step": 16980
    },
    {
      "epoch": 7.97,
      "grad_norm": 1.4543683528900146,
      "learning_rate": 2.961558926539573e-06,
      "loss": 0.358,
      "step": 16990
    },
    {
      "epoch": 7.97,
      "grad_norm": 1.8395897150039673,
      "learning_rate": 2.948392152012571e-06,
      "loss": 0.3035,
      "step": 17000
    },
    {
      "epoch": 7.97,
      "grad_norm": 1.7180424928665161,
      "learning_rate": 2.935251520938528e-06,
      "loss": 0.3595,
      "step": 17010
    },
    {
      "epoch": 7.98,
      "grad_norm": 2.194230318069458,
      "learning_rate": 2.922137061823309e-06,
      "loss": 0.296,
      "step": 17020
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.2911690473556519,
      "learning_rate": 2.909048803115998e-06,
      "loss": 0.3265,
      "step": 17030
    },
    {
      "epoch": 7.99,
      "grad_norm": 1.898347020149231,
      "learning_rate": 2.8959867732088483e-06,
      "loss": 0.3121,
      "step": 17040
    },
    {
      "epoch": 7.99,
      "grad_norm": 2.124861717224121,
      "learning_rate": 2.8829510004372116e-06,
      "loss": 0.3151,
      "step": 17050
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.504733920097351,
      "learning_rate": 2.869941513079484e-06,
      "loss": 0.3423,
      "step": 17060
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.3350560665130615,
      "learning_rate": 2.8569583393570346e-06,
      "loss": 0.3359,
      "step": 17070
    },
    {
      "epoch": 8.01,
      "grad_norm": 1.3726205825805664,
      "learning_rate": 2.8440015074341542e-06,
      "loss": 0.3414,
      "step": 17080
    },
    {
      "epoch": 8.01,
      "grad_norm": 1.1257563829421997,
      "learning_rate": 2.8310710454180016e-06,
      "loss": 0.3085,
      "step": 17090
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.446595549583435,
      "learning_rate": 2.8181669813585083e-06,
      "loss": 0.3064,
      "step": 17100
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.3321574926376343,
      "learning_rate": 2.8052893432483586e-06,
      "loss": 0.3035,
      "step": 17110
    },
    {
      "epoch": 8.03,
      "grad_norm": 2.144157648086548,
      "learning_rate": 2.7924381590228997e-06,
      "loss": 0.3255,
      "step": 17120
    },
    {
      "epoch": 8.03,
      "grad_norm": 1.5897544622421265,
      "learning_rate": 2.7796134565601087e-06,
      "loss": 0.2974,
      "step": 17130
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.5112240314483643,
      "learning_rate": 2.7668152636805032e-06,
      "loss": 0.2755,
      "step": 17140
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.7014057636260986,
      "learning_rate": 2.7540436081471e-06,
      "loss": 0.3492,
      "step": 17150
    },
    {
      "epoch": 8.05,
      "grad_norm": 2.5061726570129395,
      "learning_rate": 2.7412985176653333e-06,
      "loss": 0.3503,
      "step": 17160
    },
    {
      "epoch": 8.05,
      "grad_norm": 1.691626787185669,
      "learning_rate": 2.728580019883034e-06,
      "loss": 0.3324,
      "step": 17170
    },
    {
      "epoch": 8.05,
      "grad_norm": 1.7357773780822754,
      "learning_rate": 2.7158881423903294e-06,
      "loss": 0.2827,
      "step": 17180
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.205483317375183,
      "learning_rate": 2.7032229127196052e-06,
      "loss": 0.2956,
      "step": 17190
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.5431642532348633,
      "learning_rate": 2.6905843583454394e-06,
      "loss": 0.3405,
      "step": 17200
    },
    {
      "epoch": 8.07,
      "grad_norm": 2.069188117980957,
      "learning_rate": 2.6779725066845424e-06,
      "loss": 0.3126,
      "step": 17210
    },
    {
      "epoch": 8.07,
      "grad_norm": 2.7124733924865723,
      "learning_rate": 2.665387385095698e-06,
      "loss": 0.3296,
      "step": 17220
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.7008717060089111,
      "learning_rate": 2.652829020879709e-06,
      "loss": 0.2971,
      "step": 17230
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.4908889532089233,
      "learning_rate": 2.640297441279329e-06,
      "loss": 0.3319,
      "step": 17240
    },
    {
      "epoch": 8.09,
      "grad_norm": 1.6407239437103271,
      "learning_rate": 2.6277926734792056e-06,
      "loss": 0.2886,
      "step": 17250
    },
    {
      "epoch": 8.09,
      "grad_norm": 1.4452245235443115,
      "learning_rate": 2.615314744605842e-06,
      "loss": 0.3279,
      "step": 17260
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.6302555799484253,
      "learning_rate": 2.60286368172749e-06,
      "loss": 0.3552,
      "step": 17270
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.406834602355957,
      "learning_rate": 2.590439511854144e-06,
      "loss": 0.3542,
      "step": 17280
    },
    {
      "epoch": 8.11,
      "grad_norm": 1.77499520778656,
      "learning_rate": 2.5780422619374487e-06,
      "loss": 0.3176,
      "step": 17290
    },
    {
      "epoch": 8.11,
      "grad_norm": 1.4945050477981567,
      "learning_rate": 2.5656719588706618e-06,
      "loss": 0.3353,
      "step": 17300
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.5376191139221191,
      "learning_rate": 2.5533286294885772e-06,
      "loss": 0.3261,
      "step": 17310
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.3158257007598877,
      "learning_rate": 2.541012300567478e-06,
      "loss": 0.2775,
      "step": 17320
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.0862280130386353,
      "learning_rate": 2.5287229988250654e-06,
      "loss": 0.3157,
      "step": 17330
    },
    {
      "epoch": 8.13,
      "grad_norm": 1.8269718885421753,
      "learning_rate": 2.5164607509204297e-06,
      "loss": 0.3388,
      "step": 17340
    },
    {
      "epoch": 8.13,
      "grad_norm": 1.8474218845367432,
      "learning_rate": 2.5042255834539608e-06,
      "loss": 0.3217,
      "step": 17350
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.917134165763855,
      "learning_rate": 2.492017522967306e-06,
      "loss": 0.3095,
      "step": 17360
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.5525524616241455,
      "learning_rate": 2.4798365959433095e-06,
      "loss": 0.2845,
      "step": 17370
    },
    {
      "epoch": 8.15,
      "grad_norm": 1.463405728340149,
      "learning_rate": 2.467682828805956e-06,
      "loss": 0.3195,
      "step": 17380
    },
    {
      "epoch": 8.15,
      "grad_norm": 1.9013714790344238,
      "learning_rate": 2.4555562479203094e-06,
      "loss": 0.298,
      "step": 17390
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.5719759464263916,
      "learning_rate": 2.4434568795924626e-06,
      "loss": 0.3062,
      "step": 17400
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.2499383687973022,
      "learning_rate": 2.4313847500694746e-06,
      "loss": 0.3291,
      "step": 17410
    },
    {
      "epoch": 8.17,
      "grad_norm": 1.6939549446105957,
      "learning_rate": 2.4193398855393135e-06,
      "loss": 0.3294,
      "step": 17420
    },
    {
      "epoch": 8.17,
      "grad_norm": 1.3630610704421997,
      "learning_rate": 2.4073223121308097e-06,
      "loss": 0.3136,
      "step": 17430
    },
    {
      "epoch": 8.18,
      "grad_norm": 2.171877384185791,
      "learning_rate": 2.3953320559135865e-06,
      "loss": 0.2957,
      "step": 17440
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.6344339847564697,
      "learning_rate": 2.3833691428979998e-06,
      "loss": 0.3222,
      "step": 17450
    },
    {
      "epoch": 8.19,
      "grad_norm": 1.935997486114502,
      "learning_rate": 2.371433599035097e-06,
      "loss": 0.3731,
      "step": 17460
    },
    {
      "epoch": 8.19,
      "grad_norm": 1.4010651111602783,
      "learning_rate": 2.3595254502165624e-06,
      "loss": 0.2924,
      "step": 17470
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.1126081943511963,
      "learning_rate": 2.3476447222746407e-06,
      "loss": 0.3226,
      "step": 17480
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.2660415172576904,
      "learning_rate": 2.335791440982097e-06,
      "loss": 0.3024,
      "step": 17490
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.5485835075378418,
      "learning_rate": 2.3239656320521547e-06,
      "loss": 0.309,
      "step": 17500
    },
    {
      "epoch": 8.21,
      "grad_norm": 1.408374309539795,
      "learning_rate": 2.3121673211384446e-06,
      "loss": 0.3196,
      "step": 17510
    },
    {
      "epoch": 8.21,
      "grad_norm": 1.9303339719772339,
      "learning_rate": 2.3003965338349425e-06,
      "loss": 0.3013,
      "step": 17520
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.5205501317977905,
      "learning_rate": 2.2886532956759224e-06,
      "loss": 0.2939,
      "step": 17530
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.6391618251800537,
      "learning_rate": 2.2769376321358928e-06,
      "loss": 0.3247,
      "step": 17540
    },
    {
      "epoch": 8.23,
      "grad_norm": 1.2934130430221558,
      "learning_rate": 2.265249568629539e-06,
      "loss": 0.341,
      "step": 17550
    },
    {
      "epoch": 8.23,
      "grad_norm": 2.2177560329437256,
      "learning_rate": 2.2535891305116944e-06,
      "loss": 0.3057,
      "step": 17560
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.4847098588943481,
      "learning_rate": 2.2419563430772393e-06,
      "loss": 0.3121,
      "step": 17570
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.4685167074203491,
      "learning_rate": 2.230351231561086e-06,
      "loss": 0.3069,
      "step": 17580
    },
    {
      "epoch": 8.25,
      "grad_norm": 2.0968284606933594,
      "learning_rate": 2.2187738211381024e-06,
      "loss": 0.2964,
      "step": 17590
    },
    {
      "epoch": 8.25,
      "grad_norm": 1.588848352432251,
      "learning_rate": 2.2072241369230784e-06,
      "loss": 0.3158,
      "step": 17600
    },
    {
      "epoch": 8.26,
      "grad_norm": 2.1378605365753174,
      "learning_rate": 2.195702203970645e-06,
      "loss": 0.3447,
      "step": 17610
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.2963817119598389,
      "learning_rate": 2.1842080472752318e-06,
      "loss": 0.3139,
      "step": 17620
    },
    {
      "epoch": 8.27,
      "grad_norm": 1.9787318706512451,
      "learning_rate": 2.1727416917710157e-06,
      "loss": 0.3189,
      "step": 17630
    },
    {
      "epoch": 8.27,
      "grad_norm": 1.9858626127243042,
      "learning_rate": 2.1613031623318736e-06,
      "loss": 0.3372,
      "step": 17640
    },
    {
      "epoch": 8.27,
      "grad_norm": 1.909928321838379,
      "learning_rate": 2.1498924837713098e-06,
      "loss": 0.2925,
      "step": 17650
    },
    {
      "epoch": 8.28,
      "grad_norm": 2.96614933013916,
      "learning_rate": 2.1385096808424152e-06,
      "loss": 0.3475,
      "step": 17660
    },
    {
      "epoch": 8.28,
      "grad_norm": 1.355710506439209,
      "learning_rate": 2.127154778237807e-06,
      "loss": 0.307,
      "step": 17670
    },
    {
      "epoch": 8.29,
      "grad_norm": 1.5048704147338867,
      "learning_rate": 2.115827800589586e-06,
      "loss": 0.2884,
      "step": 17680
    },
    {
      "epoch": 8.29,
      "grad_norm": 1.3660224676132202,
      "learning_rate": 2.1045287724692653e-06,
      "loss": 0.2797,
      "step": 17690
    },
    {
      "epoch": 8.3,
      "grad_norm": 2.055779457092285,
      "learning_rate": 2.0932577183877383e-06,
      "loss": 0.3154,
      "step": 17700
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.9579949378967285,
      "learning_rate": 2.0820146627952053e-06,
      "loss": 0.3051,
      "step": 17710
    },
    {
      "epoch": 8.31,
      "grad_norm": 1.856926679611206,
      "learning_rate": 2.0707996300811316e-06,
      "loss": 0.3084,
      "step": 17720
    },
    {
      "epoch": 8.31,
      "grad_norm": 1.192621111869812,
      "learning_rate": 2.0596126445742048e-06,
      "loss": 0.3349,
      "step": 17730
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.6724623441696167,
      "learning_rate": 2.048453730542249e-06,
      "loss": 0.338,
      "step": 17740
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.8838615417480469,
      "learning_rate": 2.0373229121922075e-06,
      "loss": 0.3368,
      "step": 17750
    },
    {
      "epoch": 8.33,
      "grad_norm": 1.8338743448257446,
      "learning_rate": 2.0262202136700693e-06,
      "loss": 0.3175,
      "step": 17760
    },
    {
      "epoch": 8.33,
      "grad_norm": 1.520235300064087,
      "learning_rate": 2.015145659060834e-06,
      "loss": 0.3322,
      "step": 17770
    },
    {
      "epoch": 8.34,
      "grad_norm": 2.2116105556488037,
      "learning_rate": 2.0040992723884357e-06,
      "loss": 0.3582,
      "step": 17780
    },
    {
      "epoch": 8.34,
      "grad_norm": 1.1117308139801025,
      "learning_rate": 1.9930810776157132e-06,
      "loss": 0.3109,
      "step": 17790
    },
    {
      "epoch": 8.35,
      "grad_norm": 1.1796772480010986,
      "learning_rate": 1.9820910986443364e-06,
      "loss": 0.3025,
      "step": 17800
    },
    {
      "epoch": 8.35,
      "grad_norm": 1.326995611190796,
      "learning_rate": 1.971129359314783e-06,
      "loss": 0.32,
      "step": 17810
    },
    {
      "epoch": 8.35,
      "grad_norm": 1.6543904542922974,
      "learning_rate": 1.9601958834062627e-06,
      "loss": 0.3225,
      "step": 17820
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.5118730068206787,
      "learning_rate": 1.9492906946366724e-06,
      "loss": 0.3337,
      "step": 17830
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.90903639793396,
      "learning_rate": 1.938413816662548e-06,
      "loss": 0.3076,
      "step": 17840
    },
    {
      "epoch": 8.37,
      "grad_norm": 1.418880820274353,
      "learning_rate": 1.927565273079011e-06,
      "loss": 0.3142,
      "step": 17850
    },
    {
      "epoch": 8.37,
      "grad_norm": 1.2509586811065674,
      "learning_rate": 1.9167450874197162e-06,
      "loss": 0.32,
      "step": 17860
    },
    {
      "epoch": 8.38,
      "grad_norm": 2.446425199508667,
      "learning_rate": 1.9059532831568043e-06,
      "loss": 0.3481,
      "step": 17870
    },
    {
      "epoch": 8.38,
      "grad_norm": 1.907065987586975,
      "learning_rate": 1.895189883700844e-06,
      "loss": 0.3109,
      "step": 17880
    },
    {
      "epoch": 8.39,
      "grad_norm": 1.3729603290557861,
      "learning_rate": 1.884454912400788e-06,
      "loss": 0.3212,
      "step": 17890
    },
    {
      "epoch": 8.39,
      "grad_norm": 1.9924094676971436,
      "learning_rate": 1.873748392543927e-06,
      "loss": 0.3454,
      "step": 17900
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.8832132816314697,
      "learning_rate": 1.8630703473558236e-06,
      "loss": 0.3368,
      "step": 17910
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.2721530199050903,
      "learning_rate": 1.8524208000002673e-06,
      "loss": 0.3182,
      "step": 17920
    },
    {
      "epoch": 8.41,
      "grad_norm": 1.8401316404342651,
      "learning_rate": 1.8417997735792335e-06,
      "loss": 0.3202,
      "step": 17930
    },
    {
      "epoch": 8.41,
      "grad_norm": 1.5921872854232788,
      "learning_rate": 1.831207291132832e-06,
      "loss": 0.2694,
      "step": 17940
    },
    {
      "epoch": 8.42,
      "grad_norm": 2.106389284133911,
      "learning_rate": 1.8206433756392438e-06,
      "loss": 0.3022,
      "step": 17950
    },
    {
      "epoch": 8.42,
      "grad_norm": 2.2028486728668213,
      "learning_rate": 1.8101080500146844e-06,
      "loss": 0.3369,
      "step": 17960
    },
    {
      "epoch": 8.42,
      "grad_norm": 2.1799943447113037,
      "learning_rate": 1.7996013371133474e-06,
      "loss": 0.366,
      "step": 17970
    },
    {
      "epoch": 8.43,
      "grad_norm": 1.7052429914474487,
      "learning_rate": 1.7891232597273594e-06,
      "loss": 0.3215,
      "step": 17980
    },
    {
      "epoch": 8.43,
      "grad_norm": 1.369848608970642,
      "learning_rate": 1.7786738405867247e-06,
      "loss": 0.3055,
      "step": 17990
    },
    {
      "epoch": 8.44,
      "grad_norm": 2.364032030105591,
      "learning_rate": 1.7682531023592813e-06,
      "loss": 0.3186,
      "step": 18000
    },
    {
      "epoch": 8.44,
      "grad_norm": 2.366999387741089,
      "learning_rate": 1.7578610676506529e-06,
      "loss": 0.315,
      "step": 18010
    },
    {
      "epoch": 8.45,
      "grad_norm": 2.1921133995056152,
      "learning_rate": 1.7474977590041935e-06,
      "loss": 0.3123,
      "step": 18020
    },
    {
      "epoch": 8.45,
      "grad_norm": 1.3953243494033813,
      "learning_rate": 1.73716319890094e-06,
      "loss": 0.316,
      "step": 18030
    },
    {
      "epoch": 8.46,
      "grad_norm": 2.7566049098968506,
      "learning_rate": 1.7268574097595712e-06,
      "loss": 0.2948,
      "step": 18040
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.6355984210968018,
      "learning_rate": 1.716580413936349e-06,
      "loss": 0.3261,
      "step": 18050
    },
    {
      "epoch": 8.47,
      "grad_norm": 1.4609018564224243,
      "learning_rate": 1.7063322337250714e-06,
      "loss": 0.356,
      "step": 18060
    },
    {
      "epoch": 8.47,
      "grad_norm": 2.2342422008514404,
      "learning_rate": 1.6961128913570373e-06,
      "loss": 0.2913,
      "step": 18070
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.8149003982543945,
      "learning_rate": 1.6859224090009801e-06,
      "loss": 0.3107,
      "step": 18080
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.4203252792358398,
      "learning_rate": 1.6757608087630249e-06,
      "loss": 0.3302,
      "step": 18090
    },
    {
      "epoch": 8.49,
      "grad_norm": 1.8357748985290527,
      "learning_rate": 1.6656281126866457e-06,
      "loss": 0.2992,
      "step": 18100
    },
    {
      "epoch": 8.49,
      "grad_norm": 1.5142852067947388,
      "learning_rate": 1.6555243427526212e-06,
      "loss": 0.3216,
      "step": 18110
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.980062961578369,
      "learning_rate": 1.6454495208789737e-06,
      "loss": 0.3061,
      "step": 18120
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.2908337116241455,
      "learning_rate": 1.6354036689209313e-06,
      "loss": 0.3696,
      "step": 18130
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.37848699092865,
      "learning_rate": 1.6253868086708763e-06,
      "loss": 0.3732,
      "step": 18140
    },
    {
      "epoch": 8.51,
      "grad_norm": 2.038182497024536,
      "learning_rate": 1.615398961858302e-06,
      "loss": 0.2699,
      "step": 18150
    },
    {
      "epoch": 8.51,
      "grad_norm": 2.0293257236480713,
      "learning_rate": 1.6054401501497589e-06,
      "loss": 0.3416,
      "step": 18160
    },
    {
      "epoch": 8.52,
      "grad_norm": 2.2788519859313965,
      "learning_rate": 1.5955103951488177e-06,
      "loss": 0.2942,
      "step": 18170
    },
    {
      "epoch": 8.52,
      "grad_norm": 1.24116051197052,
      "learning_rate": 1.5856097183960123e-06,
      "loss": 0.329,
      "step": 18180
    },
    {
      "epoch": 8.53,
      "grad_norm": 1.5886247158050537,
      "learning_rate": 1.5757381413687943e-06,
      "loss": 0.3076,
      "step": 18190
    },
    {
      "epoch": 8.53,
      "grad_norm": 1.6737422943115234,
      "learning_rate": 1.5658956854815044e-06,
      "loss": 0.3171,
      "step": 18200
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.364396333694458,
      "learning_rate": 1.5560823720852929e-06,
      "loss": 0.3663,
      "step": 18210
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.6320773363113403,
      "learning_rate": 1.5462982224680999e-06,
      "loss": 0.3233,
      "step": 18220
    },
    {
      "epoch": 8.55,
      "grad_norm": 1.6078917980194092,
      "learning_rate": 1.5365432578545973e-06,
      "loss": 0.3416,
      "step": 18230
    },
    {
      "epoch": 8.55,
      "grad_norm": 1.8350965976715088,
      "learning_rate": 1.5268174994061546e-06,
      "loss": 0.3176,
      "step": 18240
    },
    {
      "epoch": 8.56,
      "grad_norm": 2.0151724815368652,
      "learning_rate": 1.5171209682207782e-06,
      "loss": 0.338,
      "step": 18250
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.4262750148773193,
      "learning_rate": 1.5074536853330739e-06,
      "loss": 0.2864,
      "step": 18260
    },
    {
      "epoch": 8.57,
      "grad_norm": 1.167533278465271,
      "learning_rate": 1.4978156717141899e-06,
      "loss": 0.3106,
      "step": 18270
    },
    {
      "epoch": 8.57,
      "grad_norm": 1.430443525314331,
      "learning_rate": 1.488206948271797e-06,
      "loss": 0.3101,
      "step": 18280
    },
    {
      "epoch": 8.57,
      "grad_norm": 1.4513205289840698,
      "learning_rate": 1.4786275358500178e-06,
      "loss": 0.3472,
      "step": 18290
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.8797105550765991,
      "learning_rate": 1.4690774552293917e-06,
      "loss": 0.2934,
      "step": 18300
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.582273006439209,
      "learning_rate": 1.45955672712683e-06,
      "loss": 0.3326,
      "step": 18310
    },
    {
      "epoch": 8.59,
      "grad_norm": 1.4112950563430786,
      "learning_rate": 1.4500653721955687e-06,
      "loss": 0.3371,
      "step": 18320
    },
    {
      "epoch": 8.59,
      "grad_norm": 1.9467809200286865,
      "learning_rate": 1.4406034110251243e-06,
      "loss": 0.3396,
      "step": 18330
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.7822519540786743,
      "learning_rate": 1.431170864141253e-06,
      "loss": 0.349,
      "step": 18340
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.5643845796585083,
      "learning_rate": 1.4217677520058968e-06,
      "loss": 0.3018,
      "step": 18350
    },
    {
      "epoch": 8.61,
      "grad_norm": 1.468558430671692,
      "learning_rate": 1.412394095017151e-06,
      "loss": 0.3342,
      "step": 18360
    },
    {
      "epoch": 8.61,
      "grad_norm": 2.057030439376831,
      "learning_rate": 1.4030499135092145e-06,
      "loss": 0.3289,
      "step": 18370
    },
    {
      "epoch": 8.62,
      "grad_norm": 2.0305910110473633,
      "learning_rate": 1.3937352277523413e-06,
      "loss": 0.3059,
      "step": 18380
    },
    {
      "epoch": 8.62,
      "grad_norm": 1.2915854454040527,
      "learning_rate": 1.3844500579527997e-06,
      "loss": 0.3126,
      "step": 18390
    },
    {
      "epoch": 8.63,
      "grad_norm": 2.0972208976745605,
      "learning_rate": 1.3751944242528307e-06,
      "loss": 0.3175,
      "step": 18400
    },
    {
      "epoch": 8.63,
      "grad_norm": 3.6628711223602295,
      "learning_rate": 1.365968346730609e-06,
      "loss": 0.2854,
      "step": 18410
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.4208693504333496,
      "learning_rate": 1.3567718454001842e-06,
      "loss": 0.3029,
      "step": 18420
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.426560640335083,
      "learning_rate": 1.3476049402114537e-06,
      "loss": 0.3074,
      "step": 18430
    },
    {
      "epoch": 8.65,
      "grad_norm": 1.606211543083191,
      "learning_rate": 1.338467651050102e-06,
      "loss": 0.3421,
      "step": 18440
    },
    {
      "epoch": 8.65,
      "grad_norm": 1.4619004726409912,
      "learning_rate": 1.329359997737582e-06,
      "loss": 0.3333,
      "step": 18450
    },
    {
      "epoch": 8.65,
      "grad_norm": 1.5180890560150146,
      "learning_rate": 1.3202820000310478e-06,
      "loss": 0.3253,
      "step": 18460
    },
    {
      "epoch": 8.66,
      "grad_norm": 1.6186645030975342,
      "learning_rate": 1.3112336776233236e-06,
      "loss": 0.2706,
      "step": 18470
    },
    {
      "epoch": 8.66,
      "grad_norm": 1.16437566280365,
      "learning_rate": 1.30221505014286e-06,
      "loss": 0.3026,
      "step": 18480
    },
    {
      "epoch": 8.67,
      "grad_norm": 1.7161070108413696,
      "learning_rate": 1.2932261371536935e-06,
      "loss": 0.2849,
      "step": 18490
    },
    {
      "epoch": 8.67,
      "grad_norm": 2.5337586402893066,
      "learning_rate": 1.2842669581553968e-06,
      "loss": 0.3216,
      "step": 18500
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.368432879447937,
      "learning_rate": 1.2753375325830412e-06,
      "loss": 0.2805,
      "step": 18510
    },
    {
      "epoch": 8.68,
      "grad_norm": 2.316620349884033,
      "learning_rate": 1.2664378798071573e-06,
      "loss": 0.295,
      "step": 18520
    },
    {
      "epoch": 8.69,
      "grad_norm": 1.8735599517822266,
      "learning_rate": 1.2575680191336853e-06,
      "loss": 0.2825,
      "step": 18530
    },
    {
      "epoch": 8.69,
      "grad_norm": 1.7322643995285034,
      "learning_rate": 1.248727969803945e-06,
      "loss": 0.3247,
      "step": 18540
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.6081963777542114,
      "learning_rate": 1.2399177509945835e-06,
      "loss": 0.3101,
      "step": 18550
    },
    {
      "epoch": 8.7,
      "grad_norm": 2.560267686843872,
      "learning_rate": 1.2311373818175282e-06,
      "loss": 0.3219,
      "step": 18560
    },
    {
      "epoch": 8.71,
      "grad_norm": 1.5776405334472656,
      "learning_rate": 1.2223868813199623e-06,
      "loss": 0.3134,
      "step": 18570
    },
    {
      "epoch": 8.71,
      "grad_norm": 2.2403852939605713,
      "learning_rate": 1.2136662684842802e-06,
      "loss": 0.3031,
      "step": 18580
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.8251101970672607,
      "learning_rate": 1.2049755622280295e-06,
      "loss": 0.3053,
      "step": 18590
    },
    {
      "epoch": 8.72,
      "grad_norm": 2.111882448196411,
      "learning_rate": 1.1963147814038895e-06,
      "loss": 0.345,
      "step": 18600
    },
    {
      "epoch": 8.72,
      "grad_norm": 2.0528597831726074,
      "learning_rate": 1.1876839447996197e-06,
      "loss": 0.306,
      "step": 18610
    },
    {
      "epoch": 8.73,
      "grad_norm": 1.7379671335220337,
      "learning_rate": 1.1790830711380219e-06,
      "loss": 0.3212,
      "step": 18620
    },
    {
      "epoch": 8.73,
      "grad_norm": 1.710416316986084,
      "learning_rate": 1.1705121790769014e-06,
      "loss": 0.3068,
      "step": 18630
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.3606970310211182,
      "learning_rate": 1.1619712872090204e-06,
      "loss": 0.3021,
      "step": 18640
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.2890616655349731,
      "learning_rate": 1.1534604140620687e-06,
      "loss": 0.3297,
      "step": 18650
    },
    {
      "epoch": 8.75,
      "grad_norm": 1.5390666723251343,
      "learning_rate": 1.1449795780986072e-06,
      "loss": 0.3332,
      "step": 18660
    },
    {
      "epoch": 8.75,
      "grad_norm": 1.8127968311309814,
      "learning_rate": 1.1365287977160516e-06,
      "loss": 0.3359,
      "step": 18670
    },
    {
      "epoch": 8.76,
      "grad_norm": 1.994450330734253,
      "learning_rate": 1.1281080912466025e-06,
      "loss": 0.2839,
      "step": 18680
    },
    {
      "epoch": 8.76,
      "grad_norm": 1.7085822820663452,
      "learning_rate": 1.1197174769572293e-06,
      "loss": 0.3187,
      "step": 18690
    },
    {
      "epoch": 8.77,
      "grad_norm": 1.2580949068069458,
      "learning_rate": 1.1113569730496225e-06,
      "loss": 0.3203,
      "step": 18700
    },
    {
      "epoch": 8.77,
      "grad_norm": 2.17114520072937,
      "learning_rate": 1.1030265976601579e-06,
      "loss": 0.3306,
      "step": 18710
    },
    {
      "epoch": 8.78,
      "grad_norm": 1.3571182489395142,
      "learning_rate": 1.0947263688598462e-06,
      "loss": 0.3883,
      "step": 18720
    },
    {
      "epoch": 8.78,
      "grad_norm": 1.287802815437317,
      "learning_rate": 1.086456304654307e-06,
      "loss": 0.3155,
      "step": 18730
    },
    {
      "epoch": 8.79,
      "grad_norm": 1.3697264194488525,
      "learning_rate": 1.0782164229837171e-06,
      "loss": 0.3043,
      "step": 18740
    },
    {
      "epoch": 8.79,
      "grad_norm": 1.3271814584732056,
      "learning_rate": 1.0700067417227888e-06,
      "loss": 0.3388,
      "step": 18750
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.3912361860275269,
      "learning_rate": 1.0618272786807125e-06,
      "loss": 0.3136,
      "step": 18760
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.4037551879882812,
      "learning_rate": 1.053678051601132e-06,
      "loss": 0.3192,
      "step": 18770
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.895438551902771,
      "learning_rate": 1.0455590781620954e-06,
      "loss": 0.3013,
      "step": 18780
    },
    {
      "epoch": 8.81,
      "grad_norm": 1.4496676921844482,
      "learning_rate": 1.0374703759760268e-06,
      "loss": 0.317,
      "step": 18790
    },
    {
      "epoch": 8.81,
      "grad_norm": 1.6195178031921387,
      "learning_rate": 1.0294119625896798e-06,
      "loss": 0.3432,
      "step": 18800
    },
    {
      "epoch": 8.82,
      "grad_norm": 1.3964881896972656,
      "learning_rate": 1.0213838554841027e-06,
      "loss": 0.3259,
      "step": 18810
    },
    {
      "epoch": 8.82,
      "grad_norm": 1.6558904647827148,
      "learning_rate": 1.013386072074603e-06,
      "loss": 0.3197,
      "step": 18820
    },
    {
      "epoch": 8.83,
      "grad_norm": 1.5998387336730957,
      "learning_rate": 1.0054186297107026e-06,
      "loss": 0.2848,
      "step": 18830
    },
    {
      "epoch": 8.83,
      "grad_norm": 3.7274038791656494,
      "learning_rate": 9.974815456761176e-07,
      "loss": 0.3394,
      "step": 18840
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.8993682861328125,
      "learning_rate": 9.89574837188687e-07,
      "loss": 0.2951,
      "step": 18850
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.395476222038269,
      "learning_rate": 9.816985214003754e-07,
      "loss": 0.3431,
      "step": 18860
    },
    {
      "epoch": 8.85,
      "grad_norm": 1.4450597763061523,
      "learning_rate": 9.738526153972039e-07,
      "loss": 0.315,
      "step": 18870
    },
    {
      "epoch": 8.85,
      "grad_norm": 1.3352067470550537,
      "learning_rate": 9.660371361992359e-07,
      "loss": 0.3119,
      "step": 18880
    },
    {
      "epoch": 8.86,
      "grad_norm": 1.3812642097473145,
      "learning_rate": 9.58252100760525e-07,
      "loss": 0.3088,
      "step": 18890
    },
    {
      "epoch": 8.86,
      "grad_norm": 1.4815667867660522,
      "learning_rate": 9.504975259690835e-07,
      "loss": 0.3273,
      "step": 18900
    },
    {
      "epoch": 8.87,
      "grad_norm": 1.7096039056777954,
      "learning_rate": 9.427734286468437e-07,
      "loss": 0.3241,
      "step": 18910
    },
    {
      "epoch": 8.87,
      "grad_norm": 1.5612735748291016,
      "learning_rate": 9.35079825549629e-07,
      "loss": 0.3077,
      "step": 18920
    },
    {
      "epoch": 8.87,
      "grad_norm": 1.6187483072280884,
      "learning_rate": 9.274167333671074e-07,
      "loss": 0.3125,
      "step": 18930
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.7641806602478027,
      "learning_rate": 9.197841687227615e-07,
      "loss": 0.3329,
      "step": 18940
    },
    {
      "epoch": 8.88,
      "grad_norm": 2.250582456588745,
      "learning_rate": 9.121821481738502e-07,
      "loss": 0.3285,
      "step": 18950
    },
    {
      "epoch": 8.89,
      "grad_norm": 1.8328757286071777,
      "learning_rate": 9.046106882113753e-07,
      "loss": 0.3071,
      "step": 18960
    },
    {
      "epoch": 8.89,
      "grad_norm": 1.992318034172058,
      "learning_rate": 8.970698052600401e-07,
      "loss": 0.3012,
      "step": 18970
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.9620070457458496,
      "learning_rate": 8.895595156782194e-07,
      "loss": 0.2909,
      "step": 18980
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.2502461671829224,
      "learning_rate": 8.82079835757924e-07,
      "loss": 0.3254,
      "step": 18990
    },
    {
      "epoch": 8.91,
      "grad_norm": 1.1597483158111572,
      "learning_rate": 8.746307817247568e-07,
      "loss": 0.333,
      "step": 19000
    },
    {
      "epoch": 8.91,
      "grad_norm": 1.5706638097763062,
      "learning_rate": 8.672123697378964e-07,
      "loss": 0.3382,
      "step": 19010
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.306681752204895,
      "learning_rate": 8.598246158900385e-07,
      "loss": 0.3044,
      "step": 19020
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.311143159866333,
      "learning_rate": 8.524675362073752e-07,
      "loss": 0.3341,
      "step": 19030
    },
    {
      "epoch": 8.93,
      "grad_norm": 1.5613152980804443,
      "learning_rate": 8.451411466495568e-07,
      "loss": 0.3087,
      "step": 19040
    },
    {
      "epoch": 8.93,
      "grad_norm": 1.5154832601547241,
      "learning_rate": 8.378454631096649e-07,
      "loss": 0.3147,
      "step": 19050
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.6732919216156006,
      "learning_rate": 8.305805014141631e-07,
      "loss": 0.3572,
      "step": 19060
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.354164481163025,
      "learning_rate": 8.233462773228701e-07,
      "loss": 0.2869,
      "step": 19070
    },
    {
      "epoch": 8.95,
      "grad_norm": 2.667743444442749,
      "learning_rate": 8.161428065289322e-07,
      "loss": 0.3135,
      "step": 19080
    },
    {
      "epoch": 8.95,
      "grad_norm": 1.3029868602752686,
      "learning_rate": 8.08970104658775e-07,
      "loss": 0.2906,
      "step": 19090
    },
    {
      "epoch": 8.95,
      "grad_norm": 1.8033379316329956,
      "learning_rate": 8.018281872720834e-07,
      "loss": 0.3018,
      "step": 19100
    },
    {
      "epoch": 8.96,
      "grad_norm": 2.6110429763793945,
      "learning_rate": 7.947170698617595e-07,
      "loss": 0.2927,
      "step": 19110
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.2616469860076904,
      "learning_rate": 7.876367678538904e-07,
      "loss": 0.3364,
      "step": 19120
    },
    {
      "epoch": 8.97,
      "grad_norm": 1.463496446609497,
      "learning_rate": 7.805872966077149e-07,
      "loss": 0.346,
      "step": 19130
    },
    {
      "epoch": 8.97,
      "grad_norm": 1.233661413192749,
      "learning_rate": 7.735686714155987e-07,
      "loss": 0.2707,
      "step": 19140
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.4131441116333008,
      "learning_rate": 7.665809075029812e-07,
      "loss": 0.3548,
      "step": 19150
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.573754072189331,
      "learning_rate": 7.596240200283633e-07,
      "loss": 0.2872,
      "step": 19160
    },
    {
      "epoch": 8.99,
      "grad_norm": 1.871748924255371,
      "learning_rate": 7.526980240832598e-07,
      "loss": 0.3924,
      "step": 19170
    },
    {
      "epoch": 8.99,
      "grad_norm": 1.663021445274353,
      "learning_rate": 7.458029346921808e-07,
      "loss": 0.3001,
      "step": 19180
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.96930730342865,
      "learning_rate": 7.389387668125863e-07,
      "loss": 0.3005,
      "step": 19190
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.476473093032837,
      "learning_rate": 7.321055353348571e-07,
      "loss": 0.3271,
      "step": 19200
    },
    {
      "epoch": 9.01,
      "grad_norm": 2.0119378566741943,
      "learning_rate": 7.253032550822642e-07,
      "loss": 0.2962,
      "step": 19210
    },
    {
      "epoch": 9.01,
      "grad_norm": 1.44117271900177,
      "learning_rate": 7.185319408109404e-07,
      "loss": 0.3449,
      "step": 19220
    },
    {
      "epoch": 9.02,
      "grad_norm": 1.8891832828521729,
      "learning_rate": 7.117916072098407e-07,
      "loss": 0.3224,
      "step": 19230
    },
    {
      "epoch": 9.02,
      "grad_norm": 1.1812516450881958,
      "learning_rate": 7.050822689007142e-07,
      "loss": 0.3729,
      "step": 19240
    },
    {
      "epoch": 9.02,
      "grad_norm": 1.8842110633850098,
      "learning_rate": 6.984039404380732e-07,
      "loss": 0.3427,
      "step": 19250
    },
    {
      "epoch": 9.03,
      "grad_norm": 1.9134082794189453,
      "learning_rate": 6.91756636309161e-07,
      "loss": 0.3462,
      "step": 19260
    },
    {
      "epoch": 9.03,
      "grad_norm": 1.3675445318222046,
      "learning_rate": 6.851403709339177e-07,
      "loss": 0.2878,
      "step": 19270
    },
    {
      "epoch": 9.04,
      "grad_norm": 1.499292254447937,
      "learning_rate": 6.785551586649541e-07,
      "loss": 0.3449,
      "step": 19280
    },
    {
      "epoch": 9.04,
      "grad_norm": 1.998734712600708,
      "learning_rate": 6.720010137875182e-07,
      "loss": 0.3141,
      "step": 19290
    },
    {
      "epoch": 9.05,
      "grad_norm": 1.7624672651290894,
      "learning_rate": 6.654779505194569e-07,
      "loss": 0.3257,
      "step": 19300
    },
    {
      "epoch": 9.05,
      "grad_norm": 2.1533639430999756,
      "learning_rate": 6.589859830112044e-07,
      "loss": 0.3022,
      "step": 19310
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.6399656534194946,
      "learning_rate": 6.525251253457271e-07,
      "loss": 0.2989,
      "step": 19320
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.2047299146652222,
      "learning_rate": 6.460953915385104e-07,
      "loss": 0.3413,
      "step": 19330
    },
    {
      "epoch": 9.07,
      "grad_norm": 1.923156499862671,
      "learning_rate": 6.396967955375221e-07,
      "loss": 0.3403,
      "step": 19340
    },
    {
      "epoch": 9.07,
      "grad_norm": 2.780001401901245,
      "learning_rate": 6.333293512231858e-07,
      "loss": 0.2907,
      "step": 19350
    },
    {
      "epoch": 9.08,
      "grad_norm": 1.5490505695343018,
      "learning_rate": 6.269930724083455e-07,
      "loss": 0.2754,
      "step": 19360
    },
    {
      "epoch": 9.08,
      "grad_norm": 1.9593782424926758,
      "learning_rate": 6.206879728382381e-07,
      "loss": 0.2596,
      "step": 19370
    },
    {
      "epoch": 9.09,
      "grad_norm": 1.2737574577331543,
      "learning_rate": 6.14414066190459e-07,
      "loss": 0.3741,
      "step": 19380
    },
    {
      "epoch": 9.09,
      "grad_norm": 1.5161164999008179,
      "learning_rate": 6.081713660749483e-07,
      "loss": 0.3223,
      "step": 19390
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.3190488815307617,
      "learning_rate": 6.019598860339414e-07,
      "loss": 0.28,
      "step": 19400
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.5327203273773193,
      "learning_rate": 5.957796395419484e-07,
      "loss": 0.3174,
      "step": 19410
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.4409139156341553,
      "learning_rate": 5.8963064000573e-07,
      "loss": 0.349,
      "step": 19420
    },
    {
      "epoch": 9.11,
      "grad_norm": 2.3819665908813477,
      "learning_rate": 5.835129007642576e-07,
      "loss": 0.3151,
      "step": 19430
    },
    {
      "epoch": 9.11,
      "grad_norm": 1.7724285125732422,
      "learning_rate": 5.774264350886937e-07,
      "loss": 0.3177,
      "step": 19440
    },
    {
      "epoch": 9.12,
      "grad_norm": 1.9604671001434326,
      "learning_rate": 5.713712561823569e-07,
      "loss": 0.2869,
      "step": 19450
    },
    {
      "epoch": 9.12,
      "grad_norm": 1.2852989435195923,
      "learning_rate": 5.653473771806966e-07,
      "loss": 0.3089,
      "step": 19460
    },
    {
      "epoch": 9.13,
      "grad_norm": 1.6720945835113525,
      "learning_rate": 5.593548111512614e-07,
      "loss": 0.3133,
      "step": 19470
    },
    {
      "epoch": 9.13,
      "grad_norm": 1.4861361980438232,
      "learning_rate": 5.53393571093681e-07,
      "loss": 0.2854,
      "step": 19480
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.943196177482605,
      "learning_rate": 5.474636699396212e-07,
      "loss": 0.3325,
      "step": 19490
    },
    {
      "epoch": 9.14,
      "grad_norm": 2.6860790252685547,
      "learning_rate": 5.415651205527639e-07,
      "loss": 0.3104,
      "step": 19500
    },
    {
      "epoch": 9.15,
      "grad_norm": 1.613343596458435,
      "learning_rate": 5.35697935728785e-07,
      "loss": 0.3211,
      "step": 19510
    },
    {
      "epoch": 9.15,
      "grad_norm": 2.191108465194702,
      "learning_rate": 5.298621281953236e-07,
      "loss": 0.3216,
      "step": 19520
    },
    {
      "epoch": 9.16,
      "grad_norm": 1.903580665588379,
      "learning_rate": 5.240577106119449e-07,
      "loss": 0.3103,
      "step": 19530
    },
    {
      "epoch": 9.16,
      "grad_norm": 1.9278020858764648,
      "learning_rate": 5.182846955701248e-07,
      "loss": 0.3143,
      "step": 19540
    },
    {
      "epoch": 9.17,
      "grad_norm": 1.584872841835022,
      "learning_rate": 5.125430955932175e-07,
      "loss": 0.3039,
      "step": 19550
    },
    {
      "epoch": 9.17,
      "grad_norm": 1.3133527040481567,
      "learning_rate": 5.068329231364283e-07,
      "loss": 0.3112,
      "step": 19560
    },
    {
      "epoch": 9.17,
      "grad_norm": 1.9429677724838257,
      "learning_rate": 5.011541905867866e-07,
      "loss": 0.3032,
      "step": 19570
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.3336091041564941,
      "learning_rate": 4.955069102631188e-07,
      "loss": 0.3101,
      "step": 19580
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.0556955337524414,
      "learning_rate": 4.898910944160235e-07,
      "loss": 0.3229,
      "step": 19590
    },
    {
      "epoch": 9.19,
      "grad_norm": 2.27070689201355,
      "learning_rate": 4.84306755227844e-07,
      "loss": 0.3058,
      "step": 19600
    },
    {
      "epoch": 9.19,
      "grad_norm": 1.6408568620681763,
      "learning_rate": 4.787539048126438e-07,
      "loss": 0.2986,
      "step": 19610
    },
    {
      "epoch": 9.2,
      "grad_norm": 1.8107404708862305,
      "learning_rate": 4.732325552161704e-07,
      "loss": 0.3442,
      "step": 19620
    },
    {
      "epoch": 9.2,
      "grad_norm": 2.0810492038726807,
      "learning_rate": 4.6774271841584446e-07,
      "loss": 0.3592,
      "step": 19630
    },
    {
      "epoch": 9.21,
      "grad_norm": 1.7531813383102417,
      "learning_rate": 4.622844063207199e-07,
      "loss": 0.2992,
      "step": 19640
    },
    {
      "epoch": 9.21,
      "grad_norm": 1.1458543539047241,
      "learning_rate": 4.568576307714734e-07,
      "loss": 0.3144,
      "step": 19650
    },
    {
      "epoch": 9.22,
      "grad_norm": 1.945492148399353,
      "learning_rate": 4.5146240354036306e-07,
      "loss": 0.316,
      "step": 19660
    },
    {
      "epoch": 9.22,
      "grad_norm": 1.416069507598877,
      "learning_rate": 4.460987363312069e-07,
      "loss": 0.3214,
      "step": 19670
    },
    {
      "epoch": 9.23,
      "grad_norm": 1.4068619012832642,
      "learning_rate": 4.407666407793659e-07,
      "loss": 0.3021,
      "step": 19680
    },
    {
      "epoch": 9.23,
      "grad_norm": 1.8311196565628052,
      "learning_rate": 4.3546612845171087e-07,
      "loss": 0.3219,
      "step": 19690
    },
    {
      "epoch": 9.24,
      "grad_norm": 2.3577117919921875,
      "learning_rate": 4.30197210846599e-07,
      "loss": 0.2868,
      "step": 19700
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.60836660861969,
      "learning_rate": 4.2495989939384916e-07,
      "loss": 0.2576,
      "step": 19710
    },
    {
      "epoch": 9.25,
      "grad_norm": 2.061662197113037,
      "learning_rate": 4.197542054547199e-07,
      "loss": 0.3263,
      "step": 19720
    },
    {
      "epoch": 9.25,
      "grad_norm": 2.423281669616699,
      "learning_rate": 4.145801403218763e-07,
      "loss": 0.3179,
      "step": 19730
    },
    {
      "epoch": 9.25,
      "grad_norm": 1.3121302127838135,
      "learning_rate": 4.094377152193784e-07,
      "loss": 0.3036,
      "step": 19740
    },
    {
      "epoch": 9.26,
      "grad_norm": 1.647958517074585,
      "learning_rate": 4.043269413026429e-07,
      "loss": 0.3357,
      "step": 19750
    },
    {
      "epoch": 9.26,
      "grad_norm": 2.095116376876831,
      "learning_rate": 3.992478296584312e-07,
      "loss": 0.2812,
      "step": 19760
    },
    {
      "epoch": 9.27,
      "grad_norm": 2.419685125350952,
      "learning_rate": 3.942003913048198e-07,
      "loss": 0.3468,
      "step": 19770
    },
    {
      "epoch": 9.27,
      "grad_norm": 1.518364667892456,
      "learning_rate": 3.891846371911717e-07,
      "loss": 0.3149,
      "step": 19780
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.2272049188613892,
      "learning_rate": 3.842005781981217e-07,
      "loss": 0.3329,
      "step": 19790
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.5371067523956299,
      "learning_rate": 3.7924822513754786e-07,
      "loss": 0.3007,
      "step": 19800
    },
    {
      "epoch": 9.29,
      "grad_norm": 1.7360835075378418,
      "learning_rate": 3.7432758875254825e-07,
      "loss": 0.2722,
      "step": 19810
    },
    {
      "epoch": 9.29,
      "grad_norm": 2.6007351875305176,
      "learning_rate": 3.694386797174193e-07,
      "loss": 0.333,
      "step": 19820
    },
    {
      "epoch": 9.3,
      "grad_norm": 1.451178789138794,
      "learning_rate": 3.6458150863763086e-07,
      "loss": 0.29,
      "step": 19830
    },
    {
      "epoch": 9.3,
      "grad_norm": 1.3546948432922363,
      "learning_rate": 3.5975608604980446e-07,
      "loss": 0.3202,
      "step": 19840
    },
    {
      "epoch": 9.31,
      "grad_norm": 1.5722806453704834,
      "learning_rate": 3.549624224216852e-07,
      "loss": 0.2802,
      "step": 19850
    },
    {
      "epoch": 9.31,
      "grad_norm": 1.811677098274231,
      "learning_rate": 3.5020052815213475e-07,
      "loss": 0.2941,
      "step": 19860
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.8713282346725464,
      "learning_rate": 3.454704135710851e-07,
      "loss": 0.2968,
      "step": 19870
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.4325580596923828,
      "learning_rate": 3.4077208893953657e-07,
      "loss": 0.3108,
      "step": 19880
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.9233046770095825,
      "learning_rate": 3.3610556444952643e-07,
      "loss": 0.3352,
      "step": 19890
    },
    {
      "epoch": 9.33,
      "grad_norm": 1.60908043384552,
      "learning_rate": 3.314708502241071e-07,
      "loss": 0.279,
      "step": 19900
    },
    {
      "epoch": 9.33,
      "grad_norm": 1.894720435142517,
      "learning_rate": 3.2686795631732603e-07,
      "loss": 0.2862,
      "step": 19910
    },
    {
      "epoch": 9.34,
      "grad_norm": 1.7591265439987183,
      "learning_rate": 3.2229689271420116e-07,
      "loss": 0.3301,
      "step": 19920
    },
    {
      "epoch": 9.34,
      "grad_norm": 1.7065688371658325,
      "learning_rate": 3.177576693307055e-07,
      "loss": 0.3,
      "step": 19930
    },
    {
      "epoch": 9.35,
      "grad_norm": 1.7222728729248047,
      "learning_rate": 3.132502960137357e-07,
      "loss": 0.3023,
      "step": 19940
    },
    {
      "epoch": 9.35,
      "grad_norm": 1.5512032508850098,
      "learning_rate": 3.087747825411003e-07,
      "loss": 0.3095,
      "step": 19950
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.3590009212493896,
      "learning_rate": 3.043311386214964e-07,
      "loss": 0.2994,
      "step": 19960
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.6961674690246582,
      "learning_rate": 2.9991937389448167e-07,
      "loss": 0.2888,
      "step": 19970
    },
    {
      "epoch": 9.37,
      "grad_norm": 1.651969075202942,
      "learning_rate": 2.9553949793045874e-07,
      "loss": 0.3032,
      "step": 19980
    },
    {
      "epoch": 9.37,
      "grad_norm": 2.2408697605133057,
      "learning_rate": 2.9119152023065756e-07,
      "loss": 0.3063,
      "step": 19990
    },
    {
      "epoch": 9.38,
      "grad_norm": 2.2219011783599854,
      "learning_rate": 2.8687545022711314e-07,
      "loss": 0.3064,
      "step": 20000
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.7252424955368042,
      "learning_rate": 2.825912972826361e-07,
      "loss": 0.3074,
      "step": 20010
    },
    {
      "epoch": 9.39,
      "grad_norm": 1.8581575155258179,
      "learning_rate": 2.78339070690809e-07,
      "loss": 0.3028,
      "step": 20020
    },
    {
      "epoch": 9.39,
      "grad_norm": 1.8145416975021362,
      "learning_rate": 2.7411877967594477e-07,
      "loss": 0.349,
      "step": 20030
    },
    {
      "epoch": 9.4,
      "grad_norm": 1.6699210405349731,
      "learning_rate": 2.699304333930902e-07,
      "loss": 0.2794,
      "step": 20040
    },
    {
      "epoch": 9.4,
      "grad_norm": 2.0155529975891113,
      "learning_rate": 2.657740409279891e-07,
      "loss": 0.307,
      "step": 20050
    },
    {
      "epoch": 9.4,
      "grad_norm": 2.303250789642334,
      "learning_rate": 2.6164961129707064e-07,
      "loss": 0.3207,
      "step": 20060
    },
    {
      "epoch": 9.41,
      "grad_norm": 2.059067487716675,
      "learning_rate": 2.57557153447423e-07,
      "loss": 0.2905,
      "step": 20070
    },
    {
      "epoch": 9.41,
      "grad_norm": 1.424729585647583,
      "learning_rate": 2.5349667625678476e-07,
      "loss": 0.2916,
      "step": 20080
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.5004993677139282,
      "learning_rate": 2.494681885335115e-07,
      "loss": 0.3179,
      "step": 20090
    },
    {
      "epoch": 9.42,
      "grad_norm": 2.5648114681243896,
      "learning_rate": 2.454716990165712e-07,
      "loss": 0.2913,
      "step": 20100
    },
    {
      "epoch": 9.43,
      "grad_norm": 1.3490378856658936,
      "learning_rate": 2.4150721637551386e-07,
      "loss": 0.3265,
      "step": 20110
    },
    {
      "epoch": 9.43,
      "grad_norm": 1.44818115234375,
      "learning_rate": 2.3757474921045685e-07,
      "loss": 0.283,
      "step": 20120
    },
    {
      "epoch": 9.44,
      "grad_norm": 1.5297507047653198,
      "learning_rate": 2.3367430605207464e-07,
      "loss": 0.3757,
      "step": 20130
    },
    {
      "epoch": 9.44,
      "grad_norm": 1.7007029056549072,
      "learning_rate": 2.298058953615606e-07,
      "loss": 0.3265,
      "step": 20140
    },
    {
      "epoch": 9.45,
      "grad_norm": 2.5922043323516846,
      "learning_rate": 2.2596952553062877e-07,
      "loss": 0.3344,
      "step": 20150
    },
    {
      "epoch": 9.45,
      "grad_norm": 2.791323184967041,
      "learning_rate": 2.2216520488148207e-07,
      "loss": 0.3498,
      "step": 20160
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.7183077335357666,
      "learning_rate": 2.1839294166680402e-07,
      "loss": 0.269,
      "step": 20170
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.4655417203903198,
      "learning_rate": 2.1465274406973213e-07,
      "loss": 0.316,
      "step": 20180
    },
    {
      "epoch": 9.47,
      "grad_norm": 1.389802098274231,
      "learning_rate": 2.1094462020384953e-07,
      "loss": 0.2976,
      "step": 20190
    },
    {
      "epoch": 9.47,
      "grad_norm": 2.049412488937378,
      "learning_rate": 2.0726857811315336e-07,
      "loss": 0.2856,
      "step": 20200
    },
    {
      "epoch": 9.47,
      "grad_norm": 2.0603716373443604,
      "learning_rate": 2.0362462577205477e-07,
      "loss": 0.3721,
      "step": 20210
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.948822021484375,
      "learning_rate": 2.0001277108534722e-07,
      "loss": 0.3096,
      "step": 20220
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.7564572095870972,
      "learning_rate": 1.964330218881999e-07,
      "loss": 0.3675,
      "step": 20230
    },
    {
      "epoch": 9.49,
      "grad_norm": 1.299416422843933,
      "learning_rate": 1.9288538594613103e-07,
      "loss": 0.3307,
      "step": 20240
    },
    {
      "epoch": 9.49,
      "grad_norm": 1.9930181503295898,
      "learning_rate": 1.893698709549996e-07,
      "loss": 0.3446,
      "step": 20250
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.8415048122406006,
      "learning_rate": 1.8588648454098023e-07,
      "loss": 0.3222,
      "step": 20260
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.3568792343139648,
      "learning_rate": 1.8243523426055674e-07,
      "loss": 0.3206,
      "step": 20270
    },
    {
      "epoch": 9.51,
      "grad_norm": 1.4251914024353027,
      "learning_rate": 1.7901612760049702e-07,
      "loss": 0.2861,
      "step": 20280
    },
    {
      "epoch": 9.51,
      "grad_norm": 1.2367210388183594,
      "learning_rate": 1.75629171977838e-07,
      "loss": 0.3432,
      "step": 20290
    },
    {
      "epoch": 9.52,
      "grad_norm": 1.27079176902771,
      "learning_rate": 1.7227437473987918e-07,
      "loss": 0.3102,
      "step": 20300
    },
    {
      "epoch": 9.52,
      "grad_norm": 1.5224502086639404,
      "learning_rate": 1.6895174316415407e-07,
      "loss": 0.3029,
      "step": 20310
    },
    {
      "epoch": 9.53,
      "grad_norm": 2.3262863159179688,
      "learning_rate": 1.6566128445841544e-07,
      "loss": 0.286,
      "step": 20320
    },
    {
      "epoch": 9.53,
      "grad_norm": 1.2464927434921265,
      "learning_rate": 1.6240300576063015e-07,
      "loss": 0.2847,
      "step": 20330
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.498053789138794,
      "learning_rate": 1.5917691413895597e-07,
      "loss": 0.3392,
      "step": 20340
    },
    {
      "epoch": 9.54,
      "grad_norm": 2.7460052967071533,
      "learning_rate": 1.559830165917281e-07,
      "loss": 0.315,
      "step": 20350
    },
    {
      "epoch": 9.55,
      "grad_norm": 2.755485773086548,
      "learning_rate": 1.528213200474393e-07,
      "loss": 0.3164,
      "step": 20360
    },
    {
      "epoch": 9.55,
      "grad_norm": 1.2822275161743164,
      "learning_rate": 1.4969183136473163e-07,
      "loss": 0.2807,
      "step": 20370
    },
    {
      "epoch": 9.55,
      "grad_norm": 1.7076417207717896,
      "learning_rate": 1.4659455733238124e-07,
      "loss": 0.3193,
      "step": 20380
    },
    {
      "epoch": 9.56,
      "grad_norm": 2.1198105812072754,
      "learning_rate": 1.4352950466927696e-07,
      "loss": 0.2849,
      "step": 20390
    },
    {
      "epoch": 9.56,
      "grad_norm": 1.6482511758804321,
      "learning_rate": 1.4049668002441175e-07,
      "loss": 0.3053,
      "step": 20400
    },
    {
      "epoch": 9.57,
      "grad_norm": 1.9792046546936035,
      "learning_rate": 1.3749608997686958e-07,
      "loss": 0.3101,
      "step": 20410
    },
    {
      "epoch": 9.57,
      "grad_norm": 1.1560721397399902,
      "learning_rate": 1.34527741035802e-07,
      "loss": 0.3284,
      "step": 20420
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.869727611541748,
      "learning_rate": 1.3159163964042818e-07,
      "loss": 0.3014,
      "step": 20430
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.685681939125061,
      "learning_rate": 1.2868779216000493e-07,
      "loss": 0.3777,
      "step": 20440
    },
    {
      "epoch": 9.59,
      "grad_norm": 1.9220354557037354,
      "learning_rate": 1.258162048938266e-07,
      "loss": 0.362,
      "step": 20450
    },
    {
      "epoch": 9.59,
      "grad_norm": 1.8874558210372925,
      "learning_rate": 1.2297688407120033e-07,
      "loss": 0.3333,
      "step": 20460
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.4745185375213623,
      "learning_rate": 1.201698358514458e-07,
      "loss": 0.3088,
      "step": 20470
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.0130336284637451,
      "learning_rate": 1.173950663238671e-07,
      "loss": 0.3293,
      "step": 20480
    },
    {
      "epoch": 9.61,
      "grad_norm": 1.4267805814743042,
      "learning_rate": 1.1465258150774927e-07,
      "loss": 0.3086,
      "step": 20490
    },
    {
      "epoch": 9.61,
      "grad_norm": 1.8230844736099243,
      "learning_rate": 1.1194238735234008e-07,
      "loss": 0.2818,
      "step": 20500
    },
    {
      "epoch": 9.62,
      "grad_norm": 1.8595454692840576,
      "learning_rate": 1.0926448973684334e-07,
      "loss": 0.3328,
      "step": 20510
    },
    {
      "epoch": 9.62,
      "grad_norm": 1.566544771194458,
      "learning_rate": 1.0661889447039886e-07,
      "loss": 0.3036,
      "step": 20520
    },
    {
      "epoch": 9.62,
      "grad_norm": 2.0214128494262695,
      "learning_rate": 1.0400560729207586e-07,
      "loss": 0.3011,
      "step": 20530
    },
    {
      "epoch": 9.63,
      "grad_norm": 1.7355555295944214,
      "learning_rate": 1.0142463387085465e-07,
      "loss": 0.2846,
      "step": 20540
    },
    {
      "epoch": 9.63,
      "grad_norm": 1.5703115463256836,
      "learning_rate": 9.887597980562158e-08,
      "loss": 0.3193,
      "step": 20550
    },
    {
      "epoch": 9.64,
      "grad_norm": 1.8008259534835815,
      "learning_rate": 9.635965062515073e-08,
      "loss": 0.2693,
      "step": 20560
    },
    {
      "epoch": 9.64,
      "grad_norm": 2.672375440597534,
      "learning_rate": 9.387565178809232e-08,
      "loss": 0.3382,
      "step": 20570
    },
    {
      "epoch": 9.65,
      "grad_norm": 2.114208459854126,
      "learning_rate": 9.142398868296431e-08,
      "loss": 0.3197,
      "step": 20580
    },
    {
      "epoch": 9.65,
      "grad_norm": 1.9609973430633545,
      "learning_rate": 8.900466662814078e-08,
      "loss": 0.324,
      "step": 20590
    },
    {
      "epoch": 9.66,
      "grad_norm": 1.5637800693511963,
      "learning_rate": 8.66176908718369e-08,
      "loss": 0.3155,
      "step": 20600
    },
    {
      "epoch": 9.66,
      "grad_norm": 1.5990463495254517,
      "learning_rate": 8.426306659209904e-08,
      "loss": 0.2992,
      "step": 20610
    },
    {
      "epoch": 9.67,
      "grad_norm": 1.9133044481277466,
      "learning_rate": 8.194079889679296e-08,
      "loss": 0.3031,
      "step": 20620
    },
    {
      "epoch": 9.67,
      "grad_norm": 1.8367180824279785,
      "learning_rate": 7.965089282359561e-08,
      "loss": 0.3249,
      "step": 20630
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.6146552562713623,
      "learning_rate": 7.739335333998176e-08,
      "loss": 0.3055,
      "step": 20640
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.4467146396636963,
      "learning_rate": 7.516818534321235e-08,
      "loss": 0.3193,
      "step": 20650
    },
    {
      "epoch": 9.69,
      "grad_norm": 1.9876186847686768,
      "learning_rate": 7.297539366032779e-08,
      "loss": 0.2945,
      "step": 20660
    },
    {
      "epoch": 9.69,
      "grad_norm": 1.8370732069015503,
      "learning_rate": 7.081498304812972e-08,
      "loss": 0.2975,
      "step": 20670
    },
    {
      "epoch": 9.7,
      "grad_norm": 1.62685227394104,
      "learning_rate": 6.868695819318094e-08,
      "loss": 0.2868,
      "step": 20680
    },
    {
      "epoch": 9.7,
      "grad_norm": 1.3973180055618286,
      "learning_rate": 6.659132371178711e-08,
      "loss": 0.3215,
      "step": 20690
    },
    {
      "epoch": 9.7,
      "grad_norm": 1.5797194242477417,
      "learning_rate": 6.452808414999178e-08,
      "loss": 0.3468,
      "step": 20700
    },
    {
      "epoch": 9.71,
      "grad_norm": 1.6995576620101929,
      "learning_rate": 6.249724398356304e-08,
      "loss": 0.3388,
      "step": 20710
    },
    {
      "epoch": 9.71,
      "grad_norm": 1.6163556575775146,
      "learning_rate": 6.049880761798521e-08,
      "loss": 0.3411,
      "step": 20720
    },
    {
      "epoch": 9.72,
      "grad_norm": 1.3526108264923096,
      "learning_rate": 5.853277938845047e-08,
      "loss": 0.3457,
      "step": 20730
    },
    {
      "epoch": 9.72,
      "grad_norm": 1.5335363149642944,
      "learning_rate": 5.6599163559845624e-08,
      "loss": 0.3596,
      "step": 20740
    },
    {
      "epoch": 9.73,
      "grad_norm": 1.7722076177597046,
      "learning_rate": 5.469796432675034e-08,
      "loss": 0.2723,
      "step": 20750
    },
    {
      "epoch": 9.73,
      "grad_norm": 1.6694356203079224,
      "learning_rate": 5.282918581341889e-08,
      "loss": 0.2957,
      "step": 20760
    },
    {
      "epoch": 9.74,
      "grad_norm": 1.9378690719604492,
      "learning_rate": 5.0992832073776806e-08,
      "loss": 0.2812,
      "step": 20770
    },
    {
      "epoch": 9.74,
      "grad_norm": 1.6765010356903076,
      "learning_rate": 4.918890709141255e-08,
      "loss": 0.313,
      "step": 20780
    },
    {
      "epoch": 9.75,
      "grad_norm": 1.5235644578933716,
      "learning_rate": 4.741741477956252e-08,
      "loss": 0.3489,
      "step": 20790
    },
    {
      "epoch": 9.75,
      "grad_norm": 1.4626293182373047,
      "learning_rate": 4.567835898111272e-08,
      "loss": 0.3131,
      "step": 20800
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.2619081735610962,
      "learning_rate": 4.3971743468582126e-08,
      "loss": 0.3229,
      "step": 20810
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.1437320709228516,
      "learning_rate": 4.229757194411765e-08,
      "loss": 0.3277,
      "step": 20820
    },
    {
      "epoch": 9.77,
      "grad_norm": 1.3994146585464478,
      "learning_rate": 4.065584803948419e-08,
      "loss": 0.3064,
      "step": 20830
    },
    {
      "epoch": 9.77,
      "grad_norm": 1.779820442199707,
      "learning_rate": 3.9046575316062925e-08,
      "loss": 0.3367,
      "step": 20840
    },
    {
      "epoch": 9.77,
      "grad_norm": 2.022089958190918,
      "learning_rate": 3.746975726483304e-08,
      "loss": 0.339,
      "step": 20850
    },
    {
      "epoch": 9.78,
      "grad_norm": 1.6827789545059204,
      "learning_rate": 3.592539730637334e-08,
      "loss": 0.3456,
      "step": 20860
    },
    {
      "epoch": 9.78,
      "grad_norm": 2.364337682723999,
      "learning_rate": 3.4413498790852314e-08,
      "loss": 0.3204,
      "step": 20870
    },
    {
      "epoch": 9.79,
      "grad_norm": 1.7058788537979126,
      "learning_rate": 3.2934064998016434e-08,
      "loss": 0.3497,
      "step": 20880
    },
    {
      "epoch": 9.79,
      "grad_norm": 1.6069532632827759,
      "learning_rate": 3.148709913719183e-08,
      "loss": 0.2638,
      "step": 20890
    },
    {
      "epoch": 9.8,
      "grad_norm": 2.190521478652954,
      "learning_rate": 3.007260434726933e-08,
      "loss": 0.3304,
      "step": 20900
    },
    {
      "epoch": 9.8,
      "grad_norm": 1.6747605800628662,
      "learning_rate": 2.8690583696699414e-08,
      "loss": 0.3475,
      "step": 20910
    },
    {
      "epoch": 9.81,
      "grad_norm": 1.7831987142562866,
      "learning_rate": 2.7341040183488932e-08,
      "loss": 0.3028,
      "step": 20920
    },
    {
      "epoch": 9.81,
      "grad_norm": 1.5869873762130737,
      "learning_rate": 2.6023976735189414e-08,
      "loss": 0.2916,
      "step": 20930
    },
    {
      "epoch": 9.82,
      "grad_norm": 2.1433169841766357,
      "learning_rate": 2.4739396208898757e-08,
      "loss": 0.2976,
      "step": 20940
    },
    {
      "epoch": 9.82,
      "grad_norm": 1.5476642847061157,
      "learning_rate": 2.3487301391244552e-08,
      "loss": 0.3807,
      "step": 20950
    },
    {
      "epoch": 9.83,
      "grad_norm": 2.2097668647766113,
      "learning_rate": 2.2267694998387435e-08,
      "loss": 0.3003,
      "step": 20960
    },
    {
      "epoch": 9.83,
      "grad_norm": 1.6033827066421509,
      "learning_rate": 2.1080579676007738e-08,
      "loss": 0.3055,
      "step": 20970
    },
    {
      "epoch": 9.84,
      "grad_norm": 1.9549814462661743,
      "learning_rate": 1.992595799930552e-08,
      "loss": 0.3168,
      "step": 20980
    },
    {
      "epoch": 9.84,
      "grad_norm": 1.5065423250198364,
      "learning_rate": 1.880383247299222e-08,
      "loss": 0.3286,
      "step": 20990
    },
    {
      "epoch": 9.85,
      "grad_norm": 1.5078729391098022,
      "learning_rate": 1.7714205531285665e-08,
      "loss": 0.2856,
      "step": 21000
    },
    {
      "epoch": 9.85,
      "grad_norm": 1.8893216848373413,
      "learning_rate": 1.6657079537905074e-08,
      "loss": 0.2925,
      "step": 21010
    },
    {
      "epoch": 9.85,
      "grad_norm": 1.778995394706726,
      "learning_rate": 1.5632456786062732e-08,
      "loss": 0.2852,
      "step": 21020
    },
    {
      "epoch": 9.86,
      "grad_norm": 2.0006332397460938,
      "learning_rate": 1.4640339498467325e-08,
      "loss": 0.3168,
      "step": 21030
    },
    {
      "epoch": 9.86,
      "grad_norm": 1.308613657951355,
      "learning_rate": 1.3680729827307282e-08,
      "loss": 0.3054,
      "step": 21040
    },
    {
      "epoch": 9.87,
      "grad_norm": 1.652132272720337,
      "learning_rate": 1.2753629854259097e-08,
      "loss": 0.2969,
      "step": 21050
    },
    {
      "epoch": 9.87,
      "grad_norm": 1.314945101737976,
      "learning_rate": 1.1859041590472352e-08,
      "loss": 0.2895,
      "step": 21060
    },
    {
      "epoch": 9.88,
      "grad_norm": 2.201322555541992,
      "learning_rate": 1.0996966976568046e-08,
      "loss": 0.2915,
      "step": 21070
    },
    {
      "epoch": 9.88,
      "grad_norm": 1.5981264114379883,
      "learning_rate": 1.0167407882640257e-08,
      "loss": 0.3414,
      "step": 21080
    },
    {
      "epoch": 9.89,
      "grad_norm": 1.9205737113952637,
      "learning_rate": 9.370366108241157e-09,
      "loss": 0.3071,
      "step": 21090
    },
    {
      "epoch": 9.89,
      "grad_norm": 1.7369439601898193,
      "learning_rate": 8.60584338239101e-09,
      "loss": 0.3049,
      "step": 21100
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.8818929195404053,
      "learning_rate": 7.873841363558177e-09,
      "loss": 0.2959,
      "step": 21110
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.9342803955078125,
      "learning_rate": 7.174361639672445e-09,
      "loss": 0.2816,
      "step": 21120
    },
    {
      "epoch": 9.91,
      "grad_norm": 2.071232557296753,
      "learning_rate": 6.507405728108373e-09,
      "loss": 0.3226,
      "step": 21130
    },
    {
      "epoch": 9.91,
      "grad_norm": 1.9486010074615479,
      "learning_rate": 5.872975075685294e-09,
      "loss": 0.3134,
      "step": 21140
    },
    {
      "epoch": 9.92,
      "grad_norm": 1.545801043510437,
      "learning_rate": 5.2710710586723055e-09,
      "loss": 0.333,
      "step": 21150
    },
    {
      "epoch": 9.92,
      "grad_norm": 1.9755644798278809,
      "learning_rate": 4.70169498277162e-09,
      "loss": 0.3135,
      "step": 21160
    },
    {
      "epoch": 9.92,
      "grad_norm": 1.4675984382629395,
      "learning_rate": 4.164848083128559e-09,
      "loss": 0.3615,
      "step": 21170
    },
    {
      "epoch": 9.93,
      "grad_norm": 1.2196376323699951,
      "learning_rate": 3.6605315243182225e-09,
      "loss": 0.3688,
      "step": 21180
    },
    {
      "epoch": 9.93,
      "grad_norm": 2.4875340461730957,
      "learning_rate": 3.1887464003521604e-09,
      "loss": 0.3266,
      "step": 21190
    },
    {
      "epoch": 9.94,
      "grad_norm": 1.085777759552002,
      "learning_rate": 2.7494937346683733e-09,
      "loss": 0.34,
      "step": 21200
    },
    {
      "epoch": 9.94,
      "grad_norm": 1.5219155550003052,
      "learning_rate": 2.3427744801363114e-09,
      "loss": 0.3685,
      "step": 21210
    },
    {
      "epoch": 9.95,
      "grad_norm": 2.323155164718628,
      "learning_rate": 1.9685895190468816e-09,
      "loss": 0.2984,
      "step": 21220
    },
    {
      "epoch": 9.95,
      "grad_norm": 1.346373200416565,
      "learning_rate": 1.6269396631157785e-09,
      "loss": 0.2656,
      "step": 21230
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.6639680862426758,
      "learning_rate": 1.3178256534834843e-09,
      "loss": 0.3374,
      "step": 21240
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.6049187183380127,
      "learning_rate": 1.0412481607069424e-09,
      "loss": 0.3177,
      "step": 21250
    },
    {
      "epoch": 9.97,
      "grad_norm": 1.4274342060089111,
      "learning_rate": 7.972077847628878e-10,
      "loss": 0.3121,
      "step": 21260
    },
    {
      "epoch": 9.97,
      "grad_norm": 1.8677923679351807,
      "learning_rate": 5.857050550478471e-10,
      "loss": 0.3563,
      "step": 21270
    },
    {
      "epoch": 9.98,
      "grad_norm": 2.7379133701324463,
      "learning_rate": 4.0674043037147723e-10,
      "loss": 0.2833,
      "step": 21280
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.321771264076233,
      "learning_rate": 2.6031429896156147e-10,
      "loss": 0.2839,
      "step": 21290
    },
    {
      "epoch": 9.99,
      "grad_norm": 2.214829921722412,
      "learning_rate": 1.4642697845734799e-10,
      "loss": 0.296,
      "step": 21300
    },
    {
      "epoch": 9.99,
      "grad_norm": 1.336351990699768,
      "learning_rate": 6.507871591454606e-11,
      "loss": 0.316,
      "step": 21310
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.7812960147857666,
      "learning_rate": 1.6269687801995224e-11,
      "loss": 0.3027,
      "step": 21320
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.6522971391677856,
      "learning_rate": 0.0,
      "loss": 0.3239,
      "step": 21330
    },
    {
      "epoch": 10.0,
      "step": 21330,
      "total_flos": 2.129343906507129e+19,
      "train_loss": 0.3892156708592604,
      "train_runtime": 130954.7422,
      "train_samples_per_second": 5.212,
      "train_steps_per_second": 0.163
    }
  ],
  "logging_steps": 10,
  "max_steps": 21330,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "total_flos": 2.129343906507129e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
